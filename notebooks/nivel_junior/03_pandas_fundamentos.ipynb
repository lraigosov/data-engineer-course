{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37391fb6",
   "metadata": {},
   "source": [
    "# Pandas: Fundamentos para An√°lisis de Datos\n",
    "\n",
    "## Objetivos de Aprendizaje\n",
    "- Dominar las estructuras de datos de Pandas (Series y DataFrame)\n",
    "- Realizar operaciones de lectura y escritura de datos\n",
    "- Manipular y transformar DataFrames eficientemente\n",
    "- Aplicar filtros, agrupaciones y agregaciones\n",
    "- Trabajar con datos faltantes y duplicados\n",
    "\n",
    "## Requisitos\n",
    "- Python 3.8+\n",
    "- pandas\n",
    "- numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088f2f06",
   "metadata": {},
   "source": [
    "### üìñ Importando Pandas - La Biblioteca M√°s Importante\n",
    "\n",
    "**¬øQu√© es pandas?**\n",
    "Pandas es **LA biblioteca fundamental** para Data Engineering y Data Science en Python. Es como tener:\n",
    "- Excel con superpoderes\n",
    "- SQL dentro de Python\n",
    "- Herramientas de an√°lisis de datos profesionales\n",
    "\n",
    "**¬øPor qu√© `import pandas as pd`?**\n",
    "- **`pd` es el alias universal**: TODO el mundo lo usa\n",
    "- **Convenio establecido**: Como `import numpy as np`\n",
    "- **M√°s r√°pido de escribir**: `pd.DataFrame()` vs `pandas.DataFrame()`\n",
    "\n",
    "**¬øQu√© puedes hacer con pandas?**\n",
    "1. **Leer datos**: CSV, Excel, JSON, SQL, Parquet, HTML\n",
    "2. **Manipular**: Filtrar, transformar, agrupar, pivotar\n",
    "3. **Limpiar**: Manejar nulos, duplicados, tipos de datos\n",
    "4. **Analizar**: Estad√≠sticas, agregaciones, series temporales\n",
    "5. **Exportar**: Guardar en m√∫ltiples formatos\n",
    "\n",
    "**Estructuras principales:**\n",
    "\n",
    "| Estructura | Dimensi√≥n | Descripci√≥n | Analog√≠a |\n",
    "|------------|-----------|-------------|----------|\n",
    "| **Series** | 1D | Array etiquetado | Una columna de Excel |\n",
    "| **DataFrame** | 2D | Tabla con filas y columnas | Hoja de Excel completa |\n",
    "\n",
    "**En este bloque:**\n",
    "Simplemente importamos pandas con el alias est√°ndar `pd`. Esto hace que toda la funcionalidad de pandas est√© disponible en tu notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b11195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalaci√≥n de dependencias\n",
    "import sys\n",
    "!{sys.executable} -m pip install pandas numpy matplotlib seaborn -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa59b80f",
   "metadata": {},
   "source": [
    "### üìñ Series - La Estructura 1D de Pandas\n",
    "\n",
    "**¬øQu√© es una Series?**\n",
    "Es un **array unidimensional etiquetado** - como una columna de Excel con esteroides:\n",
    "- Tiene **valores** (los datos)\n",
    "- Tiene **√≠ndice** (etiquetas para cada valor)\n",
    "- Tiene **tipo de dato** homog√©neo (todos int, todos float, etc.)\n",
    "\n",
    "**Diferencias clave con listas de Python:**\n",
    "\n",
    "| Caracter√≠stica | Lista Python | Pandas Series |\n",
    "|----------------|--------------|---------------|\n",
    "| √çndice | Num√©rico solo (0, 1, 2...) | Cualquier cosa (nombres, fechas, etc.) |\n",
    "| Tipos | Mixtos | Homog√©neo (optimizado) |\n",
    "| Operaciones vectorizadas | ‚ùå No | ‚úÖ S√≠ (s√∫per r√°pido) |\n",
    "| M√©todos estad√≠sticos | ‚ùå No | ‚úÖ mean(), std(), etc. |\n",
    "\n",
    "**Anatom√≠a de una Series:**\n",
    "```python\n",
    "s = pd.Series([10, 20, 30, 40])\n",
    "\n",
    "# Tiene 3 componentes:\n",
    "# 1. Valores: [10, 20, 30, 40]\n",
    "# 2. √çndice: [0, 1, 2, 3] (auto-generado)\n",
    "# 3. Tipo: dtype('int64')\n",
    "```\n",
    "\n",
    "**Visualizaci√≥n:**\n",
    "```\n",
    "0    10     ‚Üê √≠ndice 0, valor 10\n",
    "1    20     ‚Üê √≠ndice 1, valor 20\n",
    "2    30     ‚Üê √≠ndice 2, valor 30\n",
    "3    40     ‚Üê √≠ndice 3, valor 40\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "**Creaci√≥n b√°sica:**\n",
    "```python\n",
    "# Desde lista\n",
    "s = pd.Series([1, 2, 3, 4, 5])\n",
    "\n",
    "# Desde diccionario (las claves se vuelven √≠ndice)\n",
    "s = pd.Series({'a': 100, 'b': 200, 'c': 300})\n",
    "\n",
    "# Con √≠ndice personalizado\n",
    "s = pd.Series([10, 20, 30], index=['x', 'y', 'z'])\n",
    "```\n",
    "\n",
    "**¬øCu√°ndo usar Series?**\n",
    "- Representar **una columna** de datos\n",
    "- Trabajar con **series temporales** (precios de acciones)\n",
    "- Operar sobre **un atributo** (edades, salarios, etc.)\n",
    "\n",
    "**En este bloque ver√°s:**\n",
    "1. Crear Series desde listas simples\n",
    "2. Acceder a valores con √≠ndice num√©rico\n",
    "3. La estructura b√°sica: valores + √≠ndice + dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68168ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Configuraci√≥n\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8219c653",
   "metadata": {},
   "source": [
    "## 1. Series de Pandas\n",
    "\n",
    "Una Series es un array unidimensional etiquetado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df71f02b",
   "metadata": {},
   "source": [
    "### üìñ DataFrames - Tablas con Superpoderes\n",
    "\n",
    "**¬øQu√© es un DataFrame?**\n",
    "Es la **estructura 2D** (filas √ó columnas) m√°s importante de pandas:\n",
    "- Piensa en una **hoja de Excel**\n",
    "- O una **tabla SQL**\n",
    "- Cada columna es una Series\n",
    "- Cada fila es un registro\n",
    "\n",
    "**Anatom√≠a de un DataFrame:**\n",
    "```\n",
    "       nombre  edad  ciudad      ‚Üê Columnas (headers)\n",
    "    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "  0 ‚îÇ Ana      25    Madrid     ‚Üê Fila 0 (√≠ndice)\n",
    "  1 ‚îÇ Luis     30    Barcelona  ‚Üê Fila 1\n",
    "  2 ‚îÇ Carlos   28    Valencia   ‚Üê Fila 2\n",
    "    ‚îî\n",
    "    ‚Üë\n",
    "  √çndice\n",
    "```\n",
    "\n",
    "**Formas de crear un DataFrame:**\n",
    "\n",
    "**1. Desde diccionario de listas (COM√öN - orientado a columnas):**\n",
    "```python\n",
    "data = {\n",
    "    'nombre': ['Ana', 'Luis', 'Carlos'],\n",
    "    'edad': [25, 30, 28]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "```\n",
    "\n",
    "**2. Desde lista de diccionarios (orientado a filas):**\n",
    "```python\n",
    "data = [\n",
    "    {'nombre': 'Ana', 'edad': 25},\n",
    "    {'nombre': 'Luis', 'edad': 30}\n",
    "]\n",
    "df = pd.DataFrame(data)\n",
    "```\n",
    "\n",
    "**3. Desde archivo (CSV, Excel, JSON, SQL, etc.):**\n",
    "```python\n",
    "df = pd.read_csv('datos.csv')\n",
    "df = pd.read_excel('datos.xlsx')\n",
    "df = pd.read_json('datos.json')\n",
    "df = pd.read_sql('SELECT * FROM tabla', conexion)\n",
    "```\n",
    "\n",
    "**Componentes de un DataFrame:**\n",
    "- **Columnas**: Atributos/caracter√≠sticas (nombre, edad, precio, etc.)\n",
    "- **√çndice**: Identificador de cada fila (0, 1, 2... o personalizado)\n",
    "- **Valores**: Los datos en s√≠\n",
    "- **dtype por columna**: Cada columna tiene su tipo (int, float, object, datetime)\n",
    "\n",
    "**Propiedades √∫tiles:**\n",
    "```python\n",
    "df.shape         # (num_filas, num_columnas)\n",
    "df.columns       # Nombres de columnas\n",
    "df.index         # √çndice\n",
    "df.dtypes        # Tipos de datos por columna\n",
    "df.size          # Total de celdas\n",
    "df.ndim          # Dimensiones (siempre 2)\n",
    "```\n",
    "\n",
    "**En este bloque aprender√°s:**\n",
    "1. Crear DataFrames desde diccionarios\n",
    "2. Entender la estructura tabular\n",
    "3. Ver √≠ndice autom√°tico vs personalizado\n",
    "4. La relaci√≥n entre diccionarios Python y DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cf0973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una Series desde una lista\n",
    "ventas = pd.Series([100, 150, 200, 175, 225], name='ventas_diarias')\n",
    "print(\"Series b√°sica:\")\n",
    "print(ventas)\n",
    "print(f\"\\nTipo: {type(ventas)}\")\n",
    "print(f\"Shape: {ventas.shape}\")\n",
    "print(f\"Dtype: {ventas.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6e497b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Series con √≠ndice personalizado\n",
    "temperaturas = pd.Series(\n",
    "    data=[22, 25, 28, 26, 24],\n",
    "    index=['Lunes', 'Martes', 'Mi√©rcoles', 'Jueves', 'Viernes'],\n",
    "    name='temperatura_celsius'\n",
    ")\n",
    "print(\"Series con √≠ndice personalizado:\")\n",
    "print(temperaturas)\n",
    "print(f\"\\nAcceso por √≠ndice: Mi√©rcoles = {temperaturas['Mi√©rcoles']}¬∞C\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619527f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Operaciones con Series\n",
    "print(\"Estad√≠sticas descriptivas:\")\n",
    "print(f\"Media: {temperaturas.mean():.2f}¬∞C\")\n",
    "print(f\"Mediana: {temperaturas.median()}¬∞C\")\n",
    "print(f\"Desviaci√≥n est√°ndar: {temperaturas.std():.2f}¬∞C\")\n",
    "print(f\"M√≠nimo: {temperaturas.min()}¬∞C\")\n",
    "print(f\"M√°ximo: {temperaturas.max()}¬∞C\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7730787e",
   "metadata": {},
   "source": [
    "## 2. DataFrames: La estructura principal\n",
    "\n",
    "Un DataFrame es una estructura bidimensional con columnas que pueden ser de diferentes tipos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869e76af",
   "metadata": {},
   "source": [
    "### üìñ Selecci√≥n de Datos - Accediendo a lo que Necesitas\n",
    "\n",
    "**¬øPor qu√© es importante?**\n",
    "En Data Engineering, rara vez trabajas con TODO el dataset:\n",
    "- Necesitas **columnas espec√≠ficas** para an√°lisis\n",
    "- Filtras **filas que cumplen condiciones**\n",
    "- Extraes **un subconjunto** para procesar\n",
    "\n",
    "**4 formas principales de seleccionar:**\n",
    "\n",
    "**1. Por nombre de columna:**\n",
    "```python\n",
    "df['nombre']           # Una columna ‚Üí Series\n",
    "df[['nombre', 'edad']] # M√∫ltiples columnas ‚Üí DataFrame\n",
    "```\n",
    "\n",
    "**2. Con `.loc[]` (label-based - por etiqueta):**\n",
    "```python\n",
    "df.loc[0]              # Fila con √≠ndice 0\n",
    "df.loc[0:2]            # Filas 0, 1, 2 (inclusivo!)\n",
    "df.loc[0, 'nombre']    # Celda espec√≠fica\n",
    "```\n",
    "\n",
    "**3. Con `.iloc[]` (integer position-based - por posici√≥n):**\n",
    "```python\n",
    "df.iloc[0]             # Primera fila\n",
    "df.iloc[0:2]           # Filas 0, 1 (exclusivo!)\n",
    "df.iloc[0, 1]          # Fila 0, columna 1\n",
    "```\n",
    "\n",
    "**4. Filtrado booleano:**\n",
    "```python\n",
    "df[df['edad'] > 25]    # Filas donde edad > 25\n",
    "```\n",
    "\n",
    "**Diferencia clave loc vs iloc:**\n",
    "\n",
    "| Aspecto | `.loc[]` | `.iloc[]` |\n",
    "|---------|----------|-----------|\n",
    "| Tipo | Basado en etiquetas | Basado en posici√≥n |\n",
    "| √çndice | Usa nombres/√≠ndice | Usa n√∫meros (0, 1, 2...) |\n",
    "| Slicing | Inclusivo `[0:2]` incluye 2 | Exclusivo `[0:2]` excluye 2 |\n",
    "| Ejemplo | `df.loc['fila_A']` | `df.iloc[0]` |\n",
    "\n",
    "**En este bloque ver√°s:**\n",
    "1. Seleccionar una columna con `df['columna']`\n",
    "2. Seleccionar m√∫ltiples columnas con doble corchete\n",
    "3. Usar `.loc[]` para acceso por etiqueta\n",
    "4. Usar `.iloc[]` para acceso por posici√≥n num√©rica\n",
    "5. La diferencia sutil pero importante entre ambos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc2d875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear DataFrame desde diccionario\n",
    "datos_ventas = {\n",
    "    'producto': ['Laptop', 'Mouse', 'Teclado', 'Monitor', 'Webcam'],\n",
    "    'cantidad': [5, 25, 15, 8, 12],\n",
    "    'precio_unitario': [1200, 25, 75, 300, 80],\n",
    "    'categoria': ['Computadoras', 'Accesorios', 'Accesorios', 'Computadoras', 'Accesorios']\n",
    "}\n",
    "\n",
    "df_ventas = pd.DataFrame(datos_ventas)\n",
    "print(\"DataFrame de ventas:\")\n",
    "print(df_ventas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7603e7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Informaci√≥n del DataFrame\n",
    "print(\"Informaci√≥n del DataFrame:\")\n",
    "print(f\"Shape: {df_ventas.shape}\")\n",
    "print(f\"Columnas: {df_ventas.columns.tolist()}\")\n",
    "print(f\"\\nTipos de datos:\")\n",
    "print(df_ventas.dtypes)\n",
    "print(f\"\\nInformaci√≥n detallada:\")\n",
    "df_ventas.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa396e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear nueva columna calculada\n",
    "df_ventas['total_venta'] = df_ventas['cantidad'] * df_ventas['precio_unitario']\n",
    "print(\"DataFrame con columna calculada:\")\n",
    "print(df_ventas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbdfe07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estad√≠sticas descriptivas\n",
    "print(\"Estad√≠sticas del DataFrame:\")\n",
    "print(df_ventas.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5864a856",
   "metadata": {},
   "source": [
    "## 3. Selecci√≥n y Filtrado de Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57cd004",
   "metadata": {},
   "source": [
    "### üìñ Filtrado Booleano - El Poder de las Condiciones\n",
    "\n",
    "**¬øQu√© es el filtrado booleano?**\n",
    "Es usar **condiciones l√≥gicas** para seleccionar solo las filas que cumplen criterios:\n",
    "- ¬øClientes mayores de 18 a√±os?\n",
    "- ¬øVentas superiores a $1000?\n",
    "- ¬øProductos en stock?\n",
    "\n",
    "**Sintaxis b√°sica:**\n",
    "```python\n",
    "df[df['columna'] > valor]\n",
    "```\n",
    "\n",
    "**C√≥mo funciona (paso a paso):**\n",
    "```python\n",
    "# 1. La condici√≥n crea una Series booleana\n",
    "df['edad'] > 25\n",
    "# Retorna: [False, True, True, False...]\n",
    "\n",
    "# 2. Esa Series se usa como m√°scara\n",
    "df[df['edad'] > 25]\n",
    "# Solo las filas donde es True pasan\n",
    "```\n",
    "\n",
    "**Operadores de comparaci√≥n:**\n",
    "\n",
    "| Operador | Significado | Ejemplo |\n",
    "|----------|-------------|---------|\n",
    "| `==` | Igual a | `df['ciudad'] == 'Madrid'` |\n",
    "| `!=` | Diferente de | `df['status'] != 'activo'` |\n",
    "| `>` | Mayor que | `df['precio'] > 100` |\n",
    "| `<` | Menor que | `df['stock'] < 10` |\n",
    "| `>=` | Mayor o igual | `df['edad'] >= 18` |\n",
    "| `<=` | Menor o igual | `df['descuento'] <= 0.5` |\n",
    "\n",
    "**Filtros compuestos (m√∫ltiples condiciones):**\n",
    "\n",
    "**AND (ambas deben cumplirse):**\n",
    "```python\n",
    "df[(df['edad'] > 25) & (df['ciudad'] == 'Madrid')]\n",
    "```\n",
    "\n",
    "**OR (al menos una debe cumplirse):**\n",
    "```python\n",
    "df[(df['edad'] > 60) | (df['edad'] < 18)]\n",
    "```\n",
    "\n",
    "**NOT (negaci√≥n):**\n",
    "```python\n",
    "df[~(df['ciudad'] == 'Madrid')]  # Todo menos Madrid\n",
    "```\n",
    "\n",
    "**‚ö†Ô∏è IMPORTANTE:**\n",
    "- Usa `&` (AND) y `|` (OR), NO `and` y `or`\n",
    "- Envuelve cada condici√≥n en par√©ntesis: `(condicion1) & (condicion2)`\n",
    "\n",
    "**M√©todos √∫tiles con strings:**\n",
    "```python\n",
    "# Contiene substring\n",
    "df[df['nombre'].str.contains('Ana')]\n",
    "\n",
    "# Empieza con\n",
    "df[df['email'].str.startswith('admin')]\n",
    "\n",
    "# Est√° en lista\n",
    "df[df['ciudad'].isin(['Madrid', 'Barcelona'])]\n",
    "```\n",
    "\n",
    "**En este bloque aprender√°s:**\n",
    "1. Crear condiciones booleanas con operadores de comparaci√≥n\n",
    "2. Usar `&` (AND) y `|` (OR) para combinar condiciones\n",
    "3. El m√©todo `.isin()` para buscar en listas\n",
    "4. Por qu√© necesitas par√©ntesis en filtros compuestos\n",
    "5. C√≥mo funcionan las m√°scaras booleanas internamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36badc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar columnas\n",
    "print(\"Selecci√≥n de una columna:\")\n",
    "print(df_ventas['producto'])\n",
    "print(f\"\\nTipo: {type(df_ventas['producto'])}\")\n",
    "\n",
    "print(\"\\nSelecci√≥n de m√∫ltiples columnas:\")\n",
    "print(df_ventas[['producto', 'total_venta']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9017fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrado con condiciones\n",
    "print(\"Productos con ventas mayores a $1000:\")\n",
    "ventas_altas = df_ventas[df_ventas['total_venta'] > 1000]\n",
    "print(ventas_altas)\n",
    "\n",
    "print(\"\\nProductos de categor√≠a 'Accesorios':\")\n",
    "accesorios = df_ventas[df_ventas['categoria'] == 'Accesorios']\n",
    "print(accesorios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598bee4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrado con m√∫ltiples condiciones\n",
    "print(\"Accesorios con ventas mayores a $500:\")\n",
    "filtro_complejo = df_ventas[\n",
    "    (df_ventas['categoria'] == 'Accesorios') & \n",
    "    (df_ventas['total_venta'] > 500)\n",
    "]\n",
    "print(filtro_complejo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62f5bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uso de loc e iloc\n",
    "print(\"Uso de loc (etiquetas):\")\n",
    "print(df_ventas.loc[0:2, ['producto', 'cantidad']])\n",
    "\n",
    "print(\"\\nUso de iloc (posiciones):\")\n",
    "print(df_ventas.iloc[0:3, 0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02770366",
   "metadata": {},
   "source": [
    "## 4. Agrupaciones y Agregaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077852ab",
   "metadata": {},
   "source": [
    "### üìñ Operaciones con Columnas - Transformando Datos\n",
    "\n",
    "**¬øPor qu√© crear nuevas columnas?**\n",
    "Los datos crudos rara vez tienen TODO lo que necesitas:\n",
    "- Calcular **m√©tricas derivadas** (total = cantidad √ó precio)\n",
    "- Aplicar **reglas de negocio** (descuento si precio > 100)\n",
    "- Crear **categor√≠as** (edad ‚Üí 'joven', 'adulto', 'senior')\n",
    "- Convertir **unidades** (temperatura ¬∞C ‚Üí ¬∞F)\n",
    "\n",
    "**Formas de crear columnas:**\n",
    "\n",
    "**1. Operaciones aritm√©ticas:**\n",
    "```python\n",
    "df['total'] = df['cantidad'] * df['precio']\n",
    "df['precio_con_iva'] = df['precio'] * 1.21\n",
    "```\n",
    "\n",
    "**2. Operaciones condicionales (np.where):**\n",
    "```python\n",
    "df['categoria'] = np.where(df['edad'] < 18, 'Menor', 'Adulto')\n",
    "# Si edad < 18 ‚Üí 'Menor', si no ‚Üí 'Adulto'\n",
    "```\n",
    "\n",
    "**3. Apply con funciones:**\n",
    "```python\n",
    "df['nombre_upper'] = df['nombre'].apply(lambda x: x.upper())\n",
    "```\n",
    "\n",
    "**4. Operaciones entre columnas:**\n",
    "```python\n",
    "df['diferencia'] = df['precio_venta'] - df['costo']\n",
    "df['margen'] = (df['diferencia'] / df['precio_venta']) * 100\n",
    "```\n",
    "\n",
    "**Operadores soportados:**\n",
    "- `+` Suma\n",
    "- `-` Resta\n",
    "- `*` Multiplicaci√≥n\n",
    "- `/` Divisi√≥n\n",
    "- `**` Potencia\n",
    "- `%` M√≥dulo\n",
    "- `//` Divisi√≥n entera\n",
    "\n",
    "**Modificar columnas existentes:**\n",
    "```python\n",
    "# Reemplazar valores\n",
    "df['precio'] = df['precio'] * 1.1  # Aumentar 10%\n",
    "\n",
    "# Renombrar\n",
    "df = df.rename(columns={'nombre': 'nombre_cliente'})\n",
    "\n",
    "# Eliminar\n",
    "df = df.drop(columns=['columna_innecesaria'])\n",
    "```\n",
    "\n",
    "**En este bloque ver√°s:**\n",
    "1. Crear columnas con operaciones aritm√©ticas simples\n",
    "2. Usar `np.where()` para l√≥gica condicional (if-else)\n",
    "3. Sintaxis: `np.where(condicion, valor_si_true, valor_si_false)`\n",
    "4. Aplicar transformaciones a todas las filas simult√°neamente\n",
    "5. Por qu√© pandas es vectorizado (no necesitas loops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57aabd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear dataset m√°s grande para agrupaciones\n",
    "np.random.seed(42)\n",
    "n_registros = 100\n",
    "\n",
    "df_transacciones = pd.DataFrame({\n",
    "    'fecha': pd.date_range('2024-01-01', periods=n_registros, freq='D'),\n",
    "    'categoria': np.random.choice(['Electr√≥nica', 'Ropa', 'Alimentos', 'Hogar'], n_registros),\n",
    "    'producto': [f'Producto_{i}' for i in range(n_registros)],\n",
    "    'cantidad': np.random.randint(1, 20, n_registros),\n",
    "    'precio': np.random.uniform(10, 500, n_registros).round(2),\n",
    "    'region': np.random.choice(['Norte', 'Sur', 'Este', 'Oeste'], n_registros)\n",
    "})\n",
    "\n",
    "df_transacciones['total'] = df_transacciones['cantidad'] * df_transacciones['precio']\n",
    "\n",
    "print(\"Dataset de transacciones:\")\n",
    "print(df_transacciones.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01103bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrupaci√≥n simple\n",
    "print(\"Ventas totales por categor√≠a:\")\n",
    "ventas_por_categoria = df_transacciones.groupby('categoria')['total'].sum()\n",
    "print(ventas_por_categoria)\n",
    "print(f\"\\nTipo: {type(ventas_por_categoria)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af6ae29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# M√∫ltiples agregaciones\n",
    "print(\"Estad√≠sticas por categor√≠a:\")\n",
    "stats_categoria = df_transacciones.groupby('categoria')['total'].agg([\n",
    "    ('total_ventas', 'sum'),\n",
    "    ('promedio', 'mean'),\n",
    "    ('num_transacciones', 'count'),\n",
    "    ('max_venta', 'max')\n",
    "])\n",
    "print(stats_categoria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7e32f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrupaci√≥n por m√∫ltiples columnas\n",
    "print(\"Ventas por categor√≠a y regi√≥n:\")\n",
    "ventas_categoria_region = df_transacciones.groupby(['categoria', 'region'])['total'].sum()\n",
    "print(ventas_categoria_region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546762a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usar pivot_table para an√°lisis multidimensional\n",
    "print(\"Tabla din√°mica: Ventas por categor√≠a y regi√≥n:\")\n",
    "pivot_ventas = df_transacciones.pivot_table(\n",
    "    values='total',\n",
    "    index='categoria',\n",
    "    columns='region',\n",
    "    aggfunc='sum',\n",
    "    fill_value=0\n",
    ")\n",
    "print(pivot_ventas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b31f74",
   "metadata": {},
   "source": [
    "## 5. Manejo de Datos Faltantes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c18afa",
   "metadata": {},
   "source": [
    "### üìñ GroupBy - La Operaci√≥n M√°s Poderosa de Pandas\n",
    "\n",
    "**¬øQu√© es groupby?**\n",
    "Es el equivalente de **GROUP BY en SQL** - agrupa filas por valores √∫nicos de una columna:\n",
    "- Ventas **por regi√≥n**\n",
    "- Salarios **por departamento**\n",
    "- Usuarios **por pa√≠s**\n",
    "\n",
    "**Patr√≥n split-apply-combine:**\n",
    "```\n",
    "Original DataFrame:\n",
    "regi√≥n    ventas\n",
    "Norte     100\n",
    "Norte     200\n",
    "Sur       150\n",
    "Sur       250\n",
    "\n",
    "‚¨áÔ∏è SPLIT (agrupar por regi√≥n)\n",
    "\n",
    "Grupo Norte: [100, 200]\n",
    "Grupo Sur:   [150, 250]\n",
    "\n",
    "‚¨áÔ∏è APPLY (aplicar funci√≥n, ej: sum)\n",
    "\n",
    "Norte: 300\n",
    "Sur:   400\n",
    "\n",
    "‚¨áÔ∏è COMBINE (combinar resultados)\n",
    "\n",
    "regi√≥n    ventas\n",
    "Norte     300\n",
    "Sur       400\n",
    "```\n",
    "\n",
    "**Sintaxis b√°sica:**\n",
    "```python\n",
    "df.groupby('columna')['columna_a_agregar'].funcion()\n",
    "```\n",
    "\n",
    "**Desglose:**\n",
    "1. `df.groupby('region')` ‚Üí Agrupa por regi√≥n\n",
    "2. `['total']` ‚Üí Selecciona columna a operar\n",
    "3. `.sum()` ‚Üí Aplica funci√≥n de agregaci√≥n\n",
    "\n",
    "**Funciones de agregaci√≥n comunes:**\n",
    "\n",
    "| Funci√≥n | Qu√© hace | Ejemplo de uso |\n",
    "|---------|----------|----------------|\n",
    "| `.sum()` | Suma total | Ingresos totales |\n",
    "| `.mean()` | Promedio | Salario promedio |\n",
    "| `.median()` | Mediana | Precio t√≠pico |\n",
    "| `.count()` | Cantidad | N√∫mero de transacciones |\n",
    "| `.min()` | M√≠nimo | Venta m√°s baja |\n",
    "| `.max()` | M√°ximo | Venta m√°s alta |\n",
    "| `.std()` | Desviaci√≥n est√°ndar | Variabilidad |\n",
    "| `.var()` | Varianza | Dispersi√≥n |\n",
    "| `.size()` | Tama√±o de grupo | Filas por grupo |\n",
    "\n",
    "**Agrupar por m√∫ltiples columnas:**\n",
    "```python\n",
    "df.groupby(['region', 'categoria'])['total'].sum()\n",
    "```\n",
    "\n",
    "**Aplicar m√∫ltiples funciones:**\n",
    "```python\n",
    "df.groupby('region')['total'].agg(['sum', 'mean', 'count'])\n",
    "```\n",
    "\n",
    "**Casos de uso en Data Engineering:**\n",
    "1. **Reportes por dimensi√≥n**: Ventas por mes, producto, regi√≥n\n",
    "2. **C√°lculo de KPIs**: AOV (Average Order Value) por segmento\n",
    "3. **Detecci√≥n de anomal√≠as**: Comparar grupos para encontrar outliers\n",
    "4. **Feature engineering**: Crear caracter√≠sticas agregadas para ML\n",
    "5. **Data quality**: Contar registros por categor√≠a\n",
    "\n",
    "**En este bloque aprender√°s:**\n",
    "1. Usar `groupby()` para agrupar por una columna\n",
    "2. Aplicar funciones de agregaci√≥n (sum, mean, count)\n",
    "3. Agrupar por m√∫ltiples columnas simult√°neamente\n",
    "4. El patr√≥n split-apply-combine\n",
    "5. Diferencia entre `.size()` y `.count()`\n",
    "6. Usar `.agg()` para aplicar m√∫ltiples funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a95b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear DataFrame con valores faltantes\n",
    "datos_clientes = {\n",
    "    'id': [1, 2, 3, 4, 5, 6],\n",
    "    'nombre': ['Juan', 'Mar√≠a', 'Pedro', None, 'Ana', 'Luis'],\n",
    "    'edad': [25, 30, None, 28, 35, None],\n",
    "    'email': ['juan@mail.com', None, 'pedro@mail.com', 'carlos@mail.com', None, 'luis@mail.com'],\n",
    "    'salario': [50000, 60000, 55000, None, 70000, 48000]\n",
    "}\n",
    "\n",
    "df_clientes = pd.DataFrame(datos_clientes)\n",
    "print(\"DataFrame con valores faltantes:\")\n",
    "print(df_clientes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704eb328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detectar valores faltantes\n",
    "print(\"Valores nulos por columna:\")\n",
    "print(df_clientes.isnull().sum())\n",
    "\n",
    "print(\"\\nPorcentaje de valores nulos:\")\n",
    "print((df_clientes.isnull().sum() / len(df_clientes) * 100).round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411aacf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar filas con valores faltantes\n",
    "df_sin_nulos = df_clientes.dropna()\n",
    "print(f\"Filas originales: {len(df_clientes)}\")\n",
    "print(f\"Filas despu√©s de dropna(): {len(df_sin_nulos)}\")\n",
    "print(\"\\nDataFrame sin nulos:\")\n",
    "print(df_sin_nulos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964d7f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rellenar valores faltantes\n",
    "df_rellenado = df_clientes.copy()\n",
    "\n",
    "# Rellenar edad con la media\n",
    "df_rellenado['edad'].fillna(df_rellenado['edad'].mean(), inplace=True)\n",
    "\n",
    "# Rellenar nombre con un valor por defecto\n",
    "df_rellenado['nombre'].fillna('Desconocido', inplace=True)\n",
    "\n",
    "# Rellenar email con un valor espec√≠fico\n",
    "df_rellenado['email'].fillna('sin_email@ejemplo.com', inplace=True)\n",
    "\n",
    "# Rellenar salario con la mediana\n",
    "df_rellenado['salario'].fillna(df_rellenado['salario'].median(), inplace=True)\n",
    "\n",
    "print(\"DataFrame con valores imputados:\")\n",
    "print(df_rellenado)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87dc7771",
   "metadata": {},
   "source": [
    "## 6. Manejo de Duplicados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c107d57e",
   "metadata": {},
   "source": [
    "### üìñ Datos Faltantes (NaN) - El Enemigo Silencioso\n",
    "\n",
    "**¬øQu√© son los valores nulos?**\n",
    "Son **ausencias de datos** representadas como `NaN` (Not a Number) o `None`:\n",
    "- Campos opcionales no completados (tel√©fono, direcci√≥n)\n",
    "- Errores en recolecci√≥n (sensor desconectado)\n",
    "- Joins que no hicieron match\n",
    "- Datos hist√≥ricos perdidos\n",
    "\n",
    "**¬øPor qu√© son problem√°ticos?**\n",
    "- **Rompen c√°lculos**: `sum([1, 2, NaN])` puede dar resultados inesperados\n",
    "- **Sesgan estad√≠sticas**: `mean()` ignora NaN pero cambia el denominador\n",
    "- **Fallan modelos ML**: La mayor√≠a NO acepta NaN\n",
    "- **Errores en producci√≥n**: C√≥digo asume valores presentes\n",
    "\n",
    "**Detectar valores nulos:**\n",
    "\n",
    "```python\n",
    "# Por celda\n",
    "df.isnull()        # True donde hay NaN\n",
    "df.notnull()       # True donde NO hay NaN\n",
    "\n",
    "# Por columna (cu√°ntos nulos)\n",
    "df.isnull().sum()\n",
    "\n",
    "# Filas con alg√∫n nulo\n",
    "df[df.isnull().any(axis=1)]\n",
    "\n",
    "# Porcentaje de nulos\n",
    "(df.isnull().sum() / len(df)) * 100\n",
    "```\n",
    "\n",
    "**Estrategias de manejo:**\n",
    "\n",
    "**1. Eliminar (dropna):**\n",
    "```python\n",
    "# Eliminar filas con alg√∫n NaN\n",
    "df.dropna()\n",
    "\n",
    "# Eliminar filas donde TODAS las columnas sean NaN\n",
    "df.dropna(how='all')\n",
    "\n",
    "# Eliminar columnas con alg√∫n NaN\n",
    "df.dropna(axis=1)\n",
    "\n",
    "# Eliminar solo si hay NaN en columnas espec√≠ficas\n",
    "df.dropna(subset=['edad', 'salario'])\n",
    "```\n",
    "\n",
    "**‚ö†Ô∏è Cuidado:** Si tienes 1000 filas y 10 tienen NaN, ¬øvale la pena perder el 1%?\n",
    "\n",
    "**2. Rellenar (fillna):**\n",
    "```python\n",
    "# Con un valor constante\n",
    "df.fillna(0)\n",
    "\n",
    "# Con la media (para num√©ricos)\n",
    "df['edad'].fillna(df['edad'].mean())\n",
    "\n",
    "# Con la mediana (resistente a outliers)\n",
    "df['salario'].fillna(df['salario'].median())\n",
    "\n",
    "# Con la moda (m√°s frecuente)\n",
    "df['ciudad'].fillna(df['ciudad'].mode()[0])\n",
    "\n",
    "# Forward fill (llevar valor anterior)\n",
    "df.fillna(method='ffill')\n",
    "\n",
    "# Backward fill (traer valor siguiente)\n",
    "df.fillna(method='bfill')\n",
    "```\n",
    "\n",
    "**3. Imputaci√≥n avanzada:**\n",
    "```python\n",
    "# Por grupo\n",
    "df['salario'] = df.groupby('departamento')['salario'].transform(\n",
    "    lambda x: x.fillna(x.mean())\n",
    ")\n",
    "```\n",
    "\n",
    "**¬øCu√°ndo usar cada estrategia?**\n",
    "\n",
    "| Estrategia | Cu√°ndo usarla | Ejemplo |\n",
    "|------------|---------------|---------|\n",
    "| **Eliminar** | Pocos nulos (<5%), campo obligatorio | ID, fecha de transacci√≥n |\n",
    "| **Rellenar con 0** | Ausencia = cero | Descuento aplicado |\n",
    "| **Rellenar con media/mediana** | Num√©ricos, distribuci√≥n normal | Edad, salario |\n",
    "| **Rellenar con moda** | Categ√≥ricos | Ciudad, categor√≠a |\n",
    "| **Forward/Backward fill** | Series temporales | Precio de acciones |\n",
    "| **Dejar** | Ausencia es informativa | Fecha de cancelaci√≥n |\n",
    "\n",
    "**Validaci√≥n post-procesamiento:**\n",
    "```python\n",
    "# Verificar que no quedan nulos\n",
    "assert df.isnull().sum().sum() == 0, \"¬°A√∫n hay nulos!\"\n",
    "```\n",
    "\n",
    "**En este bloque aprender√°s:**\n",
    "1. Detectar nulos con `isnull()` y contar con `.sum()`\n",
    "2. Eliminar filas/columnas con `dropna()`\n",
    "3. Rellenar nulos con `fillna()`\n",
    "4. Estrategias: valor constante, media, mediana, moda\n",
    "5. Diferencia entre eliminar vs imputar\n",
    "6. Par√°metros de dropna: `how='all'`, `subset=[]`\n",
    "7. Por qu√© la mediana es mejor que la media con outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed810cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear DataFrame con duplicados\n",
    "datos_duplicados = {\n",
    "    'id': [1, 2, 3, 2, 4, 3, 5],\n",
    "    'producto': ['A', 'B', 'C', 'B', 'D', 'C', 'E'],\n",
    "    'cantidad': [10, 20, 15, 20, 25, 15, 30]\n",
    "}\n",
    "\n",
    "df_dup = pd.DataFrame(datos_duplicados)\n",
    "print(\"DataFrame con duplicados:\")\n",
    "print(df_dup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7873fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detectar duplicados\n",
    "print(\"Filas duplicadas:\")\n",
    "print(df_dup[df_dup.duplicated()])\n",
    "\n",
    "print(f\"\\nN√∫mero de duplicados: {df_dup.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0317c45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar duplicados\n",
    "df_sin_dup = df_dup.drop_duplicates()\n",
    "print(\"DataFrame sin duplicados:\")\n",
    "print(df_sin_dup)\n",
    "print(f\"\\nFilas originales: {len(df_dup)}\")\n",
    "print(f\"Filas sin duplicados: {len(df_sin_dup)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1471feba",
   "metadata": {},
   "source": [
    "## 7. Ordenamiento de Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f05d3e",
   "metadata": {},
   "source": [
    "### üìñ Duplicados - Detectando Filas Repetidas\n",
    "\n",
    "**¬øQu√© son duplicados?**\n",
    "Son **filas id√©nticas** (o id√©nticas en ciertas columnas) que aparecen m√∫ltiples veces:\n",
    "- Errores en importaci√≥n (archivo procesado dos veces)\n",
    "- Bugs en aplicaciones (mismo registro insertado m√∫ltiples veces)\n",
    "- Falta de constraints en BD (sin PRIMARY KEY)\n",
    "- Merges incorrectos (joins mal hechos)\n",
    "\n",
    "**¬øPor qu√© son problem√°ticos?**\n",
    "- **Sesgan an√°lisis**: Contar \"clientes √∫nicos\" da resultados incorrectos\n",
    "- **Inflan m√©tricas**: Ventas totales duplicadas\n",
    "- **Desperdiciar recursos**: Procesar mismo dato m√∫ltiples veces\n",
    "- **Violan integridad**: Un usuario no deber√≠a tener 2 IDs\n",
    "\n",
    "**Detectar duplicados:**\n",
    "\n",
    "```python\n",
    "# Filas completamente duplicadas\n",
    "df.duplicated()  # Retorna Series booleana\n",
    "\n",
    "# Contar duplicados\n",
    "df.duplicated().sum()\n",
    "\n",
    "# Ver las filas duplicadas\n",
    "df[df.duplicated()]\n",
    "\n",
    "# Duplicados basados en columnas espec√≠ficas\n",
    "df.duplicated(subset=['email'])  # Duplicados de email\n",
    "\n",
    "# Mostrar todas las ocurrencias (no solo la segunda)\n",
    "df[df.duplicated(subset=['email'], keep=False)]\n",
    "```\n",
    "\n",
    "**Par√°metro `keep`:**\n",
    "\n",
    "| Valor | Qu√© hace | Cu√°ndo usar |\n",
    "|-------|----------|-------------|\n",
    "| `'first'` | Marca duplicados excepto primera ocurrencia (default) | Mantener registro m√°s antiguo |\n",
    "| `'last'` | Marca duplicados excepto √∫ltima ocurrencia | Mantener registro m√°s reciente |\n",
    "| `False` | Marca TODAS las ocurrencias como duplicadas | Ver todos los duplicados |\n",
    "\n",
    "**Ejemplo visual:**\n",
    "```\n",
    "Original:\n",
    "  id  nombre\n",
    "  1   Ana\n",
    "  2   Luis\n",
    "  1   Ana    ‚Üê Duplicado\n",
    "  3   Carlos\n",
    "\n",
    "duplicated(keep='first'):\n",
    "  False, False, True, False  ‚Üê Marca el segundo\n",
    "\n",
    "duplicated(keep=False):\n",
    "  True, False, True, False   ‚Üê Marca ambos\n",
    "```\n",
    "\n",
    "**Eliminar duplicados:**\n",
    "\n",
    "```python\n",
    "# Eliminar filas completamente duplicadas\n",
    "df.drop_duplicates()\n",
    "\n",
    "# Basado en columnas espec√≠ficas\n",
    "df.drop_duplicates(subset=['email'])\n",
    "\n",
    "# Mantener √∫ltima ocurrencia\n",
    "df.drop_duplicates(subset=['email'], keep='last')\n",
    "\n",
    "# In-place (modifica el DataFrame original)\n",
    "df.drop_duplicates(inplace=True)\n",
    "```\n",
    "\n",
    "**Casos de uso:**\n",
    "\n",
    "**1. Deduplicar usuarios:**\n",
    "```python\n",
    "# Mantener √∫ltimo registro (m√°s actualizado)\n",
    "df_usuarios = df.drop_duplicates(subset=['user_id'], keep='last')\n",
    "```\n",
    "\n",
    "**2. Encontrar emails repetidos:**\n",
    "```python\n",
    "# Ver todos los duplicados\n",
    "duplicados = df[df.duplicated(subset=['email'], keep=False)]\n",
    "duplicados.sort_values('email')  # Agrupar para revisar\n",
    "```\n",
    "\n",
    "**3. Validar unicidad antes de cargar a BD:**\n",
    "```python\n",
    "assert df['id'].duplicated().sum() == 0, \"¬°IDs duplicados encontrados!\"\n",
    "```\n",
    "\n",
    "**Best practices:**\n",
    "- ‚úÖ **Investiga antes de eliminar**: ¬øPor qu√© hay duplicados?\n",
    "- ‚úÖ **Log de eliminaci√≥n**: Guarda qu√© se elimin√≥\n",
    "- ‚úÖ **Define criterio de keep**: ¬øfirst, last, o ninguno?\n",
    "- ‚úÖ **Valida post-procesamiento**: Asegura que no quedan duplicados\n",
    "- ‚ö†Ô∏è **Cuidado con None/NaN**: Pandas los considera √∫nicos\n",
    "\n",
    "**En este bloque aprender√°s:**\n",
    "1. Detectar duplicados con `duplicated()`\n",
    "2. Contar duplicados con `.sum()`\n",
    "3. Ver filas duplicadas filtrando con la m√°scara booleana\n",
    "4. Eliminar duplicados con `drop_duplicates()`\n",
    "5. El par√°metro `subset` para especificar columnas\n",
    "6. Diferencia entre `keep='first'`, `keep='last'` y `keep=False`\n",
    "7. Por qu√© revisar duplicados antes de eliminarlos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cf66c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordenar por una columna\n",
    "print(\"Ventas ordenadas por total (descendente):\")\n",
    "df_ordenado = df_ventas.sort_values('total_venta', ascending=False)\n",
    "print(df_ordenado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdbcfc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordenar por m√∫ltiples columnas\n",
    "print(\"Transacciones ordenadas por categor√≠a y total:\")\n",
    "df_multi_orden = df_transacciones.sort_values(\n",
    "    ['categoria', 'total'],\n",
    "    ascending=[True, False]\n",
    ").head(10)\n",
    "print(df_multi_orden[['categoria', 'producto', 'total']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7012ca",
   "metadata": {},
   "source": [
    "## 8. Concatenaci√≥n y Merge de DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff931a81",
   "metadata": {},
   "source": [
    "### üìñ Ordenamiento - Organizando tus Datos\n",
    "\n",
    "**¬øPor qu√© ordenar?**\n",
    "- **An√°lisis temporal**: Ver evoluci√≥n cronol√≥gica\n",
    "- **Top N**: Productos m√°s vendidos, salarios m√°s altos\n",
    "- **Presentaci√≥n**: Reportes ordenados se leen mejor\n",
    "- **Debugging**: Detectar patrones y anomal√≠as\n",
    "- **Optimizaci√≥n**: Algunos algoritmos funcionan mejor con datos ordenados\n",
    "\n",
    "**Dos tipos de ordenamiento:**\n",
    "\n",
    "**1. Por valores (sort_values):**\n",
    "```python\n",
    "# Ascendente (menor a mayor)\n",
    "df.sort_values('edad')\n",
    "\n",
    "# Descendente (mayor a menor)\n",
    "df.sort_values('edad', ascending=False)\n",
    "\n",
    "# Por m√∫ltiples columnas\n",
    "df.sort_values(['ciudad', 'edad'])\n",
    "```\n",
    "\n",
    "**2. Por √≠ndice (sort_index):**\n",
    "```python\n",
    "# Ascendente\n",
    "df.sort_index()\n",
    "\n",
    "# Descendente\n",
    "df.sort_index(ascending=False)\n",
    "```\n",
    "\n",
    "**Ordenamiento m√∫ltiple:**\n",
    "```python\n",
    "# Orden diferente por columna\n",
    "df.sort_values(\n",
    "    by=['ciudad', 'edad'],\n",
    "    ascending=[True, False]  # Ciudad ‚Üë, Edad ‚Üì\n",
    ")\n",
    "```\n",
    "\n",
    "**Visualizaci√≥n:**\n",
    "```\n",
    "Original:\n",
    "  nombre  edad  ciudad\n",
    "  Carlos  28    Valencia\n",
    "  Ana     25    Madrid\n",
    "  Luis    30    Barcelona\n",
    "\n",
    "sort_values('edad'):\n",
    "  Ana     25    Madrid\n",
    "  Carlos  28    Valencia\n",
    "  Luis    30    Barcelona\n",
    "\n",
    "sort_values('edad', ascending=False):\n",
    "  Luis    30    Barcelona\n",
    "  Carlos  28    Valencia\n",
    "  Ana     25    Madrid\n",
    "```\n",
    "\n",
    "**Par√°metros √∫tiles:**\n",
    "\n",
    "| Par√°metro | Qu√© hace | Ejemplo |\n",
    "|-----------|----------|---------|\n",
    "| `ascending` | Orden ascendente (True) o descendente (False) | `ascending=False` |\n",
    "| `inplace` | Modifica el DataFrame original | `inplace=True` |\n",
    "| `na_position` | D√≥nde poner NaN ('first' o 'last') | `na_position='first'` |\n",
    "| `key` | Funci√≥n para transformar antes de ordenar | `key=lambda x: x.str.lower()` |\n",
    "\n",
    "**Casos de uso comunes:**\n",
    "\n",
    "**1. Top N productos:**\n",
    "```python\n",
    "top_10 = df.sort_values('ventas', ascending=False).head(10)\n",
    "```\n",
    "\n",
    "**2. Cronol√≥gico:**\n",
    "```python\n",
    "df.sort_values('fecha')\n",
    "```\n",
    "\n",
    "**3. Alfab√©tico case-insensitive:**\n",
    "```python\n",
    "df.sort_values('nombre', key=lambda x: x.str.lower())\n",
    "```\n",
    "\n",
    "**4. M√∫ltiples niveles (regi√≥n > ciudad > nombre):**\n",
    "```python\n",
    "df.sort_values(['region', 'ciudad', 'nombre'])\n",
    "```\n",
    "\n",
    "**sort_values vs sort_index:**\n",
    "\n",
    "| Aspecto | sort_values | sort_index |\n",
    "|---------|-------------|------------|\n",
    "| Ordena por | Valores de columnas | Etiquetas del √≠ndice |\n",
    "| Uso com√∫n | Ordenar registros | Reorganizar despu√©s de operaciones |\n",
    "| Ejemplo | Por fecha, precio, nombre | Despu√©s de merge, groupby |\n",
    "\n",
    "**Best practices:**\n",
    "- ‚úÖ **No uses inplace=True** si necesitas el original despu√©s\n",
    "- ‚úÖ **Especifica ascending** expl√≠citamente (claridad)\n",
    "- ‚úÖ **Maneja NaN**: Decide si van primero o √∫ltimo\n",
    "- ‚úÖ **Reset index** despu√©s si el orden del √≠ndice ya no tiene sentido\n",
    "\n",
    "**En este bloque aprender√°s:**\n",
    "1. Ordenar por valores con `sort_values()`\n",
    "2. Orden ascendente vs descendente con `ascending`\n",
    "3. Ordenar por m√∫ltiples columnas\n",
    "4. Diferente orden por columna (algunas ‚Üë, otras ‚Üì)\n",
    "5. Diferencia entre sort_values y sort_index\n",
    "6. Cu√°ndo usar cada tipo de ordenamiento\n",
    "7. Obtener Top N combinando sort + head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5be325b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenaci√≥n vertical\n",
    "df1 = pd.DataFrame({\n",
    "    'id': [1, 2, 3],\n",
    "    'valor': [10, 20, 30]\n",
    "})\n",
    "\n",
    "df2 = pd.DataFrame({\n",
    "    'id': [4, 5, 6],\n",
    "    'valor': [40, 50, 60]\n",
    "})\n",
    "\n",
    "df_concat = pd.concat([df1, df2], ignore_index=True)\n",
    "print(\"Concatenaci√≥n vertical:\")\n",
    "print(df_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038ec37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge (Join)\n",
    "df_productos = pd.DataFrame({\n",
    "    'producto_id': [1, 2, 3, 4],\n",
    "    'nombre': ['Laptop', 'Mouse', 'Teclado', 'Monitor']\n",
    "})\n",
    "\n",
    "df_precios = pd.DataFrame({\n",
    "    'producto_id': [1, 2, 3, 5],\n",
    "    'precio': [1200, 25, 75, 150]\n",
    "})\n",
    "\n",
    "print(\"Productos:\")\n",
    "print(df_productos)\n",
    "print(\"\\nPrecios:\")\n",
    "print(df_precios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c12bbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inner join\n",
    "df_inner = pd.merge(df_productos, df_precios, on='producto_id', how='inner')\n",
    "print(\"Inner Join:\")\n",
    "print(df_inner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d7c5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Left join\n",
    "df_left = pd.merge(df_productos, df_precios, on='producto_id', how='left')\n",
    "print(\"Left Join:\")\n",
    "print(df_left)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd2a2b4",
   "metadata": {},
   "source": [
    "## 9. Visualizaci√≥n con Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b699578e",
   "metadata": {},
   "source": [
    "### üìñ Combinar DataFrames - Concat y Merge\n",
    "\n",
    "**¬øPor qu√© combinar DataFrames?**\n",
    "En el mundo real, los datos est√°n **fragmentados**:\n",
    "- Ventas de enero en un archivo, febrero en otro ‚Üí **Concat**\n",
    "- Datos de clientes en una tabla, pedidos en otra ‚Üí **Merge/Join**\n",
    "- M√∫ltiples fuentes que necesitan integrarse\n",
    "\n",
    "**Dos operaciones principales:**\n",
    "\n",
    "## 1. Concatenaci√≥n (pd.concat) - Apilar datos\n",
    "\n",
    "**¬øCu√°ndo usar?**\n",
    "Cuando tienes **la misma estructura** pero diferentes registros:\n",
    "- Datos mensuales ‚Üí Combinar en dataset anual\n",
    "- M√∫ltiples archivos del mismo formato\n",
    "- Agregar filas nuevas a un DataFrame\n",
    "\n",
    "**Sintaxis:**\n",
    "```python\n",
    "pd.concat([df1, df2], axis=0)  # Vertical (apilar filas)\n",
    "pd.concat([df1, df2], axis=1)  # Horizontal (a√±adir columnas)\n",
    "```\n",
    "\n",
    "**Visualizaci√≥n (axis=0):**\n",
    "```\n",
    "df1:              df2:              Resultado:\n",
    "  id  nombre        id  nombre        id  nombre\n",
    "  1   Ana           3   Carlos        1   Ana\n",
    "  2   Luis          4   Mar√≠a         2   Luis\n",
    "                                      3   Carlos\n",
    "                                      4   Mar√≠a\n",
    "```\n",
    "\n",
    "**Par√°metros √∫tiles:**\n",
    "- `ignore_index=True`: Reinicia el √≠ndice (0, 1, 2...)\n",
    "- `keys=['ene', 'feb']`: A√±ade nivel jer√°rquico al √≠ndice\n",
    "\n",
    "## 2. Merge (pd.merge) - Joins tipo SQL\n",
    "\n",
    "**¬øCu√°ndo usar?**\n",
    "Cuando necesitas **relacionar** datos por una clave com√∫n:\n",
    "- Clientes + Pedidos (ambos tienen `customer_id`)\n",
    "- Productos + Categor√≠as (ambos tienen `category_id`)\n",
    "- Usuarios + Transacciones\n",
    "\n",
    "**Tipos de joins:**\n",
    "\n",
    "| Tipo | SQL | Pandas | Qu√© hace |\n",
    "|------|-----|--------|----------|\n",
    "| **Inner** | INNER JOIN | `how='inner'` | Solo matches (intersecci√≥n) |\n",
    "| **Left** | LEFT JOIN | `how='left'` | Todas de izquierda + matches |\n",
    "| **Right** | RIGHT JOIN | `how='right'` | Todas de derecha + matches |\n",
    "| **Outer** | FULL OUTER JOIN | `how='outer'` | Todas (uni√≥n) |\n",
    "\n",
    "**Sintaxis:**\n",
    "```python\n",
    "pd.merge(\n",
    "    df_left,\n",
    "    df_right,\n",
    "    on='columna_comun',  # Columna para unir\n",
    "    how='inner'          # Tipo de join\n",
    ")\n",
    "```\n",
    "\n",
    "**Ejemplo visual (Inner Join):**\n",
    "```\n",
    "df_clientes:          df_pedidos:           Resultado:\n",
    "  id  nombre            id_cliente  total     id  nombre  total\n",
    "  1   Ana               1           100       1   Ana     100\n",
    "  2   Luis              2           200       2   Luis    200\n",
    "  3   Carlos            1           150       1   Ana     150\n",
    "```\n",
    "\n",
    "**Diferencia entre on, left_on, right_on:**\n",
    "\n",
    "```python\n",
    "# Columnas con mismo nombre\n",
    "pd.merge(df1, df2, on='id')\n",
    "\n",
    "# Columnas con diferente nombre\n",
    "pd.merge(df1, df2, left_on='customer_id', right_on='id')\n",
    "\n",
    "# M√∫ltiples columnas\n",
    "pd.merge(df1, df2, on=['region', 'fecha'])\n",
    "```\n",
    "\n",
    "**Comparaci√≥n Concat vs Merge:**\n",
    "\n",
    "| Aspecto | Concat | Merge |\n",
    "|---------|--------|-------|\n",
    "| Prop√≥sito | Apilar/juntar | Relacionar |\n",
    "| Estructura | Misma | Puede ser diferente |\n",
    "| Operaci√≥n | Union/Append | Join |\n",
    "| Clave | No necesaria | Requiere columna com√∫n |\n",
    "| SQL equivalente | UNION | JOIN |\n",
    "\n",
    "**Casos de uso:**\n",
    "\n",
    "**Concat - Agregar datos hist√≥ricos:**\n",
    "```python\n",
    "# Archivos mensuales\n",
    "df_jan = pd.read_csv('ventas_enero.csv')\n",
    "df_feb = pd.read_csv('ventas_febrero.csv')\n",
    "df_q1 = pd.concat([df_jan, df_feb], ignore_index=True)\n",
    "```\n",
    "\n",
    "**Merge - Enriquecer con informaci√≥n relacionada:**\n",
    "```python\n",
    "# A√±adir nombres de clientes a pedidos\n",
    "pedidos_enriquecidos = pd.merge(\n",
    "    df_pedidos,\n",
    "    df_clientes[['id', 'nombre']],\n",
    "    left_on='customer_id',\n",
    "    right_on='id',\n",
    "    how='left'\n",
    ")\n",
    "```\n",
    "\n",
    "**En este bloque aprender√°s:**\n",
    "1. Concatenar DataFrames verticalmente con `pd.concat()`\n",
    "2. Par√°metro `axis`: 0 para filas, 1 para columnas\n",
    "3. Usar `ignore_index=True` para reiniciar √≠ndice\n",
    "4. Hacer joins con `pd.merge()`\n",
    "5. Tipos de joins: inner, left, right, outer\n",
    "6. Especificar columnas de join con `on`, `left_on`, `right_on`\n",
    "7. Cu√°ndo usar concat vs merge\n",
    "8. Visualizar resultados de diferentes tipos de joins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d98c929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gr√°ficos b√°sicos\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Gr√°fico de barras\n",
    "ventas_por_categoria.plot(kind='bar', ax=axes[0, 0], color='skyblue')\n",
    "axes[0, 0].set_title('Ventas Totales por Categor√≠a')\n",
    "axes[0, 0].set_ylabel('Total ($)')\n",
    "\n",
    "# Gr√°fico de l√≠neas\n",
    "df_transacciones.groupby('fecha')['total'].sum().plot(ax=axes[0, 1], color='green')\n",
    "axes[0, 1].set_title('Evoluci√≥n de Ventas Diarias')\n",
    "axes[0, 1].set_ylabel('Total ($)')\n",
    "\n",
    "# Histograma\n",
    "df_transacciones['precio'].plot(kind='hist', bins=20, ax=axes[1, 0], color='coral')\n",
    "axes[1, 0].set_title('Distribuci√≥n de Precios')\n",
    "axes[1, 0].set_xlabel('Precio')\n",
    "\n",
    "# Box plot\n",
    "df_transacciones.boxplot(column='total', by='categoria', ax=axes[1, 1])\n",
    "axes[1, 1].set_title('Distribuci√≥n de Ventas por Categor√≠a')\n",
    "axes[1, 1].set_ylabel('Total ($)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465460c2",
   "metadata": {},
   "source": [
    "## 10. Ejercicios Pr√°cticos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce775c8",
   "metadata": {},
   "source": [
    "### üìñ Visualizaci√≥n R√°pida con Pandas\n",
    "\n",
    "**¬øPor qu√© pandas tiene plotting integrado?**\n",
    "Para **exploraci√≥n r√°pida** sin salir del flujo de an√°lisis:\n",
    "- No necesitas importar matplotlib para gr√°ficos simples\n",
    "- Sintaxis m√°s corta: `df.plot()` vs configurar matplotlib\n",
    "- Perfecto para an√°lisis exploratorio (EDA)\n",
    "\n",
    "**Integraci√≥n con matplotlib:**\n",
    "Pandas usa matplotlib por detr√°s, as√≠ que puedes:\n",
    "- Personalizar con comandos de matplotlib\n",
    "- Combinar ambas bibliotecas\n",
    "- Todo lo que funciona en matplotlib funciona aqu√≠\n",
    "\n",
    "**Tipos de gr√°ficos disponibles:**\n",
    "\n",
    "| Tipo | M√©todo | Cu√°ndo usar |\n",
    "|------|--------|-------------|\n",
    "| **Line** | `.plot()` o `.plot(kind='line')` | Tendencias temporales |\n",
    "| **Bar** | `.plot(kind='bar')` | Comparar categor√≠as |\n",
    "| **Histogram** | `.plot(kind='hist')` | Distribuci√≥n de valores |\n",
    "| **Box** | `.plot(kind='box')` | Detectar outliers, cuartiles |\n",
    "| **Scatter** | `.plot(kind='scatter')` | Relaci√≥n entre 2 variables |\n",
    "| **Pie** | `.plot(kind='pie')` | Proporciones (evitar si >5 categor√≠as) |\n",
    "| **Area** | `.plot(kind='area')` | Tendencias apiladas |\n",
    "\n",
    "**Sintaxis general:**\n",
    "```python\n",
    "df['columna'].plot(\n",
    "    kind='bar',           # Tipo de gr√°fico\n",
    "    title='T√≠tulo',       # T√≠tulo\n",
    "    figsize=(10, 6),      # Tama√±o (ancho, alto)\n",
    "    color='steelblue',    # Color\n",
    "    legend=True           # Mostrar leyenda\n",
    ")\n",
    "plt.ylabel('Eje Y')\n",
    "plt.xlabel('Eje X')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "**Ejemplos r√°pidos:**\n",
    "\n",
    "**Histograma (distribuci√≥n):**\n",
    "```python\n",
    "df['edad'].plot(kind='hist', bins=20, title='Distribuci√≥n de Edades')\n",
    "```\n",
    "\n",
    "**Line chart (temporal):**\n",
    "```python\n",
    "df.groupby('fecha')['ventas'].sum().plot(title='Ventas Diarias')\n",
    "```\n",
    "\n",
    "**Bar chart (categor√≠as):**\n",
    "```python\n",
    "df['categoria'].value_counts().plot(kind='bar', title='Productos por Categor√≠a')\n",
    "```\n",
    "\n",
    "**Scatter (correlaci√≥n):**\n",
    "```python\n",
    "df.plot(kind='scatter', x='precio', y='ventas', alpha=0.5)\n",
    "```\n",
    "\n",
    "**Box plot (outliers):**\n",
    "```python\n",
    "df[['edad', 'salario']].plot(kind='box')\n",
    "```\n",
    "\n",
    "**Personalizaci√≥n com√∫n:**\n",
    "\n",
    "```python\n",
    "# Tama√±o de figura\n",
    "df.plot(figsize=(12, 6))\n",
    "\n",
    "# Colores personalizados\n",
    "df.plot(color=['red', 'blue', 'green'])\n",
    "\n",
    "# Rotaci√≥n de labels\n",
    "df.plot(kind='bar')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Grid\n",
    "df.plot(grid=True)\n",
    "\n",
    "# Estilo\n",
    "plt.style.use('ggplot')\n",
    "df.plot()\n",
    "```\n",
    "\n",
    "**M√∫ltiples subplots:**\n",
    "```python\n",
    "df.plot(subplots=True, layout=(2, 2), figsize=(12, 8))\n",
    "```\n",
    "\n",
    "**Best practices:**\n",
    "- ‚úÖ **T√≠tulos claros**: Qu√© muestra el gr√°fico\n",
    "- ‚úÖ **Etiquetas con unidades**: \"$\", \"%\", \"kg\", etc.\n",
    "- ‚úÖ **Tama√±o apropiado**: `figsize=(10, 6)` para legibilidad\n",
    "- ‚úÖ **Colores consistentes**: Usa paletas profesionales\n",
    "- ‚ö†Ô∏è **No abuses de pie charts**: Barras son m√°s claras\n",
    "- ‚ö†Ô∏è **Cuidado con histogramas**: Ajusta `bins` seg√∫n datos\n",
    "\n",
    "**Cu√°ndo usar pandas.plot vs matplotlib puro:**\n",
    "\n",
    "| Usa pandas.plot cuando | Usa matplotlib cuando |\n",
    "|-------------------------|----------------------|\n",
    "| Exploraci√≥n r√°pida | Presentaci√≥n final |\n",
    "| Prototipado | Personalizaci√≥n extrema |\n",
    "| Gr√°ficos simples | M√∫ltiples fuentes de datos |\n",
    "| Trabajas con Series/DataFrame | Necesitas control total |\n",
    "\n",
    "**En este bloque aprender√°s:**\n",
    "1. Crear gr√°ficos directamente desde DataFrames con `.plot()`\n",
    "2. Diferentes tipos con `kind=`: bar, hist, scatter, box\n",
    "3. Personalizar con par√°metros: figsize, title, color\n",
    "4. Combinar pandas.plot con matplotlib para detalles\n",
    "5. Cu√°ndo usar cada tipo de gr√°fico\n",
    "6. Shortcuts para an√°lisis exploratorio r√°pido\n",
    "7. Generar m√∫ltiples gr√°ficos con subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c5445a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejercicio 1: An√°lisis de ventas mensuales\n",
    "print(\"=== Ejercicio 1: An√°lisis de Ventas Mensuales ===\")\n",
    "\n",
    "# Agregar columna de mes\n",
    "df_transacciones['mes'] = df_transacciones['fecha'].dt.month\n",
    "df_transacciones['mes_nombre'] = df_transacciones['fecha'].dt.month_name()\n",
    "\n",
    "# Ventas por mes\n",
    "ventas_mensuales = df_transacciones.groupby('mes_nombre')['total'].agg([\n",
    "    ('total', 'sum'),\n",
    "    ('promedio', 'mean'),\n",
    "    ('transacciones', 'count')\n",
    "])\n",
    "\n",
    "print(ventas_mensuales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53760b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejercicio 2: Top 5 productos m√°s vendidos\n",
    "print(\"=== Ejercicio 2: Top 5 Productos ===\")\n",
    "\n",
    "top_productos = df_transacciones.groupby('producto').agg({\n",
    "    'cantidad': 'sum',\n",
    "    'total': 'sum'\n",
    "}).sort_values('total', ascending=False).head(5)\n",
    "\n",
    "print(top_productos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9859cb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejercicio 3: An√°lisis por regi√≥n\n",
    "print(\"=== Ejercicio 3: Rendimiento por Regi√≥n ===\")\n",
    "\n",
    "analisis_region = df_transacciones.groupby('region').agg({\n",
    "    'total': ['sum', 'mean', 'count'],\n",
    "    'cantidad': 'sum'\n",
    "})\n",
    "\n",
    "analisis_region.columns = ['_'.join(col) for col in analisis_region.columns]\n",
    "analisis_region = analisis_region.sort_values('total_sum', ascending=False)\n",
    "\n",
    "print(analisis_region)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f71b5f7",
   "metadata": {},
   "source": [
    "## Resumen y Mejores Pr√°cticas\n",
    "\n",
    "### Puntos Clave:\n",
    "1. **Series y DataFrames**: Estructuras fundamentales de pandas\n",
    "2. **Selecci√≥n**: Usar `loc` para etiquetas, `iloc` para posiciones\n",
    "3. **Filtrado**: Combinar condiciones con `&` (AND) y `|` (OR)\n",
    "4. **Agrupaciones**: `groupby()` para an√°lisis agregado\n",
    "5. **Datos faltantes**: Detectar con `isnull()`, manejar con `fillna()` o `dropna()`\n",
    "6. **Duplicados**: Detectar con `duplicated()`, eliminar con `drop_duplicates()`\n",
    "\n",
    "### Mejores Pr√°cticas:\n",
    "- Siempre explorar los datos con `head()`, `info()`, `describe()`\n",
    "- Verificar tipos de datos antes de operaciones\n",
    "- Manejar valores faltantes apropiadamente seg√∫n el contexto\n",
    "- Usar nombres descriptivos para variables\n",
    "- Documentar transformaciones complejas\n",
    "- Validar resultados despu√©s de cada transformaci√≥n\n",
    "\n",
    "### Recursos Adicionales:\n",
    "- [Documentaci√≥n oficial de Pandas](https://pandas.pydata.org/docs/)\n",
    "- [10 minutes to pandas](https://pandas.pydata.org/docs/user_guide/10min.html)\n",
    "- [Pandas Cheat Sheet](https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
