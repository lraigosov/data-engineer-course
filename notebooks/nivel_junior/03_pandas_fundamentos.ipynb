{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37391fb6",
   "metadata": {},
   "source": [
    "# Pandas: Fundamentos para An\u00e1lisis de Datos\n",
    "\n",
    "## Objetivos de Aprendizaje\n",
    "- Dominar las estructuras de datos de Pandas (Series y DataFrame)\n",
    "- Realizar operaciones de lectura y escritura de datos\n",
    "- Manipular y transformar DataFrames eficientemente\n",
    "- Aplicar filtros, agrupaciones y agregaciones\n",
    "- Trabajar con datos faltantes y duplicados\n",
    "\n",
    "## Requisitos\n",
    "- Python 3.8+\n",
    "- pandas\n",
    "- numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088f2f06",
   "metadata": {},
   "source": [
    "### \ud83d\udcd6 Importando Pandas - La Biblioteca M\u00e1s Importante\n",
    "\n",
    "**\u00bfQu\u00e9 es pandas?**\n",
    "Pandas es **LA biblioteca fundamental** para Data Engineering y Data Science en Python. Es como tener:\n",
    "- Excel con superpoderes\n",
    "- SQL dentro de Python\n",
    "- Herramientas de an\u00e1lisis de datos profesionales\n",
    "\n",
    "**\u00bfPor qu\u00e9 `import pandas as pd`?**\n",
    "- **`pd` es el alias universal**: TODO el mundo lo usa\n",
    "- **Convenio establecido**: Como `import numpy as np`\n",
    "- **M\u00e1s r\u00e1pido de escribir**: `pd.DataFrame()` vs `pandas.DataFrame()`\n",
    "\n",
    "**\u00bfQu\u00e9 puedes hacer con pandas?**\n",
    "1. **Leer datos**: CSV, Excel, JSON, SQL, Parquet, HTML\n",
    "2. **Manipular**: Filtrar, transformar, agrupar, pivotar\n",
    "3. **Limpiar**: Manejar nulos, duplicados, tipos de datos\n",
    "4. **Analizar**: Estad\u00edsticas, agregaciones, series temporales\n",
    "5. **Exportar**: Guardar en m\u00faltiples formatos\n",
    "\n",
    "**Estructuras principales:**\n",
    "\n",
    "| Estructura | Dimensi\u00f3n | Descripci\u00f3n | Analog\u00eda |\n",
    "|------------|-----------|-------------|----------|\n",
    "| **Series** | 1D | Array etiquetado | Una columna de Excel |\n",
    "| **DataFrame** | 2D | Tabla con filas y columnas | Hoja de Excel completa |\n",
    "\n",
    "**En este bloque:**\n",
    "Simplemente importamos pandas con el alias est\u00e1ndar `pd`. Esto hace que toda la funcionalidad de pandas est\u00e9 disponible en tu notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b11195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalaci\u00f3n de dependencias\n",
    "import sys\n",
    "!{sys.executable} -m pip install pandas numpy matplotlib seaborn -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa59b80f",
   "metadata": {},
   "source": [
    "### \ud83d\udcd6 Series - La Estructura 1D de Pandas\n",
    "\n",
    "**\u00bfQu\u00e9 es una Series?**\n",
    "Es un **array unidimensional etiquetado** - como una columna de Excel con esteroides:\n",
    "- Tiene **valores** (los datos)\n",
    "- Tiene **\u00edndice** (etiquetas para cada valor)\n",
    "- Tiene **tipo de dato** homog\u00e9neo (todos int, todos float, etc.)\n",
    "\n",
    "**Diferencias clave con listas de Python:**\n",
    "\n",
    "| Caracter\u00edstica | Lista Python | Pandas Series |\n",
    "|----------------|--------------|---------------|\n",
    "| \u00cdndice | Num\u00e9rico solo (0, 1, 2...) | Cualquier cosa (nombres, fechas, etc.) |\n",
    "| Tipos | Mixtos | Homog\u00e9neo (optimizado) |\n",
    "| Operaciones vectorizadas | \u274c No | \u2705 S\u00ed (s\u00faper r\u00e1pido) |\n",
    "| M\u00e9todos estad\u00edsticos | \u274c No | \u2705 mean(), std(), etc. |\n",
    "\n",
    "**Anatom\u00eda de una Series:**\n",
    "```python\n",
    "s = pd.Series([10, 20, 30, 40])\n",
    "\n",
    "# Tiene 3 componentes:\n",
    "# 1. Valores: [10, 20, 30, 40]\n",
    "# 2. \u00cdndice: [0, 1, 2, 3] (auto-generado)\n",
    "# 3. Tipo: dtype('int64')\n",
    "```\n",
    "\n",
    "**Visualizaci\u00f3n:**\n",
    "```\n",
    "0    10     \u2190 \u00edndice 0, valor 10\n",
    "1    20     \u2190 \u00edndice 1, valor 20\n",
    "2    30     \u2190 \u00edndice 2, valor 30\n",
    "3    40     \u2190 \u00edndice 3, valor 40\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "**Creaci\u00f3n b\u00e1sica:**\n",
    "```python\n",
    "# Desde lista\n",
    "s = pd.Series([1, 2, 3, 4, 5])\n",
    "\n",
    "# Desde diccionario (las claves se vuelven \u00edndice)\n",
    "s = pd.Series({'a': 100, 'b': 200, 'c': 300})\n",
    "\n",
    "# Con \u00edndice personalizado\n",
    "s = pd.Series([10, 20, 30], index=['x', 'y', 'z'])\n",
    "```\n",
    "\n",
    "**\u00bfCu\u00e1ndo usar Series?**\n",
    "- Representar **una columna** de datos\n",
    "- Trabajar con **series temporales** (precios de acciones)\n",
    "- Operar sobre **un atributo** (edades, salarios, etc.)\n",
    "\n",
    "**En este bloque ver\u00e1s:**\n",
    "1. Crear Series desde listas simples\n",
    "2. Acceder a valores con \u00edndice num\u00e9rico\n",
    "3. La estructura b\u00e1sica: valores + \u00edndice + dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68168ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Configuraci\u00f3n\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8219c653",
   "metadata": {},
   "source": [
    "## 1. Series de Pandas\n",
    "\n",
    "Una Series es un array unidimensional etiquetado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df71f02b",
   "metadata": {},
   "source": [
    "### \ud83d\udcd6 DataFrames - Tablas con Superpoderes\n",
    "\n",
    "**\u00bfQu\u00e9 es un DataFrame?**\n",
    "Es la **estructura 2D** (filas \u00d7 columnas) m\u00e1s importante de pandas:\n",
    "- Piensa en una **hoja de Excel**\n",
    "- O una **tabla SQL**\n",
    "- Cada columna es una Series\n",
    "- Cada fila es un registro\n",
    "\n",
    "**Anatom\u00eda de un DataFrame:**\n",
    "```\n",
    "       nombre  edad  ciudad      \u2190 Columnas (headers)\n",
    "    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
    "  0 \u2502 Ana      25    Madrid     \u2190 Fila 0 (\u00edndice)\n",
    "  1 \u2502 Luis     30    Barcelona  \u2190 Fila 1\n",
    "  2 \u2502 Carlos   28    Valencia   \u2190 Fila 2\n",
    "    \u2514\n",
    "    \u2191\n",
    "  \u00cdndice\n",
    "```\n",
    "\n",
    "**Formas de crear un DataFrame:**\n",
    "\n",
    "**1. Desde diccionario de listas (COM\u00daN - orientado a columnas):**\n",
    "```python\n",
    "data = {\n",
    "    'nombre': ['Ana', 'Luis', 'Carlos'],\n",
    "    'edad': [25, 30, 28]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "```\n",
    "\n",
    "**2. Desde lista de diccionarios (orientado a filas):**\n",
    "```python\n",
    "data = [\n",
    "    {'nombre': 'Ana', 'edad': 25},\n",
    "    {'nombre': 'Luis', 'edad': 30}\n",
    "]\n",
    "df = pd.DataFrame(data)\n",
    "```\n",
    "\n",
    "**3. Desde archivo (CSV, Excel, JSON, SQL, etc.):**\n",
    "```python\n",
    "df = pd.read_csv('datos.csv')\n",
    "df = pd.read_excel('datos.xlsx')\n",
    "df = pd.read_json('datos.json')\n",
    "df = pd.read_sql('SELECT * FROM tabla', conexion)\n",
    "```\n",
    "\n",
    "**Componentes de un DataFrame:**\n",
    "- **Columnas**: Atributos/caracter\u00edsticas (nombre, edad, precio, etc.)\n",
    "- **\u00cdndice**: Identificador de cada fila (0, 1, 2... o personalizado)\n",
    "- **Valores**: Los datos en s\u00ed\n",
    "- **dtype por columna**: Cada columna tiene su tipo (int, float, object, datetime)\n",
    "\n",
    "**Propiedades \u00fatiles:**\n",
    "```python\n",
    "df.shape         # (num_filas, num_columnas)\n",
    "df.columns       # Nombres de columnas\n",
    "df.index         # \u00cdndice\n",
    "df.dtypes        # Tipos de datos por columna\n",
    "df.size          # Total de celdas\n",
    "df.ndim          # Dimensiones (siempre 2)\n",
    "```\n",
    "\n",
    "**En este bloque aprender\u00e1s:**\n",
    "1. Crear DataFrames desde diccionarios\n",
    "2. Entender la estructura tabular\n",
    "3. Ver \u00edndice autom\u00e1tico vs personalizado\n",
    "4. La relaci\u00f3n entre diccionarios Python y DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cf0973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una Series desde una lista\n",
    "ventas = pd.Series([100, 150, 200, 175, 225], name='ventas_diarias')\n",
    "print(\"Series b\u00e1sica:\")\n",
    "print(ventas)\n",
    "print(f\"\\nTipo: {type(ventas)}\")\n",
    "print(f\"Shape: {ventas.shape}\")\n",
    "print(f\"Dtype: {ventas.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6e497b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Series con \u00edndice personalizado\n",
    "temperaturas = pd.Series(\n",
    "    data=[22, 25, 28, 26, 24],\n",
    "    index=['Lunes', 'Martes', 'Mi\u00e9rcoles', 'Jueves', 'Viernes'],\n",
    "    name='temperatura_celsius'\n",
    ")\n",
    "print(\"Series con \u00edndice personalizado:\")\n",
    "print(temperaturas)\n",
    "print(f\"\\nAcceso por \u00edndice: Mi\u00e9rcoles = {temperaturas['Mi\u00e9rcoles']}\u00b0C\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619527f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Operaciones con Series\n",
    "print(\"Estad\u00edsticas descriptivas:\")\n",
    "print(f\"Media: {temperaturas.mean():.2f}\u00b0C\")\n",
    "print(f\"Mediana: {temperaturas.median()}\u00b0C\")\n",
    "print(f\"Desviaci\u00f3n est\u00e1ndar: {temperaturas.std():.2f}\u00b0C\")\n",
    "print(f\"M\u00ednimo: {temperaturas.min()}\u00b0C\")\n",
    "print(f\"M\u00e1ximo: {temperaturas.max()}\u00b0C\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7730787e",
   "metadata": {},
   "source": [
    "## 2. DataFrames: La estructura principal\n",
    "\n",
    "Un DataFrame es una estructura bidimensional con columnas que pueden ser de diferentes tipos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869e76af",
   "metadata": {},
   "source": [
    "### \ud83d\udcd6 Selecci\u00f3n de Datos - Accediendo a lo que Necesitas\n",
    "\n",
    "**\u00bfPor qu\u00e9 es importante?**\n",
    "En Data Engineering, rara vez trabajas con TODO el dataset:\n",
    "- Necesitas **columnas espec\u00edficas** para an\u00e1lisis\n",
    "- Filtras **filas que cumplen condiciones**\n",
    "- Extraes **un subconjunto** para procesar\n",
    "\n",
    "**4 formas principales de seleccionar:**\n",
    "\n",
    "**1. Por nombre de columna:**\n",
    "```python\n",
    "df['nombre']           # Una columna \u2192 Series\n",
    "df[['nombre', 'edad']] # M\u00faltiples columnas \u2192 DataFrame\n",
    "```\n",
    "\n",
    "**2. Con `.loc[]` (label-based - por etiqueta):**\n",
    "```python\n",
    "df.loc[0]              # Fila con \u00edndice 0\n",
    "df.loc[0:2]            # Filas 0, 1, 2 (inclusivo!)\n",
    "df.loc[0, 'nombre']    # Celda espec\u00edfica\n",
    "```\n",
    "\n",
    "**3. Con `.iloc[]` (integer position-based - por posici\u00f3n):**\n",
    "```python\n",
    "df.iloc[0]             # Primera fila\n",
    "df.iloc[0:2]           # Filas 0, 1 (exclusivo!)\n",
    "df.iloc[0, 1]          # Fila 0, columna 1\n",
    "```\n",
    "\n",
    "**4. Filtrado booleano:**\n",
    "```python\n",
    "df[df['edad'] > 25]    # Filas donde edad > 25\n",
    "```\n",
    "\n",
    "**Diferencia clave loc vs iloc:**\n",
    "\n",
    "| Aspecto | `.loc[]` | `.iloc[]` |\n",
    "|---------|----------|-----------|\n",
    "| Tipo | Basado en etiquetas | Basado en posici\u00f3n |\n",
    "| \u00cdndice | Usa nombres/\u00edndice | Usa n\u00fameros (0, 1, 2...) |\n",
    "| Slicing | Inclusivo `[0:2]` incluye 2 | Exclusivo `[0:2]` excluye 2 |\n",
    "| Ejemplo | `df.loc['fila_A']` | `df.iloc[0]` |\n",
    "\n",
    "**En este bloque ver\u00e1s:**\n",
    "1. Seleccionar una columna con `df['columna']`\n",
    "2. Seleccionar m\u00faltiples columnas con doble corchete\n",
    "3. Usar `.loc[]` para acceso por etiqueta\n",
    "4. Usar `.iloc[]` para acceso por posici\u00f3n num\u00e9rica\n",
    "5. La diferencia sutil pero importante entre ambos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc2d875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear DataFrame desde diccionario\n",
    "datos_ventas = {\n",
    "    'producto': ['Laptop', 'Mouse', 'Teclado', 'Monitor', 'Webcam'],\n",
    "    'cantidad': [5, 25, 15, 8, 12],\n",
    "    'precio_unitario': [1200, 25, 75, 300, 80],\n",
    "    'categoria': ['Computadoras', 'Accesorios', 'Accesorios', 'Computadoras', 'Accesorios']\n",
    "}\n",
    "\n",
    "df_ventas = pd.DataFrame(datos_ventas)\n",
    "print(\"DataFrame de ventas:\")\n",
    "print(df_ventas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7603e7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Informaci\u00f3n del DataFrame\n",
    "print(\"Informaci\u00f3n del DataFrame:\")\n",
    "print(f\"Shape: {df_ventas.shape}\")\n",
    "print(f\"Columnas: {df_ventas.columns.tolist()}\")\n",
    "print(f\"\\nTipos de datos:\")\n",
    "print(df_ventas.dtypes)\n",
    "print(f\"\\nInformaci\u00f3n detallada:\")\n",
    "df_ventas.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa396e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear nueva columna calculada\n",
    "df_ventas['total_venta'] = df_ventas['cantidad'] * df_ventas['precio_unitario']\n",
    "print(\"DataFrame con columna calculada:\")\n",
    "print(df_ventas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbdfe07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estad\u00edsticas descriptivas\n",
    "print(\"Estad\u00edsticas del DataFrame:\")\n",
    "print(df_ventas.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5864a856",
   "metadata": {},
   "source": [
    "## 3. Selecci\u00f3n y Filtrado de Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57cd004",
   "metadata": {},
   "source": [
    "### \ud83d\udcd6 Filtrado Booleano - El Poder de las Condiciones\n",
    "\n",
    "**\u00bfQu\u00e9 es el filtrado booleano?**\n",
    "Es usar **condiciones l\u00f3gicas** para seleccionar solo las filas que cumplen criterios:\n",
    "- \u00bfClientes mayores de 18 a\u00f1os?\n",
    "- \u00bfVentas superiores a $1000?\n",
    "- \u00bfProductos en stock?\n",
    "\n",
    "**Sintaxis b\u00e1sica:**\n",
    "```python\n",
    "df[df['columna'] > valor]\n",
    "```\n",
    "\n",
    "**C\u00f3mo funciona (paso a paso):**\n",
    "```python\n",
    "# 1. La condici\u00f3n crea una Series booleana\n",
    "df['edad'] > 25\n",
    "# Retorna: [False, True, True, False...]\n",
    "\n",
    "# 2. Esa Series se usa como m\u00e1scara\n",
    "df[df['edad'] > 25]\n",
    "# Solo las filas donde es True pasan\n",
    "```\n",
    "\n",
    "**Operadores de comparaci\u00f3n:**\n",
    "\n",
    "| Operador | Significado | Ejemplo |\n",
    "|----------|-------------|---------|\n",
    "| `==` | Igual a | `df['ciudad'] == 'Madrid'` |\n",
    "| `!=` | Diferente de | `df['status'] != 'activo'` |\n",
    "| `>` | Mayor que | `df['precio'] > 100` |\n",
    "| `<` | Menor que | `df['stock'] < 10` |\n",
    "| `>=` | Mayor o igual | `df['edad'] >= 18` |\n",
    "| `<=` | Menor o igual | `df['descuento'] <= 0.5` |\n",
    "\n",
    "**Filtros compuestos (m\u00faltiples condiciones):**\n",
    "\n",
    "**AND (ambas deben cumplirse):**\n",
    "```python\n",
    "df[(df['edad'] > 25) & (df['ciudad'] == 'Madrid')]\n",
    "```\n",
    "\n",
    "**OR (al menos una debe cumplirse):**\n",
    "```python\n",
    "df[(df['edad'] > 60) | (df['edad'] < 18)]\n",
    "```\n",
    "\n",
    "**NOT (negaci\u00f3n):**\n",
    "```python\n",
    "df[~(df['ciudad'] == 'Madrid')]  # Todo menos Madrid\n",
    "```\n",
    "\n",
    "**\u26a0\ufe0f IMPORTANTE:**\n",
    "- Usa `&` (AND) y `|` (OR), NO `and` y `or`\n",
    "- Envuelve cada condici\u00f3n en par\u00e9ntesis: `(condicion1) & (condicion2)`\n",
    "\n",
    "**M\u00e9todos \u00fatiles con strings:**\n",
    "```python\n",
    "# Contiene substring\n",
    "df[df['nombre'].str.contains('Ana')]\n",
    "\n",
    "# Empieza con\n",
    "df[df['email'].str.startswith('admin')]\n",
    "\n",
    "# Est\u00e1 en lista\n",
    "df[df['ciudad'].isin(['Madrid', 'Barcelona'])]\n",
    "```\n",
    "\n",
    "**En este bloque aprender\u00e1s:**\n",
    "1. Crear condiciones booleanas con operadores de comparaci\u00f3n\n",
    "2. Usar `&` (AND) y `|` (OR) para combinar condiciones\n",
    "3. El m\u00e9todo `.isin()` para buscar en listas\n",
    "4. Por qu\u00e9 necesitas par\u00e9ntesis en filtros compuestos\n",
    "5. C\u00f3mo funcionan las m\u00e1scaras booleanas internamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36badc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar columnas\n",
    "print(\"Selecci\u00f3n de una columna:\")\n",
    "print(df_ventas['producto'])\n",
    "print(f\"\\nTipo: {type(df_ventas['producto'])}\")\n",
    "\n",
    "print(\"\\nSelecci\u00f3n de m\u00faltiples columnas:\")\n",
    "print(df_ventas[['producto', 'total_venta']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9017fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrado con condiciones\n",
    "print(\"Productos con ventas mayores a $1000:\")\n",
    "ventas_altas = df_ventas[df_ventas['total_venta'] > 1000]\n",
    "print(ventas_altas)\n",
    "\n",
    "print(\"\\nProductos de categor\u00eda 'Accesorios':\")\n",
    "accesorios = df_ventas[df_ventas['categoria'] == 'Accesorios']\n",
    "print(accesorios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598bee4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrado con m\u00faltiples condiciones\n",
    "print(\"Accesorios con ventas mayores a $500:\")\n",
    "filtro_complejo = df_ventas[\n",
    "    (df_ventas['categoria'] == 'Accesorios') & \n",
    "    (df_ventas['total_venta'] > 500)\n",
    "]\n",
    "print(filtro_complejo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62f5bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uso de loc e iloc\n",
    "print(\"Uso de loc (etiquetas):\")\n",
    "print(df_ventas.loc[0:2, ['producto', 'cantidad']])\n",
    "\n",
    "print(\"\\nUso de iloc (posiciones):\")\n",
    "print(df_ventas.iloc[0:3, 0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02770366",
   "metadata": {},
   "source": [
    "## 4. Agrupaciones y Agregaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077852ab",
   "metadata": {},
   "source": [
    "### \ud83d\udcd6 Operaciones con Columnas - Transformando Datos\n",
    "\n",
    "**\u00bfPor qu\u00e9 crear nuevas columnas?**\n",
    "Los datos crudos rara vez tienen TODO lo que necesitas:\n",
    "- Calcular **m\u00e9tricas derivadas** (total = cantidad \u00d7 precio)\n",
    "- Aplicar **reglas de negocio** (descuento si precio > 100)\n",
    "- Crear **categor\u00edas** (edad \u2192 'joven', 'adulto', 'senior')\n",
    "- Convertir **unidades** (temperatura \u00b0C \u2192 \u00b0F)\n",
    "\n",
    "**Formas de crear columnas:**\n",
    "\n",
    "**1. Operaciones aritm\u00e9ticas:**\n",
    "```python\n",
    "df['total'] = df['cantidad'] * df['precio']\n",
    "df['precio_con_iva'] = df['precio'] * 1.21\n",
    "```\n",
    "\n",
    "**2. Operaciones condicionales (np.where):**\n",
    "```python\n",
    "df['categoria'] = np.where(df['edad'] < 18, 'Menor', 'Adulto')\n",
    "# Si edad < 18 \u2192 'Menor', si no \u2192 'Adulto'\n",
    "```\n",
    "\n",
    "**3. Apply con funciones:**\n",
    "```python\n",
    "df['nombre_upper'] = df['nombre'].apply(lambda x: x.upper())\n",
    "```\n",
    "\n",
    "**4. Operaciones entre columnas:**\n",
    "```python\n",
    "df['diferencia'] = df['precio_venta'] - df['costo']\n",
    "df['margen'] = (df['diferencia'] / df['precio_venta']) * 100\n",
    "```\n",
    "\n",
    "**Operadores soportados:**\n",
    "- `+` Suma\n",
    "- `-` Resta\n",
    "- `*` Multiplicaci\u00f3n\n",
    "- `/` Divisi\u00f3n\n",
    "- `**` Potencia\n",
    "- `%` M\u00f3dulo\n",
    "- `//` Divisi\u00f3n entera\n",
    "\n",
    "**Modificar columnas existentes:**\n",
    "```python\n",
    "# Reemplazar valores\n",
    "df['precio'] = df['precio'] * 1.1  # Aumentar 10%\n",
    "\n",
    "# Renombrar\n",
    "df = df.rename(columns={'nombre': 'nombre_cliente'})\n",
    "\n",
    "# Eliminar\n",
    "df = df.drop(columns=['columna_innecesaria'])\n",
    "```\n",
    "\n",
    "**En este bloque ver\u00e1s:**\n",
    "1. Crear columnas con operaciones aritm\u00e9ticas simples\n",
    "2. Usar `np.where()` para l\u00f3gica condicional (if-else)\n",
    "3. Sintaxis: `np.where(condicion, valor_si_true, valor_si_false)`\n",
    "4. Aplicar transformaciones a todas las filas simult\u00e1neamente\n",
    "5. Por qu\u00e9 pandas es vectorizado (no necesitas loops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57aabd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear dataset m\u00e1s grande para agrupaciones\n",
    "np.random.seed(42)\n",
    "n_registros = 100\n",
    "\n",
    "df_transacciones = pd.DataFrame({\n",
    "    'fecha': pd.date_range('2024-01-01', periods=n_registros, freq='D'),\n",
    "    'categoria': np.random.choice(['Electr\u00f3nica', 'Ropa', 'Alimentos', 'Hogar'], n_registros),\n",
    "    'producto': [f'Producto_{i}' for i in range(n_registros)],\n",
    "    'cantidad': np.random.randint(1, 20, n_registros),\n",
    "    'precio': np.random.uniform(10, 500, n_registros).round(2),\n",
    "    'region': np.random.choice(['Norte', 'Sur', 'Este', 'Oeste'], n_registros)\n",
    "})\n",
    "\n",
    "df_transacciones['total'] = df_transacciones['cantidad'] * df_transacciones['precio']\n",
    "\n",
    "print(\"Dataset de transacciones:\")\n",
    "print(df_transacciones.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01103bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrupaci\u00f3n simple\n",
    "print(\"Ventas totales por categor\u00eda:\")\n",
    "ventas_por_categoria = df_transacciones.groupby('categoria')['total'].sum()\n",
    "print(ventas_por_categoria)\n",
    "print(f\"\\nTipo: {type(ventas_por_categoria)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af6ae29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# M\u00faltiples agregaciones\n",
    "print(\"Estad\u00edsticas por categor\u00eda:\")\n",
    "stats_categoria = df_transacciones.groupby('categoria')['total'].agg([\n",
    "    ('total_ventas', 'sum'),\n",
    "    ('promedio', 'mean'),\n",
    "    ('num_transacciones', 'count'),\n",
    "    ('max_venta', 'max')\n",
    "])\n",
    "print(stats_categoria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7e32f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrupaci\u00f3n por m\u00faltiples columnas\n",
    "print(\"Ventas por categor\u00eda y regi\u00f3n:\")\n",
    "ventas_categoria_region = df_transacciones.groupby(['categoria', 'region'])['total'].sum()\n",
    "print(ventas_categoria_region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546762a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usar pivot_table para an\u00e1lisis multidimensional\n",
    "print(\"Tabla din\u00e1mica: Ventas por categor\u00eda y regi\u00f3n:\")\n",
    "pivot_ventas = df_transacciones.pivot_table(\n",
    "    values='total',\n",
    "    index='categoria',\n",
    "    columns='region',\n",
    "    aggfunc='sum',\n",
    "    fill_value=0\n",
    ")\n",
    "print(pivot_ventas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b31f74",
   "metadata": {},
   "source": [
    "## 5. Manejo de Datos Faltantes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c18afa",
   "metadata": {},
   "source": [
    "### \ud83d\udcd6 GroupBy - La Operaci\u00f3n M\u00e1s Poderosa de Pandas\n",
    "\n",
    "**\u00bfQu\u00e9 es groupby?**\n",
    "Es el equivalente de **GROUP BY en SQL** - agrupa filas por valores \u00fanicos de una columna:\n",
    "- Ventas **por regi\u00f3n**\n",
    "- Salarios **por departamento**\n",
    "- Usuarios **por pa\u00eds**\n",
    "\n",
    "**Patr\u00f3n split-apply-combine:**\n",
    "```\n",
    "Original DataFrame:\n",
    "regi\u00f3n    ventas\n",
    "Norte     100\n",
    "Norte     200\n",
    "Sur       150\n",
    "Sur       250\n",
    "\n",
    "\u2b07\ufe0f SPLIT (agrupar por regi\u00f3n)\n",
    "\n",
    "Grupo Norte: [100, 200]\n",
    "Grupo Sur:   [150, 250]\n",
    "\n",
    "\u2b07\ufe0f APPLY (aplicar funci\u00f3n, ej: sum)\n",
    "\n",
    "Norte: 300\n",
    "Sur:   400\n",
    "\n",
    "\u2b07\ufe0f COMBINE (combinar resultados)\n",
    "\n",
    "regi\u00f3n    ventas\n",
    "Norte     300\n",
    "Sur       400\n",
    "```\n",
    "\n",
    "**Sintaxis b\u00e1sica:**\n",
    "```python\n",
    "df.groupby('columna')['columna_a_agregar'].funcion()\n",
    "```\n",
    "\n",
    "**Desglose:**\n",
    "1. `df.groupby('region')` \u2192 Agrupa por regi\u00f3n\n",
    "2. `['total']` \u2192 Selecciona columna a operar\n",
    "3. `.sum()` \u2192 Aplica funci\u00f3n de agregaci\u00f3n\n",
    "\n",
    "**Funciones de agregaci\u00f3n comunes:**\n",
    "\n",
    "| Funci\u00f3n | Qu\u00e9 hace | Ejemplo de uso |\n",
    "|---------|----------|----------------|\n",
    "| `.sum()` | Suma total | Ingresos totales |\n",
    "| `.mean()` | Promedio | Salario promedio |\n",
    "| `.median()` | Mediana | Precio t\u00edpico |\n",
    "| `.count()` | Cantidad | N\u00famero de transacciones |\n",
    "| `.min()` | M\u00ednimo | Venta m\u00e1s baja |\n",
    "| `.max()` | M\u00e1ximo | Venta m\u00e1s alta |\n",
    "| `.std()` | Desviaci\u00f3n est\u00e1ndar | Variabilidad |\n",
    "| `.var()` | Varianza | Dispersi\u00f3n |\n",
    "| `.size()` | Tama\u00f1o de grupo | Filas por grupo |\n",
    "\n",
    "**Agrupar por m\u00faltiples columnas:**\n",
    "```python\n",
    "df.groupby(['region', 'categoria'])['total'].sum()\n",
    "```\n",
    "\n",
    "**Aplicar m\u00faltiples funciones:**\n",
    "```python\n",
    "df.groupby('region')['total'].agg(['sum', 'mean', 'count'])\n",
    "```\n",
    "\n",
    "**Casos de uso en Data Engineering:**\n",
    "1. **Reportes por dimensi\u00f3n**: Ventas por mes, producto, regi\u00f3n\n",
    "2. **C\u00e1lculo de KPIs**: AOV (Average Order Value) por segmento\n",
    "3. **Detecci\u00f3n de anomal\u00edas**: Comparar grupos para encontrar outliers\n",
    "4. **Feature engineering**: Crear caracter\u00edsticas agregadas para ML\n",
    "5. **Data quality**: Contar registros por categor\u00eda\n",
    "\n",
    "**En este bloque aprender\u00e1s:**\n",
    "1. Usar `groupby()` para agrupar por una columna\n",
    "2. Aplicar funciones de agregaci\u00f3n (sum, mean, count)\n",
    "3. Agrupar por m\u00faltiples columnas simult\u00e1neamente\n",
    "4. El patr\u00f3n split-apply-combine\n",
    "5. Diferencia entre `.size()` y `.count()`\n",
    "6. Usar `.agg()` para aplicar m\u00faltiples funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a95b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear DataFrame con valores faltantes\n",
    "datos_clientes = {\n",
    "    'id': [1, 2, 3, 4, 5, 6],\n",
    "    'nombre': ['Juan', 'Mar\u00eda', 'Pedro', None, 'Ana', 'Luis'],\n",
    "    'edad': [25, 30, None, 28, 35, None],\n",
    "    'email': ['juan@mail.com', None, 'pedro@mail.com', 'carlos@mail.com', None, 'luis@mail.com'],\n",
    "    'salario': [50000, 60000, 55000, None, 70000, 48000]\n",
    "}\n",
    "\n",
    "df_clientes = pd.DataFrame(datos_clientes)\n",
    "print(\"DataFrame con valores faltantes:\")\n",
    "print(df_clientes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704eb328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detectar valores faltantes\n",
    "print(\"Valores nulos por columna:\")\n",
    "print(df_clientes.isnull().sum())\n",
    "\n",
    "print(\"\\nPorcentaje de valores nulos:\")\n",
    "print((df_clientes.isnull().sum() / len(df_clientes) * 100).round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411aacf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar filas con valores faltantes\n",
    "df_sin_nulos = df_clientes.dropna()\n",
    "print(f\"Filas originales: {len(df_clientes)}\")\n",
    "print(f\"Filas despu\u00e9s de dropna(): {len(df_sin_nulos)}\")\n",
    "print(\"\\nDataFrame sin nulos:\")\n",
    "print(df_sin_nulos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964d7f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rellenar valores faltantes\n",
    "df_rellenado = df_clientes.copy()\n",
    "\n",
    "# Rellenar edad con la media\n",
    "df_rellenado['edad'].fillna(df_rellenado['edad'].mean(), inplace=True)\n",
    "\n",
    "# Rellenar nombre con un valor por defecto\n",
    "df_rellenado['nombre'].fillna('Desconocido', inplace=True)\n",
    "\n",
    "# Rellenar email con un valor espec\u00edfico\n",
    "df_rellenado['email'].fillna('sin_email@ejemplo.com', inplace=True)\n",
    "\n",
    "# Rellenar salario con la mediana\n",
    "df_rellenado['salario'].fillna(df_rellenado['salario'].median(), inplace=True)\n",
    "\n",
    "print(\"DataFrame con valores imputados:\")\n",
    "print(df_rellenado)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87dc7771",
   "metadata": {},
   "source": [
    "## 6. Manejo de Duplicados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c107d57e",
   "metadata": {},
   "source": [
    "### \ud83d\udcd6 Datos Faltantes (NaN) - El Enemigo Silencioso\n",
    "\n",
    "**\u00bfQu\u00e9 son los valores nulos?**\n",
    "Son **ausencias de datos** representadas como `NaN` (Not a Number) o `None`:\n",
    "- Campos opcionales no completados (tel\u00e9fono, direcci\u00f3n)\n",
    "- Errores en recolecci\u00f3n (sensor desconectado)\n",
    "- Joins que no hicieron match\n",
    "- Datos hist\u00f3ricos perdidos\n",
    "\n",
    "**\u00bfPor qu\u00e9 son problem\u00e1ticos?**\n",
    "- **Rompen c\u00e1lculos**: `sum([1, 2, NaN])` puede dar resultados inesperados\n",
    "- **Sesgan estad\u00edsticas**: `mean()` ignora NaN pero cambia el denominador\n",
    "- **Fallan modelos ML**: La mayor\u00eda NO acepta NaN\n",
    "- **Errores en producci\u00f3n**: C\u00f3digo asume valores presentes\n",
    "\n",
    "**Detectar valores nulos:**\n",
    "\n",
    "```python\n",
    "# Por celda\n",
    "df.isnull()        # True donde hay NaN\n",
    "df.notnull()       # True donde NO hay NaN\n",
    "\n",
    "# Por columna (cu\u00e1ntos nulos)\n",
    "df.isnull().sum()\n",
    "\n",
    "# Filas con alg\u00fan nulo\n",
    "df[df.isnull().any(axis=1)]\n",
    "\n",
    "# Porcentaje de nulos\n",
    "(df.isnull().sum() / len(df)) * 100\n",
    "```\n",
    "\n",
    "**Estrategias de manejo:**\n",
    "\n",
    "**1. Eliminar (dropna):**\n",
    "```python\n",
    "# Eliminar filas con alg\u00fan NaN\n",
    "df.dropna()\n",
    "\n",
    "# Eliminar filas donde TODAS las columnas sean NaN\n",
    "df.dropna(how='all')\n",
    "\n",
    "# Eliminar columnas con alg\u00fan NaN\n",
    "df.dropna(axis=1)\n",
    "\n",
    "# Eliminar solo si hay NaN en columnas espec\u00edficas\n",
    "df.dropna(subset=['edad', 'salario'])\n",
    "```\n",
    "\n",
    "**\u26a0\ufe0f Cuidado:** Si tienes 1000 filas y 10 tienen NaN, \u00bfvale la pena perder el 1%?\n",
    "\n",
    "**2. Rellenar (fillna):**\n",
    "```python\n",
    "# Con un valor constante\n",
    "df.fillna(0)\n",
    "\n",
    "# Con la media (para num\u00e9ricos)\n",
    "df['edad'].fillna(df['edad'].mean())\n",
    "\n",
    "# Con la mediana (resistente a outliers)\n",
    "df['salario'].fillna(df['salario'].median())\n",
    "\n",
    "# Con la moda (m\u00e1s frecuente)\n",
    "df['ciudad'].fillna(df['ciudad'].mode()[0])\n",
    "\n",
    "# Forward fill (llevar valor anterior)\n",
    "df.fillna(method='ffill')\n",
    "\n",
    "# Backward fill (traer valor siguiente)\n",
    "df.fillna(method='bfill')\n",
    "```\n",
    "\n",
    "**3. Imputaci\u00f3n avanzada:**\n",
    "```python\n",
    "# Por grupo\n",
    "df['salario'] = df.groupby('departamento')['salario'].transform(\n",
    "    lambda x: x.fillna(x.mean())\n",
    ")\n",
    "```\n",
    "\n",
    "**\u00bfCu\u00e1ndo usar cada estrategia?**\n",
    "\n",
    "| Estrategia | Cu\u00e1ndo usarla | Ejemplo |\n",
    "|------------|---------------|---------|\n",
    "| **Eliminar** | Pocos nulos (<5%), campo obligatorio | ID, fecha de transacci\u00f3n |\n",
    "| **Rellenar con 0** | Ausencia = cero | Descuento aplicado |\n",
    "| **Rellenar con media/mediana** | Num\u00e9ricos, distribuci\u00f3n normal | Edad, salario |\n",
    "| **Rellenar con moda** | Categ\u00f3ricos | Ciudad, categor\u00eda |\n",
    "| **Forward/Backward fill** | Series temporales | Precio de acciones |\n",
    "| **Dejar** | Ausencia es informativa | Fecha de cancelaci\u00f3n |\n",
    "\n",
    "**Validaci\u00f3n post-procesamiento:**\n",
    "```python\n",
    "# Verificar que no quedan nulos\n",
    "assert df.isnull().sum().sum() == 0, \"\u00a1A\u00fan hay nulos!\"\n",
    "```\n",
    "\n",
    "**En este bloque aprender\u00e1s:**\n",
    "1. Detectar nulos con `isnull()` y contar con `.sum()`\n",
    "2. Eliminar filas/columnas con `dropna()`\n",
    "3. Rellenar nulos con `fillna()`\n",
    "4. Estrategias: valor constante, media, mediana, moda\n",
    "5. Diferencia entre eliminar vs imputar\n",
    "6. Par\u00e1metros de dropna: `how='all'`, `subset=[]`\n",
    "7. Por qu\u00e9 la mediana es mejor que la media con outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed810cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear DataFrame con duplicados\n",
    "datos_duplicados = {\n",
    "    'id': [1, 2, 3, 2, 4, 3, 5],\n",
    "    'producto': ['A', 'B', 'C', 'B', 'D', 'C', 'E'],\n",
    "    'cantidad': [10, 20, 15, 20, 25, 15, 30]\n",
    "}\n",
    "\n",
    "df_dup = pd.DataFrame(datos_duplicados)\n",
    "print(\"DataFrame con duplicados:\")\n",
    "print(df_dup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7873fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detectar duplicados\n",
    "print(\"Filas duplicadas:\")\n",
    "print(df_dup[df_dup.duplicated()])\n",
    "\n",
    "print(f\"\\nN\u00famero de duplicados: {df_dup.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0317c45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar duplicados\n",
    "df_sin_dup = df_dup.drop_duplicates()\n",
    "print(\"DataFrame sin duplicados:\")\n",
    "print(df_sin_dup)\n",
    "print(f\"\\nFilas originales: {len(df_dup)}\")\n",
    "print(f\"Filas sin duplicados: {len(df_sin_dup)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1471feba",
   "metadata": {},
   "source": [
    "## 7. Ordenamiento de Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f05d3e",
   "metadata": {},
   "source": [
    "### \ud83d\udcd6 Duplicados - Detectando Filas Repetidas\n",
    "\n",
    "**\u00bfQu\u00e9 son duplicados?**\n",
    "Son **filas id\u00e9nticas** (o id\u00e9nticas en ciertas columnas) que aparecen m\u00faltiples veces:\n",
    "- Errores en importaci\u00f3n (archivo procesado dos veces)\n",
    "- Bugs en aplicaciones (mismo registro insertado m\u00faltiples veces)\n",
    "- Falta de constraints en BD (sin PRIMARY KEY)\n",
    "- Merges incorrectos (joins mal hechos)\n",
    "\n",
    "**\u00bfPor qu\u00e9 son problem\u00e1ticos?**\n",
    "- **Sesgan an\u00e1lisis**: Contar \"clientes \u00fanicos\" da resultados incorrectos\n",
    "- **Inflan m\u00e9tricas**: Ventas totales duplicadas\n",
    "- **Desperdiciar recursos**: Procesar mismo dato m\u00faltiples veces\n",
    "- **Violan integridad**: Un usuario no deber\u00eda tener 2 IDs\n",
    "\n",
    "**Detectar duplicados:**\n",
    "\n",
    "```python\n",
    "# Filas completamente duplicadas\n",
    "df.duplicated()  # Retorna Series booleana\n",
    "\n",
    "# Contar duplicados\n",
    "df.duplicated().sum()\n",
    "\n",
    "# Ver las filas duplicadas\n",
    "df[df.duplicated()]\n",
    "\n",
    "# Duplicados basados en columnas espec\u00edficas\n",
    "df.duplicated(subset=['email'])  # Duplicados de email\n",
    "\n",
    "# Mostrar todas las ocurrencias (no solo la segunda)\n",
    "df[df.duplicated(subset=['email'], keep=False)]\n",
    "```\n",
    "\n",
    "**Par\u00e1metro `keep`:**\n",
    "\n",
    "| Valor | Qu\u00e9 hace | Cu\u00e1ndo usar |\n",
    "|-------|----------|-------------|\n",
    "| `'first'` | Marca duplicados excepto primera ocurrencia (default) | Mantener registro m\u00e1s antiguo |\n",
    "| `'last'` | Marca duplicados excepto \u00faltima ocurrencia | Mantener registro m\u00e1s reciente |\n",
    "| `False` | Marca TODAS las ocurrencias como duplicadas | Ver todos los duplicados |\n",
    "\n",
    "**Ejemplo visual:**\n",
    "```\n",
    "Original:\n",
    "  id  nombre\n",
    "  1   Ana\n",
    "  2   Luis\n",
    "  1   Ana    \u2190 Duplicado\n",
    "  3   Carlos\n",
    "\n",
    "duplicated(keep='first'):\n",
    "  False, False, True, False  \u2190 Marca el segundo\n",
    "\n",
    "duplicated(keep=False):\n",
    "  True, False, True, False   \u2190 Marca ambos\n",
    "```\n",
    "\n",
    "**Eliminar duplicados:**\n",
    "\n",
    "```python\n",
    "# Eliminar filas completamente duplicadas\n",
    "df.drop_duplicates()\n",
    "\n",
    "# Basado en columnas espec\u00edficas\n",
    "df.drop_duplicates(subset=['email'])\n",
    "\n",
    "# Mantener \u00faltima ocurrencia\n",
    "df.drop_duplicates(subset=['email'], keep='last')\n",
    "\n",
    "# In-place (modifica el DataFrame original)\n",
    "df.drop_duplicates(inplace=True)\n",
    "```\n",
    "\n",
    "**Casos de uso:**\n",
    "\n",
    "**1. Deduplicar usuarios:**\n",
    "```python\n",
    "# Mantener \u00faltimo registro (m\u00e1s actualizado)\n",
    "df_usuarios = df.drop_duplicates(subset=['user_id'], keep='last')\n",
    "```\n",
    "\n",
    "**2. Encontrar emails repetidos:**\n",
    "```python\n",
    "# Ver todos los duplicados\n",
    "duplicados = df[df.duplicated(subset=['email'], keep=False)]\n",
    "duplicados.sort_values('email')  # Agrupar para revisar\n",
    "```\n",
    "\n",
    "**3. Validar unicidad antes de cargar a BD:**\n",
    "```python\n",
    "assert df['id'].duplicated().sum() == 0, \"\u00a1IDs duplicados encontrados!\"\n",
    "```\n",
    "\n",
    "**Best practices:**\n",
    "- \u2705 **Investiga antes de eliminar**: \u00bfPor qu\u00e9 hay duplicados?\n",
    "- \u2705 **Log de eliminaci\u00f3n**: Guarda qu\u00e9 se elimin\u00f3\n",
    "- \u2705 **Define criterio de keep**: \u00bffirst, last, o ninguno?\n",
    "- \u2705 **Valida post-procesamiento**: Asegura que no quedan duplicados\n",
    "- \u26a0\ufe0f **Cuidado con None/NaN**: Pandas los considera \u00fanicos\n",
    "\n",
    "**En este bloque aprender\u00e1s:**\n",
    "1. Detectar duplicados con `duplicated()`\n",
    "2. Contar duplicados con `.sum()`\n",
    "3. Ver filas duplicadas filtrando con la m\u00e1scara booleana\n",
    "4. Eliminar duplicados con `drop_duplicates()`\n",
    "5. El par\u00e1metro `subset` para especificar columnas\n",
    "6. Diferencia entre `keep='first'`, `keep='last'` y `keep=False`\n",
    "7. Por qu\u00e9 revisar duplicados antes de eliminarlos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cf66c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordenar por una columna\n",
    "print(\"Ventas ordenadas por total (descendente):\")\n",
    "df_ordenado = df_ventas.sort_values('total_venta', ascending=False)\n",
    "print(df_ordenado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdbcfc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordenar por m\u00faltiples columnas\n",
    "print(\"Transacciones ordenadas por categor\u00eda y total:\")\n",
    "df_multi_orden = df_transacciones.sort_values(\n",
    "    ['categoria', 'total'],\n",
    "    ascending=[True, False]\n",
    ").head(10)\n",
    "print(df_multi_orden[['categoria', 'producto', 'total']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7012ca",
   "metadata": {},
   "source": [
    "## 8. Concatenaci\u00f3n y Merge de DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff931a81",
   "metadata": {},
   "source": [
    "### \ud83d\udcd6 Ordenamiento - Organizando tus Datos\n",
    "\n",
    "**\u00bfPor qu\u00e9 ordenar?**\n",
    "- **An\u00e1lisis temporal**: Ver evoluci\u00f3n cronol\u00f3gica\n",
    "- **Top N**: Productos m\u00e1s vendidos, salarios m\u00e1s altos\n",
    "- **Presentaci\u00f3n**: Reportes ordenados se leen mejor\n",
    "- **Debugging**: Detectar patrones y anomal\u00edas\n",
    "- **Optimizaci\u00f3n**: Algunos algoritmos funcionan mejor con datos ordenados\n",
    "\n",
    "**Dos tipos de ordenamiento:**\n",
    "\n",
    "**1. Por valores (sort_values):**\n",
    "```python\n",
    "# Ascendente (menor a mayor)\n",
    "df.sort_values('edad')\n",
    "\n",
    "# Descendente (mayor a menor)\n",
    "df.sort_values('edad', ascending=False)\n",
    "\n",
    "# Por m\u00faltiples columnas\n",
    "df.sort_values(['ciudad', 'edad'])\n",
    "```\n",
    "\n",
    "**2. Por \u00edndice (sort_index):**\n",
    "```python\n",
    "# Ascendente\n",
    "df.sort_index()\n",
    "\n",
    "# Descendente\n",
    "df.sort_index(ascending=False)\n",
    "```\n",
    "\n",
    "**Ordenamiento m\u00faltiple:**\n",
    "```python\n",
    "# Orden diferente por columna\n",
    "df.sort_values(\n",
    "    by=['ciudad', 'edad'],\n",
    "    ascending=[True, False]  # Ciudad \u2191, Edad \u2193\n",
    ")\n",
    "```\n",
    "\n",
    "**Visualizaci\u00f3n:**\n",
    "```\n",
    "Original:\n",
    "  nombre  edad  ciudad\n",
    "  Carlos  28    Valencia\n",
    "  Ana     25    Madrid\n",
    "  Luis    30    Barcelona\n",
    "\n",
    "sort_values('edad'):\n",
    "  Ana     25    Madrid\n",
    "  Carlos  28    Valencia\n",
    "  Luis    30    Barcelona\n",
    "\n",
    "sort_values('edad', ascending=False):\n",
    "  Luis    30    Barcelona\n",
    "  Carlos  28    Valencia\n",
    "  Ana     25    Madrid\n",
    "```\n",
    "\n",
    "**Par\u00e1metros \u00fatiles:**\n",
    "\n",
    "| Par\u00e1metro | Qu\u00e9 hace | Ejemplo |\n",
    "|-----------|----------|---------|\n",
    "| `ascending` | Orden ascendente (True) o descendente (False) | `ascending=False` |\n",
    "| `inplace` | Modifica el DataFrame original | `inplace=True` |\n",
    "| `na_position` | D\u00f3nde poner NaN ('first' o 'last') | `na_position='first'` |\n",
    "| `key` | Funci\u00f3n para transformar antes de ordenar | `key=lambda x: x.str.lower()` |\n",
    "\n",
    "**Casos de uso comunes:**\n",
    "\n",
    "**1. Top N productos:**\n",
    "```python\n",
    "top_10 = df.sort_values('ventas', ascending=False).head(10)\n",
    "```\n",
    "\n",
    "**2. Cronol\u00f3gico:**\n",
    "```python\n",
    "df.sort_values('fecha')\n",
    "```\n",
    "\n",
    "**3. Alfab\u00e9tico case-insensitive:**\n",
    "```python\n",
    "df.sort_values('nombre', key=lambda x: x.str.lower())\n",
    "```\n",
    "\n",
    "**4. M\u00faltiples niveles (regi\u00f3n > ciudad > nombre):**\n",
    "```python\n",
    "df.sort_values(['region', 'ciudad', 'nombre'])\n",
    "```\n",
    "\n",
    "**sort_values vs sort_index:**\n",
    "\n",
    "| Aspecto | sort_values | sort_index |\n",
    "|---------|-------------|------------|\n",
    "| Ordena por | Valores de columnas | Etiquetas del \u00edndice |\n",
    "| Uso com\u00fan | Ordenar registros | Reorganizar despu\u00e9s de operaciones |\n",
    "| Ejemplo | Por fecha, precio, nombre | Despu\u00e9s de merge, groupby |\n",
    "\n",
    "**Best practices:**\n",
    "- \u2705 **No uses inplace=True** si necesitas el original despu\u00e9s\n",
    "- \u2705 **Especifica ascending** expl\u00edcitamente (claridad)\n",
    "- \u2705 **Maneja NaN**: Decide si van primero o \u00faltimo\n",
    "- \u2705 **Reset index** despu\u00e9s si el orden del \u00edndice ya no tiene sentido\n",
    "\n",
    "**En este bloque aprender\u00e1s:**\n",
    "1. Ordenar por valores con `sort_values()`\n",
    "2. Orden ascendente vs descendente con `ascending`\n",
    "3. Ordenar por m\u00faltiples columnas\n",
    "4. Diferente orden por columna (algunas \u2191, otras \u2193)\n",
    "5. Diferencia entre sort_values y sort_index\n",
    "6. Cu\u00e1ndo usar cada tipo de ordenamiento\n",
    "7. Obtener Top N combinando sort + head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5be325b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenaci\u00f3n vertical\n",
    "df1 = pd.DataFrame({\n",
    "    'id': [1, 2, 3],\n",
    "    'valor': [10, 20, 30]\n",
    "})\n",
    "\n",
    "df2 = pd.DataFrame({\n",
    "    'id': [4, 5, 6],\n",
    "    'valor': [40, 50, 60]\n",
    "})\n",
    "\n",
    "df_concat = pd.concat([df1, df2], ignore_index=True)\n",
    "print(\"Concatenaci\u00f3n vertical:\")\n",
    "print(df_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038ec37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge (Join)\n",
    "df_productos = pd.DataFrame({\n",
    "    'producto_id': [1, 2, 3, 4],\n",
    "    'nombre': ['Laptop', 'Mouse', 'Teclado', 'Monitor']\n",
    "})\n",
    "\n",
    "df_precios = pd.DataFrame({\n",
    "    'producto_id': [1, 2, 3, 5],\n",
    "    'precio': [1200, 25, 75, 150]\n",
    "})\n",
    "\n",
    "print(\"Productos:\")\n",
    "print(df_productos)\n",
    "print(\"\\nPrecios:\")\n",
    "print(df_precios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c12bbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inner join\n",
    "df_inner = pd.merge(df_productos, df_precios, on='producto_id', how='inner')\n",
    "print(\"Inner Join:\")\n",
    "print(df_inner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d7c5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Left join\n",
    "df_left = pd.merge(df_productos, df_precios, on='producto_id', how='left')\n",
    "print(\"Left Join:\")\n",
    "print(df_left)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd2a2b4",
   "metadata": {},
   "source": [
    "## 9. Visualizaci\u00f3n con Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b699578e",
   "metadata": {},
   "source": [
    "### \ud83d\udcd6 Combinar DataFrames - Concat y Merge\n",
    "\n",
    "**\u00bfPor qu\u00e9 combinar DataFrames?**\n",
    "En el mundo real, los datos est\u00e1n **fragmentados**:\n",
    "- Ventas de enero en un archivo, febrero en otro \u2192 **Concat**\n",
    "- Datos de clientes en una tabla, pedidos en otra \u2192 **Merge/Join**\n",
    "- M\u00faltiples fuentes que necesitan integrarse\n",
    "\n",
    "**Dos operaciones principales:**\n",
    "\n",
    "## 1. Concatenaci\u00f3n (pd.concat) - Apilar datos\n",
    "\n",
    "**\u00bfCu\u00e1ndo usar?**\n",
    "Cuando tienes **la misma estructura** pero diferentes registros:\n",
    "- Datos mensuales \u2192 Combinar en dataset anual\n",
    "- M\u00faltiples archivos del mismo formato\n",
    "- Agregar filas nuevas a un DataFrame\n",
    "\n",
    "**Sintaxis:**\n",
    "```python\n",
    "pd.concat([df1, df2], axis=0)  # Vertical (apilar filas)\n",
    "pd.concat([df1, df2], axis=1)  # Horizontal (a\u00f1adir columnas)\n",
    "```\n",
    "\n",
    "**Visualizaci\u00f3n (axis=0):**\n",
    "```\n",
    "df1:              df2:              Resultado:\n",
    "  id  nombre        id  nombre        id  nombre\n",
    "  1   Ana           3   Carlos        1   Ana\n",
    "  2   Luis          4   Mar\u00eda         2   Luis\n",
    "                                      3   Carlos\n",
    "                                      4   Mar\u00eda\n",
    "```\n",
    "\n",
    "**Par\u00e1metros \u00fatiles:**\n",
    "- `ignore_index=True`: Reinicia el \u00edndice (0, 1, 2...)\n",
    "- `keys=['ene', 'feb']`: A\u00f1ade nivel jer\u00e1rquico al \u00edndice\n",
    "\n",
    "## 2. Merge (pd.merge) - Joins tipo SQL\n",
    "\n",
    "**\u00bfCu\u00e1ndo usar?**\n",
    "Cuando necesitas **relacionar** datos por una clave com\u00fan:\n",
    "- Clientes + Pedidos (ambos tienen `customer_id`)\n",
    "- Productos + Categor\u00edas (ambos tienen `category_id`)\n",
    "- Usuarios + Transacciones\n",
    "\n",
    "**Tipos de joins:**\n",
    "\n",
    "| Tipo | SQL | Pandas | Qu\u00e9 hace |\n",
    "|------|-----|--------|----------|\n",
    "| **Inner** | INNER JOIN | `how='inner'` | Solo matches (intersecci\u00f3n) |\n",
    "| **Left** | LEFT JOIN | `how='left'` | Todas de izquierda + matches |\n",
    "| **Right** | RIGHT JOIN | `how='right'` | Todas de derecha + matches |\n",
    "| **Outer** | FULL OUTER JOIN | `how='outer'` | Todas (uni\u00f3n) |\n",
    "\n",
    "**Sintaxis:**\n",
    "```python\n",
    "pd.merge(\n",
    "    df_left,\n",
    "    df_right,\n",
    "    on='columna_comun',  # Columna para unir\n",
    "    how='inner'          # Tipo de join\n",
    ")\n",
    "```\n",
    "\n",
    "**Ejemplo visual (Inner Join):**\n",
    "```\n",
    "df_clientes:          df_pedidos:           Resultado:\n",
    "  id  nombre            id_cliente  total     id  nombre  total\n",
    "  1   Ana               1           100       1   Ana     100\n",
    "  2   Luis              2           200       2   Luis    200\n",
    "  3   Carlos            1           150       1   Ana     150\n",
    "```\n",
    "\n",
    "**Diferencia entre on, left_on, right_on:**\n",
    "\n",
    "```python\n",
    "# Columnas con mismo nombre\n",
    "pd.merge(df1, df2, on='id')\n",
    "\n",
    "# Columnas con diferente nombre\n",
    "pd.merge(df1, df2, left_on='customer_id', right_on='id')\n",
    "\n",
    "# M\u00faltiples columnas\n",
    "pd.merge(df1, df2, on=['region', 'fecha'])\n",
    "```\n",
    "\n",
    "**Comparaci\u00f3n Concat vs Merge:**\n",
    "\n",
    "| Aspecto | Concat | Merge |\n",
    "|---------|--------|-------|\n",
    "| Prop\u00f3sito | Apilar/juntar | Relacionar |\n",
    "| Estructura | Misma | Puede ser diferente |\n",
    "| Operaci\u00f3n | Union/Append | Join |\n",
    "| Clave | No necesaria | Requiere columna com\u00fan |\n",
    "| SQL equivalente | UNION | JOIN |\n",
    "\n",
    "**Casos de uso:**\n",
    "\n",
    "**Concat - Agregar datos hist\u00f3ricos:**\n",
    "```python\n",
    "# Archivos mensuales\n",
    "df_jan = pd.read_csv('ventas_enero.csv')\n",
    "df_feb = pd.read_csv('ventas_febrero.csv')\n",
    "df_q1 = pd.concat([df_jan, df_feb], ignore_index=True)\n",
    "```\n",
    "\n",
    "**Merge - Enriquecer con informaci\u00f3n relacionada:**\n",
    "```python\n",
    "# A\u00f1adir nombres de clientes a pedidos\n",
    "pedidos_enriquecidos = pd.merge(\n",
    "    df_pedidos,\n",
    "    df_clientes[['id', 'nombre']],\n",
    "    left_on='customer_id',\n",
    "    right_on='id',\n",
    "    how='left'\n",
    ")\n",
    "```\n",
    "\n",
    "**En este bloque aprender\u00e1s:**\n",
    "1. Concatenar DataFrames verticalmente con `pd.concat()`\n",
    "2. Par\u00e1metro `axis`: 0 para filas, 1 para columnas\n",
    "3. Usar `ignore_index=True` para reiniciar \u00edndice\n",
    "4. Hacer joins con `pd.merge()`\n",
    "5. Tipos de joins: inner, left, right, outer\n",
    "6. Especificar columnas de join con `on`, `left_on`, `right_on`\n",
    "7. Cu\u00e1ndo usar concat vs merge\n",
    "8. Visualizar resultados de diferentes tipos de joins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d98c929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gr\u00e1ficos b\u00e1sicos\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Gr\u00e1fico de barras\n",
    "ventas_por_categoria.plot(kind='bar', ax=axes[0, 0], color='skyblue')\n",
    "axes[0, 0].set_title('Ventas Totales por Categor\u00eda')\n",
    "axes[0, 0].set_ylabel('Total ($)')\n",
    "\n",
    "# Gr\u00e1fico de l\u00edneas\n",
    "df_transacciones.groupby('fecha')['total'].sum().plot(ax=axes[0, 1], color='green')\n",
    "axes[0, 1].set_title('Evoluci\u00f3n de Ventas Diarias')\n",
    "axes[0, 1].set_ylabel('Total ($)')\n",
    "\n",
    "# Histograma\n",
    "df_transacciones['precio'].plot(kind='hist', bins=20, ax=axes[1, 0], color='coral')\n",
    "axes[1, 0].set_title('Distribuci\u00f3n de Precios')\n",
    "axes[1, 0].set_xlabel('Precio')\n",
    "\n",
    "# Box plot\n",
    "df_transacciones.boxplot(column='total', by='categoria', ax=axes[1, 1])\n",
    "axes[1, 1].set_title('Distribuci\u00f3n de Ventas por Categor\u00eda')\n",
    "axes[1, 1].set_ylabel('Total ($)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465460c2",
   "metadata": {},
   "source": [
    "## 10. Ejercicios Pr\u00e1cticos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce775c8",
   "metadata": {},
   "source": [
    "### \ud83d\udcd6 Visualizaci\u00f3n R\u00e1pida con Pandas\n",
    "\n",
    "**\u00bfPor qu\u00e9 pandas tiene plotting integrado?**\n",
    "Para **exploraci\u00f3n r\u00e1pida** sin salir del flujo de an\u00e1lisis:\n",
    "- No necesitas importar matplotlib para gr\u00e1ficos simples\n",
    "- Sintaxis m\u00e1s corta: `df.plot()` vs configurar matplotlib\n",
    "- Perfecto para an\u00e1lisis exploratorio (EDA)\n",
    "\n",
    "**Integraci\u00f3n con matplotlib:**\n",
    "Pandas usa matplotlib por detr\u00e1s, as\u00ed que puedes:\n",
    "- Personalizar con comandos de matplotlib\n",
    "- Combinar ambas bibliotecas\n",
    "- Todo lo que funciona en matplotlib funciona aqu\u00ed\n",
    "\n",
    "**Tipos de gr\u00e1ficos disponibles:**\n",
    "\n",
    "| Tipo | M\u00e9todo | Cu\u00e1ndo usar |\n",
    "|------|--------|-------------|\n",
    "| **Line** | `.plot()` o `.plot(kind='line')` | Tendencias temporales |\n",
    "| **Bar** | `.plot(kind='bar')` | Comparar categor\u00edas |\n",
    "| **Histogram** | `.plot(kind='hist')` | Distribuci\u00f3n de valores |\n",
    "| **Box** | `.plot(kind='box')` | Detectar outliers, cuartiles |\n",
    "| **Scatter** | `.plot(kind='scatter')` | Relaci\u00f3n entre 2 variables |\n",
    "| **Pie** | `.plot(kind='pie')` | Proporciones (evitar si >5 categor\u00edas) |\n",
    "| **Area** | `.plot(kind='area')` | Tendencias apiladas |\n",
    "\n",
    "**Sintaxis general:**\n",
    "```python\n",
    "df['columna'].plot(\n",
    "    kind='bar',           # Tipo de gr\u00e1fico\n",
    "    title='T\u00edtulo',       # T\u00edtulo\n",
    "    figsize=(10, 6),      # Tama\u00f1o (ancho, alto)\n",
    "    color='steelblue',    # Color\n",
    "    legend=True           # Mostrar leyenda\n",
    ")\n",
    "plt.ylabel('Eje Y')\n",
    "plt.xlabel('Eje X')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "**Ejemplos r\u00e1pidos:**\n",
    "\n",
    "**Histograma (distribuci\u00f3n):**\n",
    "```python\n",
    "df['edad'].plot(kind='hist', bins=20, title='Distribuci\u00f3n de Edades')\n",
    "```\n",
    "\n",
    "**Line chart (temporal):**\n",
    "```python\n",
    "df.groupby('fecha')['ventas'].sum().plot(title='Ventas Diarias')\n",
    "```\n",
    "\n",
    "**Bar chart (categor\u00edas):**\n",
    "```python\n",
    "df['categoria'].value_counts().plot(kind='bar', title='Productos por Categor\u00eda')\n",
    "```\n",
    "\n",
    "**Scatter (correlaci\u00f3n):**\n",
    "```python\n",
    "df.plot(kind='scatter', x='precio', y='ventas', alpha=0.5)\n",
    "```\n",
    "\n",
    "**Box plot (outliers):**\n",
    "```python\n",
    "df[['edad', 'salario']].plot(kind='box')\n",
    "```\n",
    "\n",
    "**Personalizaci\u00f3n com\u00fan:**\n",
    "\n",
    "```python\n",
    "# Tama\u00f1o de figura\n",
    "df.plot(figsize=(12, 6))\n",
    "\n",
    "# Colores personalizados\n",
    "df.plot(color=['red', 'blue', 'green'])\n",
    "\n",
    "# Rotaci\u00f3n de labels\n",
    "df.plot(kind='bar')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Grid\n",
    "df.plot(grid=True)\n",
    "\n",
    "# Estilo\n",
    "plt.style.use('ggplot')\n",
    "df.plot()\n",
    "```\n",
    "\n",
    "**M\u00faltiples subplots:**\n",
    "```python\n",
    "df.plot(subplots=True, layout=(2, 2), figsize=(12, 8))\n",
    "```\n",
    "\n",
    "**Best practices:**\n",
    "- \u2705 **T\u00edtulos claros**: Qu\u00e9 muestra el gr\u00e1fico\n",
    "- \u2705 **Etiquetas con unidades**: \"$\", \"%\", \"kg\", etc.\n",
    "- \u2705 **Tama\u00f1o apropiado**: `figsize=(10, 6)` para legibilidad\n",
    "- \u2705 **Colores consistentes**: Usa paletas profesionales\n",
    "- \u26a0\ufe0f **No abuses de pie charts**: Barras son m\u00e1s claras\n",
    "- \u26a0\ufe0f **Cuidado con histogramas**: Ajusta `bins` seg\u00fan datos\n",
    "\n",
    "**Cu\u00e1ndo usar pandas.plot vs matplotlib puro:**\n",
    "\n",
    "| Usa pandas.plot cuando | Usa matplotlib cuando |\n",
    "|-------------------------|----------------------|\n",
    "| Exploraci\u00f3n r\u00e1pida | Presentaci\u00f3n final |\n",
    "| Prototipado | Personalizaci\u00f3n extrema |\n",
    "| Gr\u00e1ficos simples | M\u00faltiples fuentes de datos |\n",
    "| Trabajas con Series/DataFrame | Necesitas control total |\n",
    "\n",
    "**En este bloque aprender\u00e1s:**\n",
    "1. Crear gr\u00e1ficos directamente desde DataFrames con `.plot()`\n",
    "2. Diferentes tipos con `kind=`: bar, hist, scatter, box\n",
    "3. Personalizar con par\u00e1metros: figsize, title, color\n",
    "4. Combinar pandas.plot con matplotlib para detalles\n",
    "5. Cu\u00e1ndo usar cada tipo de gr\u00e1fico\n",
    "6. Shortcuts para an\u00e1lisis exploratorio r\u00e1pido\n",
    "7. Generar m\u00faltiples gr\u00e1ficos con subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c5445a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejercicio 1: An\u00e1lisis de ventas mensuales\n",
    "print(\"=== Ejercicio 1: An\u00e1lisis de Ventas Mensuales ===\")\n",
    "\n",
    "# Agregar columna de mes\n",
    "df_transacciones['mes'] = df_transacciones['fecha'].dt.month\n",
    "df_transacciones['mes_nombre'] = df_transacciones['fecha'].dt.month_name()\n",
    "\n",
    "# Ventas por mes\n",
    "ventas_mensuales = df_transacciones.groupby('mes_nombre')['total'].agg([\n",
    "    ('total', 'sum'),\n",
    "    ('promedio', 'mean'),\n",
    "    ('transacciones', 'count')\n",
    "])\n",
    "\n",
    "print(ventas_mensuales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53760b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejercicio 2: Top 5 productos m\u00e1s vendidos\n",
    "print(\"=== Ejercicio 2: Top 5 Productos ===\")\n",
    "\n",
    "top_productos = df_transacciones.groupby('producto').agg({\n",
    "    'cantidad': 'sum',\n",
    "    'total': 'sum'\n",
    "}).sort_values('total', ascending=False).head(5)\n",
    "\n",
    "print(top_productos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9859cb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejercicio 3: An\u00e1lisis por regi\u00f3n\n",
    "print(\"=== Ejercicio 3: Rendimiento por Regi\u00f3n ===\")\n",
    "\n",
    "analisis_region = df_transacciones.groupby('region').agg({\n",
    "    'total': ['sum', 'mean', 'count'],\n",
    "    'cantidad': 'sum'\n",
    "})\n",
    "\n",
    "analisis_region.columns = ['_'.join(col) for col in analisis_region.columns]\n",
    "analisis_region = analisis_region.sort_values('total_sum', ascending=False)\n",
    "\n",
    "print(analisis_region)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f71b5f7",
   "metadata": {},
   "source": [
    "## Resumen y Mejores Pr\u00e1cticas\n",
    "\n",
    "### Puntos Clave:\n",
    "1. **Series y DataFrames**: Estructuras fundamentales de pandas\n",
    "2. **Selecci\u00f3n**: Usar `loc` para etiquetas, `iloc` para posiciones\n",
    "3. **Filtrado**: Combinar condiciones con `&` (AND) y `|` (OR)\n",
    "4. **Agrupaciones**: `groupby()` para an\u00e1lisis agregado\n",
    "5. **Datos faltantes**: Detectar con `isnull()`, manejar con `fillna()` o `dropna()`\n",
    "6. **Duplicados**: Detectar con `duplicated()`, eliminar con `drop_duplicates()`\n",
    "\n",
    "### Mejores Pr\u00e1cticas:\n",
    "- Siempre explorar los datos con `head()`, `info()`, `describe()`\n",
    "- Verificar tipos de datos antes de operaciones\n",
    "- Manejar valores faltantes apropiadamente seg\u00fan el contexto\n",
    "- Usar nombres descriptivos para variables\n",
    "- Documentar transformaciones complejas\n",
    "- Validar resultados despu\u00e9s de cada transformaci\u00f3n\n",
    "\n",
    "### Recursos Adicionales:\n",
    "- [Documentaci\u00f3n oficial de Pandas](https://pandas.pydata.org/docs/)\n",
    "- [10 minutes to pandas](https://pandas.pydata.org/docs/user_guide/10min.html)\n",
    "- [Pandas Cheat Sheet](https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## \ud83e\udded Navegaci\u00f3n\n",
    "\n",
    "**\u2190 Anterior:** [\ud83d\udc0d Junior - 02. Python para Manipulaci\u00f3n de Datos](02_python_manipulacion_datos.ipynb)\n",
    "\n",
    "**Siguiente \u2192:** [SQL B\u00e1sico para Ingenier\u00eda de Datos \u2192](04_sql_basico.ipynb)\n",
    "\n",
    "**\ud83d\udcda \u00cdndice de Nivel Junior:**\n",
    "- [\ud83d\udcca Junior - 01. Introducci\u00f3n a la Ingenier\u00eda de Datos](01_introduccion_ingenieria_datos.ipynb)\n",
    "- [\ud83d\udc0d Junior - 02. Python para Manipulaci\u00f3n de Datos](02_python_manipulacion_datos.ipynb)\n",
    "- [Pandas: Fundamentos para An\u00e1lisis de Datos](03_pandas_fundamentos.ipynb) \u2190 \ud83d\udd35 Est\u00e1s aqu\u00ed\n",
    "- [SQL B\u00e1sico para Ingenier\u00eda de Datos](04_sql_basico.ipynb)\n",
    "- [Limpieza y Preparaci\u00f3n de Datos](05_limpieza_datos.ipynb)\n",
    "- [\ud83d\udcca Visualizaci\u00f3n de Datos en Ingenier\u00eda de Datos](06_visualizacion_datos.ipynb)\n",
    "- [\ud83d\udd04 Git y Control de Versiones para Ingenier\u00eda de Datos](07_git_control_versiones.ipynb)\n",
    "- [\ud83c\udf10 APIs REST y Web Scraping para Ingenier\u00eda de Datos](08_apis_web_scraping.ipynb)\n",
    "- [\ud83c\udfaf Proyecto Integrador 1: Pipeline ETL Completo](09_proyecto_integrador_1.ipynb)\n",
    "- [\ud83d\ude80 Proyecto Integrador 2: Pipeline Near Real-Time, Scheduling y Alertas](10_proyecto_integrador_2.ipynb)\n",
    "\n",
    "**\ud83c\udf93 Otros Niveles:**\n",
    "- [Nivel Junior](../nivel_junior/README.md)\n",
    "- [Nivel Mid](../nivel_mid/README.md)\n",
    "- [Nivel Senior](../nivel_senior/README.md)\n",
    "- [Nivel GenAI](../nivel_genai/README.md)\n",
    "- [Negocio LATAM](../negocios_latam/README.md)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
