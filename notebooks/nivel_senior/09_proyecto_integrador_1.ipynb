{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6bceb9d",
   "metadata": {},
   "source": [
    "# üèÜ Proyecto Integrador Senior 1: Plataforma de Datos Completa\n",
    "\n",
    "Objetivo: dise√±ar e implementar una plataforma moderna de datos con governance, lakehouse, orquestaci√≥n, observabilidad y compliance.\n",
    "\n",
    "- Duraci√≥n: 180+ min (proyecto multi-d√≠a)\n",
    "- Dificultad: Muy Alta\n",
    "- Prerrequisitos: Todos los notebooks Senior 01‚Äì08"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e867067",
   "metadata": {},
   "source": [
    "## 1. Contexto y requerimientos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73cb5ee",
   "metadata": {},
   "source": [
    "**Empresa**: E-commerce global con 3 dominios de datos (Ventas, Log√≠stica, Anal√≠tica).\n",
    "\n",
    "**Requerimientos funcionales**:\n",
    "- Ingestar transacciones en tiempo real (Kafka) y batch nocturno (archivos SFTP).\n",
    "- Almacenar en data lakehouse (Parquet + Delta Lake) particionado por fecha y regi√≥n.\n",
    "- Cat√°logo central con metadatos, linaje y pol√≠ticas de acceso (Glue/Unity/DataHub).\n",
    "- Orquestaci√≥n diaria con Airflow: validaciones de calidad, transformaciones, reportes.\n",
    "- APIs de servicio (FastAPI) para consultas ad-hoc por BI y cient√≠ficos de datos.\n",
    "\n",
    "**Requerimientos no funcionales**:\n",
    "- Compliance GDPR: enmascaramiento de PII, derecho al olvido.\n",
    "- SLO: latencia p99 < 30 min, disponibilidad > 99.5%.\n",
    "- Costos: < $5000/mes, optimizaci√≥n continua (FinOps).\n",
    "- Observabilidad: logs estructurados, m√©tricas en Prometheus, linaje en DataHub.\n",
    "- Seguridad: IAM con m√≠nimo privilegio, cifrado at-rest y in-transit, auditor√≠a."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88bdb0bc",
   "metadata": {},
   "source": [
    "## 2. Arquitectura propuesta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938bdaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "arquitectura_diagrama = '''\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ  Transac-   ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ    Kafka     ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  Spark        ‚îÇ\n",
    "‚îÇ  ciones RT  ‚îÇ       ‚îÇ  (streaming) ‚îÇ       ‚îÇ  Streaming    ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "                                                      ‚îÇ\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê              ‚îÇ\n",
    "‚îÇ  Archivos   ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ   Airflow    ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
    "‚îÇ  SFTP Batch ‚îÇ       ‚îÇ  (orquesta)  ‚îÇ              ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò              ‚îÇ\n",
    "                                                     ‚ñº\n",
    "                      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "                      ‚îÇ  Data Lakehouse (S3 + Delta)     ‚îÇ\n",
    "                      ‚îÇ  - raw/                          ‚îÇ\n",
    "                      ‚îÇ  - curated/                      ‚îÇ\n",
    "                      ‚îÇ  - gold/ (agregados)             ‚îÇ\n",
    "                      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "                                ‚îÇ\n",
    "                ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "                ‚ñº               ‚ñº               ‚ñº\n",
    "         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "         ‚îÇ  Athena  ‚îÇ   ‚îÇ FastAPI  ‚îÇ   ‚îÇ   BI     ‚îÇ\n",
    "         ‚îÇ  (SQL)   ‚îÇ   ‚îÇ (APIs)   ‚îÇ   ‚îÇ (Tableau)‚îÇ\n",
    "         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "\n",
    "Observabilidad: Prometheus + Grafana + DataHub (linaje)\n",
    "Seguridad: IAM, KMS, CloudTrail, enmascaramiento PII\n",
    "'''\n",
    "print(arquitectura_diagrama)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35f7e2e",
   "metadata": {},
   "source": [
    "## 3. Componentes a implementar (checklist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17901a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "checklist = '''\n",
    "‚òê 1. Kafka cluster (Docker Compose local o MSK en AWS)\n",
    "‚òê 2. Productor de eventos simulados (transacciones)\n",
    "‚òê 3. Consumidor Spark Streaming ‚Üí Delta Lake (S3)\n",
    "‚òê 4. Airflow DAG batch: SFTP ‚Üí raw ‚Üí validaci√≥n ‚Üí curated ‚Üí gold\n",
    "‚òê 5. Validaciones de calidad con Great Expectations\n",
    "‚òê 6. Enmascaramiento de PII (email, tarjeta)\n",
    "‚òê 7. Cat√°logo con Glue Data Catalog o DataHub\n",
    "‚òê 8. Linaje con OpenLineage (plugin Airflow)\n",
    "‚òê 9. FastAPI endpoint para consultas SQL (proxy a Athena/Trino)\n",
    "‚òê 10. M√©tricas Prometheus exportadas por pipelines\n",
    "‚òê 11. Dashboard Grafana con SLOs y alertas\n",
    "‚òê 12. Pol√≠ticas IAM con m√≠nimo privilegio\n",
    "‚òê 13. Cifrado KMS para S3 y RDS\n",
    "‚òê 14. Auditor√≠a CloudTrail habilitada\n",
    "‚òê 15. Presupuestos y alertas de costos (AWS Budgets)\n",
    "‚òê 16. Documentaci√≥n t√©cnica y runbooks\n",
    "‚òê 17. Tests de integraci√≥n (Pytest)\n",
    "‚òê 18. CI/CD con GitHub Actions (lint, test, deploy)\n",
    "'''\n",
    "print(checklist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20bb8e10",
   "metadata": {},
   "source": [
    "## 4. Implementaci√≥n paso a paso"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58a21a9",
   "metadata": {},
   "source": [
    "### 4.1 Setup inicial\n",
    "- Crear bucket S3 con estructura `raw/`, `curated/`, `gold/`.\n",
    "- Configurar Glue Data Catalog con base de datos `ecommerce`.\n",
    "- Levantar Kafka local con Docker Compose (zookeeper + broker).\n",
    "\n",
    "### 4.2 Streaming path\n",
    "- Productor Python: genera eventos JSON (transacci√≥n_id, cliente_id, monto, timestamp).\n",
    "- Spark Structured Streaming: consume de Kafka, valida schema, escribe a Delta en `curated/ventas/`.\n",
    "- Checkpointing idempotente.\n",
    "\n",
    "### 4.3 Batch path\n",
    "- Airflow DAG: sensor SFTP ‚Üí download ‚Üí validate (GE) ‚Üí transform (Pandas/Spark) ‚Üí write Delta ‚Üí optimize.\n",
    "- Agregaciones gold: ventas por d√≠a/regi√≥n/producto.\n",
    "\n",
    "### 4.4 Governance y seguridad\n",
    "- Enmascarar email y tarjeta antes de escribir en curated.\n",
    "- Registrar linaje en DataHub v√≠a OpenLineage.\n",
    "- Configurar IAM roles para Spark, Airflow, APIs.\n",
    "\n",
    "### 4.5 Observabilidad\n",
    "- Exportar m√©tricas de conteo, latencia, errores.\n",
    "- Dashboard Grafana con paneles por pipeline.\n",
    "- Alertas en Slack si SLO violado.\n",
    "\n",
    "### 4.6 Servicio de consultas\n",
    "- FastAPI endpoint `/query` que ejecuta SQL en Athena y retorna JSON.\n",
    "- Cach√© Redis para queries repetitivas.\n",
    "- Rate limiting por API key."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5728559c",
   "metadata": {},
   "source": [
    "## 5. Entregables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460d2f42",
   "metadata": {},
   "source": [
    "- Repositorio Git con c√≥digo (pipelines, DAGs, APIs, tests).\n",
    "- Diagrama de arquitectura actualizado.\n",
    "- Documento de dise√±o (decisiones t√©cnicas, trade-offs).\n",
    "- Dashboard Grafana exportado (JSON).\n",
    "- Runbook de operaciones (troubleshooting, rollback).\n",
    "- Video/demo ejecutando pipeline end-to-end."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc021c5",
   "metadata": {},
   "source": [
    "## 6. Evaluaci√≥n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1259a0dd",
   "metadata": {},
   "source": [
    "- Funcionalidad: ¬øpipelines ejecutan correctamente?\n",
    "- Calidad: ¬øvalidaciones y tests implementados?\n",
    "- Observabilidad: ¬øm√©tricas y linaje visibles?\n",
    "- Seguridad: ¬øIAM, cifrado, PII enmascarado?\n",
    "- Costos: ¬øpresupuesto respetado?\n",
    "- Documentaci√≥n: ¬øclara y completa?"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
