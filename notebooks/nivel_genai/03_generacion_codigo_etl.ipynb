{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42d426fb",
   "metadata": {},
   "source": [
    "# 🔧 Generación Automática de Código ETL con LLMs\n",
    "\n",
    "Objetivo: automatizar la creación de pipelines ETL, transformaciones y scripts de datos usando IA generativa, con validación y best practices.\n",
    "\n",
    "- Duración: 90-120 min\n",
    "- Dificultad: Media/Alta\n",
    "- Prerrequisitos: GenAI 01-02, experiencia con ETL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca1fbdf",
   "metadata": {},
   "source": [
    "### 🏗️ **Code Generation Architecture: From Prompt to Production Pipeline**\n",
    "\n",
    "**Evolution of ETL Code Generation:**\n",
    "\n",
    "```\n",
    "2015-2019: Template-Based Generation\n",
    "  ├─ Jinja2 templates con parámetros\n",
    "  ├─ Cookiecutter projects\n",
    "  └─ Limited flexibility, manual configuration\n",
    "\n",
    "2020-2022: GPT-3 Era (Codex)\n",
    "  ├─ GitHub Copilot (autocomplete)\n",
    "  ├─ Function-level generation\n",
    "  └─ Still requires significant editing\n",
    "\n",
    "2023-2024: GPT-4 + Specialized Models\n",
    "  ├─ Full pipeline generation\n",
    "  ├─ Multi-file projects\n",
    "  ├─ Self-correction capabilities\n",
    "  └─ Context-aware refactoring\n",
    "\n",
    "2024+: LLM + MCP (Model Context Protocol)\n",
    "  ├─ RAG with codebase context\n",
    "  ├─ Real-time validation\n",
    "  ├─ Automated testing generation\n",
    "  └─ Production-ready code\n",
    "```\n",
    "\n",
    "**Code Generation System Architecture:**\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────────┐\n",
    "│  INPUT: Natural Language Requirements                       │\n",
    "│  \"Create ETL pipeline: S3 CSV → validate → Snowflake\"      │\n",
    "└─────────────────────┬───────────────────────────────────────┘\n",
    "                      │\n",
    "        ┌─────────────┴─────────────┐\n",
    "        │   LAYER 1: SPECIFICATION   │\n",
    "        │   ├─ Parse requirements    │\n",
    "        │   ├─ Identify tech stack   │\n",
    "        │   └─ Extract constraints    │\n",
    "        └─────────────┬───────────────┘\n",
    "                      │\n",
    "        ┌─────────────┴─────────────┐\n",
    "        │   LAYER 2: CONTEXT RETRIEVAL (RAG) │\n",
    "        │   ├─ Search codebase (embeddings)  │\n",
    "        │   ├─ Find similar patterns         │\n",
    "        │   ├─ Retrieve docs/examples        │\n",
    "        │   └─ Load company standards        │\n",
    "        └─────────────┬────────────────────────┘\n",
    "                      │\n",
    "        ┌─────────────┴─────────────┐\n",
    "        │   LAYER 3: CODE GENERATION │\n",
    "        │   ├─ Main pipeline (LLM)   │\n",
    "        │   ├─ Config files (YAML)   │\n",
    "        │   ├─ Tests (pytest)        │\n",
    "        │   └─ Docs (README)         │\n",
    "        └─────────────┬───────────────┘\n",
    "                      │\n",
    "        ┌─────────────┴─────────────┐\n",
    "        │   LAYER 4: VALIDATION      │\n",
    "        │   ├─ Syntax check (AST)    │\n",
    "        │   ├─ Linting (ruff/flake8) │\n",
    "        │   ├─ Type check (mypy)     │\n",
    "        │   ├─ Security (bandit)     │\n",
    "        │   └─ Complexity (radon)    │\n",
    "        └─────────────┬───────────────┘\n",
    "                      │\n",
    "        ┌─────────────┴─────────────┐\n",
    "        │   LAYER 5: SELF-CORRECTION │\n",
    "        │   ├─ Execute validation    │\n",
    "        │   ├─ Parse error messages  │\n",
    "        │   ├─ Regenerate fixes      │\n",
    "        │   └─ Iterate (max 3 times) │\n",
    "        └─────────────┬───────────────┘\n",
    "                      │\n",
    "        ┌─────────────┴─────────────┐\n",
    "        │   LAYER 6: TESTING         │\n",
    "        │   ├─ Generate unit tests   │\n",
    "        │   ├─ Generate integration  │\n",
    "        │   ├─ Execute test suite    │\n",
    "        │   └─ Coverage report       │\n",
    "        └─────────────┬───────────────┘\n",
    "                      │\n",
    "┌─────────────────────┴───────────────────────────────────────┐\n",
    "│  OUTPUT: Production-Ready ETL Pipeline                      │\n",
    "│  ├─ pipeline.py (main code)                                │\n",
    "│  ├─ config.yaml (configuration)                            │\n",
    "│  ├─ test_pipeline.py (tests with 80%+ coverage)           │\n",
    "│  ├─ requirements.txt (dependencies)                        │\n",
    "│  ├─ Dockerfile (containerization)                          │\n",
    "│  ├─ README.md (documentation)                              │\n",
    "│  └─ .github/workflows/ci.yml (CI/CD)                      │\n",
    "└─────────────────────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "**Model Selection for Code Generation:**\n",
    "\n",
    "| Model | Use Case | Strengths | Limitations | Cost/1M tokens |\n",
    "|-------|----------|-----------|-------------|----------------|\n",
    "| **GPT-4o** | Complex ETL pipelines, multi-step logic | Highest accuracy (95%), excellent reasoning, handles edge cases | Slower (4-8s), expensive | $2.50 in / $10 out |\n",
    "| **Claude 3.5 Sonnet** | Data transformations, business logic | Strong code quality, good at SQL/Pandas, excellent refactoring | Limited context vs GPT-4, occasional verbosity | $3 in / $15 out |\n",
    "| **GPT-3.5-turbo** | Simple scripts, boilerplate code | Fast (1-2s), cheap, good for templates | Less sophisticated logic, more errors | $0.50 in / $1.50 out |\n",
    "| **Codestral (Mistral)** | OSS alternative, on-prem deployment | Open source, fast inference, privacy | Lower accuracy (75%), needs fine-tuning | Self-hosted |\n",
    "| **Code Llama 70B** | Self-hosted code generation | Free, customizable, no API limits | Requires GPU (A100), 70% accuracy | $0 (hardware only) |\n",
    "| **Gemini 1.5 Pro** | Large context pipelines (2M tokens) | Massive context window, multimodal, cost-effective | Newer model, less proven | $1.25 in / $5 out |\n",
    "\n",
    "**Prompt Engineering for Code Generation:**\n",
    "\n",
    "```python\n",
    "def build_code_generation_prompt(\n",
    "    requirements: str,\n",
    "    tech_stack: List[str],\n",
    "    context: Optional[str] = None,\n",
    "    constraints: Optional[Dict] = None\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Construye prompt optimizado para generación de código ETL.\n",
    "    \n",
    "    Best Practices:\n",
    "    - Especificar tech stack explícitamente\n",
    "    - Incluir ejemplos del codebase (few-shot)\n",
    "    - Definir estándares de calidad\n",
    "    - Solicitar explicaciones (razonamiento)\n",
    "    \"\"\"\n",
    "    \n",
    "    prompt = f\"\"\"You are an expert Data Engineer specializing in production ETL pipelines.\n",
    "\n",
    "**Requirements:**\n",
    "{requirements}\n",
    "\n",
    "**Tech Stack:**\n",
    "{', '.join(tech_stack)}\n",
    "\n",
    "**Coding Standards:**\n",
    "- Python 3.11+ with type hints (PEP 484)\n",
    "- Error handling with try-except and logging\n",
    "- Docstrings (Google style)\n",
    "- Modular functions (max 50 lines)\n",
    "- Configuration externalized (YAML/env vars)\n",
    "- Idempotent operations (safe to re-run)\n",
    "\n",
    "**Quality Checklist:**\n",
    "✅ No hardcoded credentials\n",
    "✅ Parameterized queries (prevent SQL injection)\n",
    "✅ Retry logic with exponential backoff\n",
    "✅ Metrics instrumentation (Prometheus)\n",
    "✅ Comprehensive logging (structured JSON)\n",
    "✅ Unit tests (pytest, 80%+ coverage)\n",
    "\n",
    "\"\"\"\n",
    "    \n",
    "    if context:\n",
    "        prompt += f\"\\n**Codebase Context (existing patterns):**\\n{context}\\n\"\n",
    "    \n",
    "    if constraints:\n",
    "        prompt += f\"\\n**Constraints:**\\n\"\n",
    "        for key, value in constraints.items():\n",
    "            prompt += f\"- {key}: {value}\\n\"\n",
    "    \n",
    "    prompt += \"\"\"\n",
    "**Output Format:**\n",
    "1. Main pipeline code (complete and executable)\n",
    "2. Configuration file (YAML)\n",
    "3. Unit tests (pytest)\n",
    "4. Brief explanation of design decisions\n",
    "\n",
    "Generate the code:\n",
    "\"\"\"\n",
    "    return prompt\n",
    "```\n",
    "\n",
    "**Example: Full Pipeline Generation**\n",
    "\n",
    "```python\n",
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))\n",
    "\n",
    "requirements = \"\"\"\n",
    "Create an ETL pipeline that:\n",
    "1. Extracts daily sales data from PostgreSQL (table: raw_sales)\n",
    "2. Transforms:\n",
    "   - Deduplicate by (transaction_id, timestamp)\n",
    "   - Filter out refunds (amount < 0)\n",
    "   - Enrich with customer tier from Redis cache\n",
    "   - Aggregate metrics: total_sales, avg_order_value by (date, customer_tier)\n",
    "3. Loads to Snowflake (table: analytics.daily_sales_summary)\n",
    "4. Send Slack notification with summary statistics\n",
    "\"\"\"\n",
    "\n",
    "tech_stack = [\n",
    "    \"Python 3.11\",\n",
    "    \"pandas\",\n",
    "    \"SQLAlchemy (PostgreSQL)\",\n",
    "    \"redis-py\",\n",
    "    \"snowflake-connector-python\",\n",
    "    \"slack-sdk\",\n",
    "    \"pydantic (config validation)\"\n",
    "]\n",
    "\n",
    "prompt = build_code_generation_prompt(\n",
    "    requirements=requirements,\n",
    "    tech_stack=tech_stack,\n",
    "    constraints={\n",
    "        \"max_memory\": \"2GB\",\n",
    "        \"timeout\": \"15 minutes\",\n",
    "        \"batch_size\": \"10,000 rows\"\n",
    "    }\n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    temperature=0.2,  # Low temperature for deterministic code\n",
    "    max_tokens=4000\n",
    ")\n",
    "\n",
    "generated_code = response.choices[0].message.content\n",
    "print(generated_code)\n",
    "```\n",
    "\n",
    "**RAG-Enhanced Code Generation (Context from Codebase):**\n",
    "\n",
    "```python\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "\n",
    "# Initialize embeddings\n",
    "embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "chroma_client = chromadb.Client()\n",
    "code_collection = chroma_client.create_collection(\"codebase\")\n",
    "\n",
    "# Index existing codebase\n",
    "def index_codebase(codebase_path: str):\n",
    "    \"\"\"Embeds all Python files for similarity search.\"\"\"\n",
    "    for file_path in Path(codebase_path).rglob(\"*.py\"):\n",
    "        with open(file_path) as f:\n",
    "            code = f.read()\n",
    "        \n",
    "        embedding = embedder.encode(code)\n",
    "        code_collection.add(\n",
    "            ids=[str(file_path)],\n",
    "            embeddings=[embedding.tolist()],\n",
    "            documents=[code],\n",
    "            metadatas=[{\"path\": str(file_path), \"type\": \"python\"}]\n",
    "        )\n",
    "\n",
    "# Retrieve similar code\n",
    "def get_similar_code(query: str, n_results: int = 3) -> List[str]:\n",
    "    \"\"\"Finds similar code patterns from existing codebase.\"\"\"\n",
    "    query_embedding = embedder.encode(query)\n",
    "    \n",
    "    results = code_collection.query(\n",
    "        query_embeddings=[query_embedding.tolist()],\n",
    "        n_results=n_results\n",
    "    )\n",
    "    \n",
    "    return results['documents'][0]  # Top-k similar code snippets\n",
    "\n",
    "# Enhanced generation with context\n",
    "requirements = \"Create Spark ETL for parquet → delta lake\"\n",
    "similar_code = get_similar_code(requirements, n_results=2)\n",
    "\n",
    "prompt = f\"\"\"\n",
    "{requirements}\n",
    "\n",
    "**Reference implementations from codebase:**\n",
    "\n",
    "Example 1:\n",
    "{similar_code[0]}\n",
    "\n",
    "Example 2:\n",
    "{similar_code[1]}\n",
    "\n",
    "Follow the same patterns and coding style. Generate code:\n",
    "\"\"\"\n",
    "\n",
    "# Generate with context (accuracy improves ~20%)\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    temperature=0.2\n",
    ")\n",
    "```\n",
    "\n",
    "**Token Optimization for Cost Reduction:**\n",
    "\n",
    "```python\n",
    "import tiktoken\n",
    "\n",
    "def optimize_prompt(prompt: str, max_tokens: int = 2000) -> str:\n",
    "    \"\"\"\n",
    "    Reduce prompt tokens while preserving essential information.\n",
    "    Strategies:\n",
    "    1. Remove redundant examples\n",
    "    2. Compress documentation\n",
    "    3. Use abbreviations for repetitive terms\n",
    "    \"\"\"\n",
    "    encoding = tiktoken.encoding_for_model(\"gpt-4\")\n",
    "    tokens = encoding.encode(prompt)\n",
    "    \n",
    "    if len(tokens) <= max_tokens:\n",
    "        return prompt\n",
    "    \n",
    "    # Truncate examples, keep requirements\n",
    "    lines = prompt.split('\\n')\n",
    "    essential_lines = [l for l in lines if 'Requirements' in l or 'Tech Stack' in l]\n",
    "    \n",
    "    optimized = '\\n'.join(essential_lines)\n",
    "    return optimized\n",
    "\n",
    "# Cost comparison\n",
    "original_tokens = len(tiktoken.encoding_for_model(\"gpt-4\").encode(prompt))\n",
    "optimized_prompt = optimize_prompt(prompt, max_tokens=1500)\n",
    "optimized_tokens = len(tiktoken.encoding_for_model(\"gpt-4\").encode(optimized_prompt))\n",
    "\n",
    "print(f\"Original: {original_tokens} tokens → ${original_tokens * 0.00001:.4f}\")\n",
    "print(f\"Optimized: {optimized_tokens} tokens → ${optimized_tokens * 0.00001:.4f}\")\n",
    "print(f\"Savings: {((original_tokens - optimized_tokens) / original_tokens * 100):.1f}%\")\n",
    "```\n",
    "\n",
    "---\n",
    "**Autor:** Luis J. Raigoso V. (LJRV)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede8e780",
   "metadata": {},
   "source": [
    "### 🛡️ **Code Validation & Security: Multi-Layer Quality Assurance**\n",
    "\n",
    "**Validation Pipeline Architecture:**\n",
    "\n",
    "```\n",
    "Generated Code\n",
    "     │\n",
    "     ▼\n",
    "┌─────────────────────────────────────┐\n",
    "│  LAYER 1: SYNTAX VALIDATION         │\n",
    "│  ├─ AST Parsing (ast.parse)         │\n",
    "│  ├─ Compile Check (compile())       │\n",
    "│  └─ Python Version Compatibility    │\n",
    "│  → Result: Syntactically valid code │\n",
    "└────────────┬────────────────────────┘\n",
    "             │ PASS\n",
    "             ▼\n",
    "┌─────────────────────────────────────┐\n",
    "│  LAYER 2: STATIC ANALYSIS           │\n",
    "│  ├─ Linting (ruff/flake8/pylint)    │\n",
    "│  ├─ Type Checking (mypy)            │\n",
    "│  ├─ Complexity (radon: CC < 10)     │\n",
    "│  ├─ Code Smells (pylint)            │\n",
    "│  └─ Formatting (black/autopep8)     │\n",
    "│  → Result: Clean, readable code     │\n",
    "└────────────┬────────────────────────┘\n",
    "             │ PASS\n",
    "             ▼\n",
    "┌─────────────────────────────────────┐\n",
    "│  LAYER 3: SECURITY SCAN             │\n",
    "│  ├─ Bandit (vulnerability detection)│\n",
    "│  ├─ Safety (dependency vulnerabilities)│\n",
    "│  ├─ Secrets Detection (detect-secrets)│\n",
    "│  ├─ SQL Injection Check (sqlparse)  │\n",
    "│  └─ Path Traversal Check            │\n",
    "│  → Result: Secure code              │\n",
    "└────────────┬────────────────────────┘\n",
    "             │ PASS\n",
    "             ▼\n",
    "┌─────────────────────────────────────┐\n",
    "│  LAYER 4: FUNCTIONAL TESTING        │\n",
    "│  ├─ Unit Tests (pytest)             │\n",
    "│  ├─ Integration Tests (testcontainers)│\n",
    "│  ├─ Property-Based (hypothesis)     │\n",
    "│  ├─ Coverage (pytest-cov > 80%)     │\n",
    "│  └─ Performance (locust benchmarks) │\n",
    "│  → Result: Functionally correct     │\n",
    "└────────────┬────────────────────────┘\n",
    "             │ PASS\n",
    "             ▼\n",
    "┌─────────────────────────────────────┐\n",
    "│  LAYER 5: RUNTIME VALIDATION        │\n",
    "│  ├─ Dry-Run with Sample Data        │\n",
    "│  ├─ Memory Profiling (memory_profiler)│\n",
    "│  ├─ Execution Time Check            │\n",
    "│  └─ Resource Limits (cgroups)       │\n",
    "│  → Result: Production-ready         │\n",
    "└─────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "**Implementation: Comprehensive Validation Suite**\n",
    "\n",
    "```python\n",
    "import ast\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple\n",
    "import tempfile\n",
    "import json\n",
    "\n",
    "class CodeValidator:\n",
    "    \"\"\"\n",
    "    Multi-layer validation system for LLM-generated code.\n",
    "    \n",
    "    Usage:\n",
    "        validator = CodeValidator()\n",
    "        results = validator.validate_all(generated_code)\n",
    "        if results['is_valid']:\n",
    "            print(\"✅ Code is production-ready\")\n",
    "        else:\n",
    "            print(f\"❌ Validation failed: {results['errors']}\")\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.validation_results = {}\n",
    "    \n",
    "    def validate_syntax(self, code: str) -> Tuple[bool, str]:\n",
    "        \"\"\"\n",
    "        Layer 1: AST parsing and compilation.\n",
    "        \n",
    "        Catches:\n",
    "        - SyntaxError (invalid Python)\n",
    "        - IndentationError\n",
    "        - TabError\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Parse to AST\n",
    "            tree = ast.parse(code)\n",
    "            \n",
    "            # Compile (more thorough than parse)\n",
    "            compile(code, '<generated>', 'exec')\n",
    "            \n",
    "            # Check for common anti-patterns\n",
    "            issues = []\n",
    "            for node in ast.walk(tree):\n",
    "                # Detect 'exec' usage (security risk)\n",
    "                if isinstance(node, ast.Expr) and isinstance(node.value, ast.Call):\n",
    "                    if hasattr(node.value.func, 'id') and node.value.func.id == 'exec':\n",
    "                        issues.append(\"⚠️ Usage of 'exec()' detected (security risk)\")\n",
    "                \n",
    "                # Detect bare 'except' (anti-pattern)\n",
    "                if isinstance(node, ast.ExceptHandler) and node.type is None:\n",
    "                    issues.append(\"⚠️ Bare 'except:' clause detected (catch specific exceptions)\")\n",
    "            \n",
    "            if issues:\n",
    "                return True, \"Syntax valid but has warnings:\\n\" + \"\\n\".join(issues)\n",
    "            \n",
    "            return True, \"✅ Syntax valid\"\n",
    "        \n",
    "        except SyntaxError as e:\n",
    "            return False, f\"❌ Syntax Error at line {e.lineno}: {e.msg}\"\n",
    "        except Exception as e:\n",
    "            return False, f\"❌ Compilation Error: {str(e)}\"\n",
    "    \n",
    "    def validate_linting(self, code: str) -> Tuple[bool, str]:\n",
    "        \"\"\"\n",
    "        Layer 2: Static analysis with ruff (faster than flake8).\n",
    "        \n",
    "        Checks:\n",
    "        - PEP 8 compliance\n",
    "        - Unused imports/variables\n",
    "        - Undefined names\n",
    "        - Line length violations\n",
    "        \"\"\"\n",
    "        with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f:\n",
    "            f.write(code)\n",
    "            temp_path = f.name\n",
    "        \n",
    "        try:\n",
    "            # Ruff (Rust-based, ~100x faster than flake8)\n",
    "            result = subprocess.run(\n",
    "                ['ruff', 'check', temp_path, '--output-format', 'json'],\n",
    "                capture_output=True,\n",
    "                text=True,\n",
    "                timeout=10\n",
    "            )\n",
    "            \n",
    "            if result.returncode == 0:\n",
    "                return True, \"✅ No linting issues\"\n",
    "            \n",
    "            # Parse JSON output\n",
    "            issues = json.loads(result.stdout)\n",
    "            error_summary = []\n",
    "            for issue in issues[:5]:  # Show top 5\n",
    "                error_summary.append(\n",
    "                    f\"Line {issue['location']['row']}: {issue['code']} - {issue['message']}\"\n",
    "                )\n",
    "            \n",
    "            return False, f\"❌ Linting issues found:\\n\" + \"\\n\".join(error_summary)\n",
    "        \n",
    "        except FileNotFoundError:\n",
    "            # Fallback to flake8 if ruff not installed\n",
    "            result = subprocess.run(\n",
    "                ['flake8', temp_path, '--max-line-length', '100'],\n",
    "                capture_output=True,\n",
    "                text=True,\n",
    "                timeout=10\n",
    "            )\n",
    "            \n",
    "            if result.returncode == 0:\n",
    "                return True, \"✅ No linting issues (flake8)\"\n",
    "            \n",
    "            return False, f\"❌ Flake8 issues:\\n{result.stdout[:500]}\"\n",
    "        \n",
    "        except subprocess.TimeoutExpired:\n",
    "            return False, \"❌ Linting timeout (code too large)\"\n",
    "        \n",
    "        finally:\n",
    "            Path(temp_path).unlink()\n",
    "    \n",
    "    def validate_types(self, code: str) -> Tuple[bool, str]:\n",
    "        \"\"\"\n",
    "        Layer 2.5: Type checking with mypy.\n",
    "        \n",
    "        Ensures:\n",
    "        - Type hints are consistent\n",
    "        - No type mismatches\n",
    "        - Return types match annotations\n",
    "        \"\"\"\n",
    "        with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f:\n",
    "            f.write(code)\n",
    "            temp_path = f.name\n",
    "        \n",
    "        try:\n",
    "            result = subprocess.run(\n",
    "                ['mypy', temp_path, '--no-error-summary', '--show-error-codes'],\n",
    "                capture_output=True,\n",
    "                text=True,\n",
    "                timeout=15\n",
    "            )\n",
    "            \n",
    "            if result.returncode == 0:\n",
    "                return True, \"✅ Type checking passed\"\n",
    "            \n",
    "            # Filter errors (ignore missing imports for now)\n",
    "            errors = [line for line in result.stdout.split('\\n') \n",
    "                     if 'error:' in line and 'import' not in line.lower()]\n",
    "            \n",
    "            if not errors:\n",
    "                return True, \"✅ Type checking passed (ignoring import issues)\"\n",
    "            \n",
    "            return False, f\"❌ Type errors:\\n\" + \"\\n\".join(errors[:3])\n",
    "        \n",
    "        except FileNotFoundError:\n",
    "            return True, \"⚠️ mypy not installed (skipping type check)\"\n",
    "        \n",
    "        except subprocess.TimeoutExpired:\n",
    "            return False, \"❌ Type checking timeout\"\n",
    "        \n",
    "        finally:\n",
    "            Path(temp_path).unlink()\n",
    "    \n",
    "    def validate_security(self, code: str) -> Tuple[bool, str]:\n",
    "        \"\"\"\n",
    "        Layer 3: Security vulnerability scanning with bandit.\n",
    "        \n",
    "        Detects:\n",
    "        - Hardcoded credentials\n",
    "        - SQL injection risks\n",
    "        - Shell injection (subprocess)\n",
    "        - Insecure cryptography\n",
    "        - Path traversal vulnerabilities\n",
    "        \"\"\"\n",
    "        with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f:\n",
    "            f.write(code)\n",
    "            temp_path = f.name\n",
    "        \n",
    "        try:\n",
    "            result = subprocess.run(\n",
    "                ['bandit', '-r', temp_path, '-f', 'json'],\n",
    "                capture_output=True,\n",
    "                text=True,\n",
    "                timeout=10\n",
    "            )\n",
    "            \n",
    "            report = json.loads(result.stdout)\n",
    "            \n",
    "            # Filter high/medium severity issues\n",
    "            critical_issues = [\n",
    "                issue for issue in report.get('results', [])\n",
    "                if issue['issue_severity'] in ['HIGH', 'MEDIUM']\n",
    "            ]\n",
    "            \n",
    "            if not critical_issues:\n",
    "                return True, \"✅ No security vulnerabilities detected\"\n",
    "            \n",
    "            # Format error messages\n",
    "            error_summary = []\n",
    "            for issue in critical_issues[:3]:\n",
    "                error_summary.append(\n",
    "                    f\"Line {issue['line_number']}: [{issue['issue_severity']}] \"\n",
    "                    f\"{issue['issue_text']}\"\n",
    "                )\n",
    "            \n",
    "            return False, f\"❌ Security issues found:\\n\" + \"\\n\".join(error_summary)\n",
    "        \n",
    "        except FileNotFoundError:\n",
    "            # Manual security checks if bandit not installed\n",
    "            dangerous_patterns = [\n",
    "                ('eval(', 'Code execution vulnerability'),\n",
    "                ('exec(', 'Code execution vulnerability'),\n",
    "                ('__import__', 'Dynamic import (potential code injection)'),\n",
    "                ('pickle.loads', 'Insecure deserialization'),\n",
    "                ('password = \"', 'Hardcoded password'),\n",
    "                ('api_key = \"', 'Hardcoded API key'),\n",
    "                ('token = \"', 'Hardcoded token'),\n",
    "            ]\n",
    "            \n",
    "            found_issues = []\n",
    "            for pattern, description in dangerous_patterns:\n",
    "                if pattern in code:\n",
    "                    found_issues.append(f\"⚠️ {description}: '{pattern}' found\")\n",
    "            \n",
    "            if found_issues:\n",
    "                return False, f\"❌ Security issues:\\n\" + \"\\n\".join(found_issues)\n",
    "            \n",
    "            return True, \"✅ Basic security check passed (install bandit for thorough scan)\"\n",
    "        \n",
    "        finally:\n",
    "            Path(temp_path).unlink()\n",
    "    \n",
    "    def validate_complexity(self, code: str) -> Tuple[bool, str]:\n",
    "        \"\"\"\n",
    "        Layer 2: Cyclomatic complexity analysis with radon.\n",
    "        \n",
    "        Standards:\n",
    "        - A: CC 1-5 (simple)\n",
    "        - B: CC 6-10 (more complex)\n",
    "        - C: CC 11-20 (complex) ← threshold\n",
    "        - D: CC 21-30 (very complex)\n",
    "        - F: CC 31+ (extremely complex)\n",
    "        \"\"\"\n",
    "        with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f:\n",
    "            f.write(code)\n",
    "            temp_path = f.name\n",
    "        \n",
    "        try:\n",
    "            result = subprocess.run(\n",
    "                ['radon', 'cc', temp_path, '-j'],  # JSON output\n",
    "                capture_output=True,\n",
    "                text=True,\n",
    "                timeout=10\n",
    "            )\n",
    "            \n",
    "            complexity_data = json.loads(result.stdout)\n",
    "            \n",
    "            # Check for functions with CC > 10\n",
    "            complex_functions = []\n",
    "            for file_data in complexity_data.values():\n",
    "                for item in file_data:\n",
    "                    if item['complexity'] > 10:\n",
    "                        complex_functions.append(\n",
    "                            f\"{item['name']}: CC={item['complexity']} (line {item['lineno']})\"\n",
    "                        )\n",
    "            \n",
    "            if not complex_functions:\n",
    "                return True, \"✅ Complexity within acceptable range\"\n",
    "            \n",
    "            return False, f\"⚠️ High complexity detected:\\n\" + \"\\n\".join(complex_functions)\n",
    "        \n",
    "        except FileNotFoundError:\n",
    "            return True, \"⚠️ radon not installed (skipping complexity check)\"\n",
    "        \n",
    "        finally:\n",
    "            Path(temp_path).unlink()\n",
    "    \n",
    "    def validate_all(self, code: str) -> Dict:\n",
    "        \"\"\"\n",
    "        Execute full validation pipeline.\n",
    "        \n",
    "        Returns:\n",
    "            {\n",
    "                'is_valid': bool,\n",
    "                'syntax': {'passed': bool, 'message': str},\n",
    "                'linting': {...},\n",
    "                'types': {...},\n",
    "                'security': {...},\n",
    "                'complexity': {...},\n",
    "                'overall_score': float (0-100)\n",
    "            }\n",
    "        \"\"\"\n",
    "        results = {}\n",
    "        \n",
    "        # Layer 1: Syntax (critical - must pass)\n",
    "        syntax_pass, syntax_msg = self.validate_syntax(code)\n",
    "        results['syntax'] = {'passed': syntax_pass, 'message': syntax_msg}\n",
    "        \n",
    "        if not syntax_pass:\n",
    "            results['is_valid'] = False\n",
    "            results['overall_score'] = 0\n",
    "            return results\n",
    "        \n",
    "        # Layer 2: Linting\n",
    "        lint_pass, lint_msg = self.validate_linting(code)\n",
    "        results['linting'] = {'passed': lint_pass, 'message': lint_msg}\n",
    "        \n",
    "        # Layer 2.5: Types\n",
    "        types_pass, types_msg = self.validate_types(code)\n",
    "        results['types'] = {'passed': types_pass, 'message': types_msg}\n",
    "        \n",
    "        # Layer 3: Security (critical)\n",
    "        security_pass, security_msg = self.validate_security(code)\n",
    "        results['security'] = {'passed': security_pass, 'message': security_msg}\n",
    "        \n",
    "        # Layer 2: Complexity\n",
    "        complexity_pass, complexity_msg = self.validate_complexity(code)\n",
    "        results['complexity'] = {'passed': complexity_pass, 'message': complexity_msg}\n",
    "        \n",
    "        # Calculate overall score\n",
    "        weights = {\n",
    "            'syntax': 30,       # Critical\n",
    "            'security': 30,     # Critical\n",
    "            'linting': 15,\n",
    "            'types': 15,\n",
    "            'complexity': 10\n",
    "        }\n",
    "        \n",
    "        score = sum(\n",
    "            weights[key] for key, value in results.items()\n",
    "            if key in weights and value.get('passed', False)\n",
    "        )\n",
    "        \n",
    "        results['overall_score'] = score\n",
    "        results['is_valid'] = score >= 70  # 70% threshold for production\n",
    "        \n",
    "        return results\n",
    "\n",
    "# Example usage\n",
    "validator = CodeValidator()\n",
    "\n",
    "generated_code = '''\n",
    "def process_sales(data):\n",
    "    import pandas as pd\n",
    "    df = pd.DataFrame(data)\n",
    "    df['total'] = df['quantity'] * df['price']\n",
    "    return df.to_dict('records')\n",
    "'''\n",
    "\n",
    "results = validator.validate_all(generated_code)\n",
    "print(f\"Overall Score: {results['overall_score']}/100\")\n",
    "print(f\"Production Ready: {results['is_valid']}\")\n",
    "for check, result in results.items():\n",
    "    if isinstance(result, dict) and 'message' in result:\n",
    "        print(f\"{check.upper()}: {result['message']}\")\n",
    "```\n",
    "\n",
    "**Self-Correction Loop with LLM:**\n",
    "\n",
    "```python\n",
    "def self_correct_code(\n",
    "    code: str,\n",
    "    validation_results: Dict,\n",
    "    max_attempts: int = 3\n",
    ") -> Tuple[str, bool]:\n",
    "    \"\"\"\n",
    "    Iteratively fix code based on validation errors.\n",
    "    \n",
    "    Strategy:\n",
    "    1. Extract error messages from validation\n",
    "    2. Send to LLM with context: original code + errors\n",
    "    3. Re-validate corrected code\n",
    "    4. Repeat until valid or max_attempts reached\n",
    "    \"\"\"\n",
    "    \n",
    "    for attempt in range(max_attempts):\n",
    "        # Check if already valid\n",
    "        if validation_results['is_valid']:\n",
    "            return code, True\n",
    "        \n",
    "        # Collect error messages\n",
    "        errors = []\n",
    "        for check, result in validation_results.items():\n",
    "            if isinstance(result, dict) and not result.get('passed', True):\n",
    "                errors.append(f\"{check}: {result['message']}\")\n",
    "        \n",
    "        # Generate correction prompt\n",
    "        correction_prompt = f\"\"\"\n",
    "Fix the following Python code based on validation errors:\n",
    "\n",
    "**Original Code:**\n",
    "```python\n",
    "{code}\n",
    "```\n",
    "\n",
    "**Validation Errors:**\n",
    "{chr(10).join(errors)}\n",
    "\n",
    "**Instructions:**\n",
    "- Fix all syntax, linting, type, and security issues\n",
    "- Maintain the original functionality\n",
    "- Do not add unnecessary complexity\n",
    "- Return only the corrected code (no explanations)\n",
    "\n",
    "**Corrected Code:**\n",
    "\"\"\"\n",
    "        \n",
    "        # Call LLM for correction\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[{\"role\": \"user\", \"content\": correction_prompt}],\n",
    "            temperature=0.1  # Deterministic fixes\n",
    "        )\n",
    "        \n",
    "        corrected_code = response.choices[0].message.content.strip()\n",
    "        corrected_code = corrected_code.replace('```python', '').replace('```', '').strip()\n",
    "        \n",
    "        # Re-validate\n",
    "        validation_results = validator.validate_all(corrected_code)\n",
    "        code = corrected_code\n",
    "        \n",
    "        print(f\"Attempt {attempt + 1}: Score = {validation_results['overall_score']}/100\")\n",
    "        \n",
    "        if validation_results['is_valid']:\n",
    "            return code, True\n",
    "    \n",
    "    return code, False  # Failed after max_attempts\n",
    "\n",
    "# Example: Self-correction workflow\n",
    "initial_code = '''\n",
    "def risky_function(user_input):\n",
    "    result = eval(user_input)  # Security issue!\n",
    "    return result\n",
    "'''\n",
    "\n",
    "validation = validator.validate_all(initial_code)\n",
    "print(f\"Initial Score: {validation['overall_score']}/100\")\n",
    "\n",
    "corrected_code, success = self_correct_code(initial_code, validation)\n",
    "if success:\n",
    "    print(\"✅ Code successfully corrected and validated!\")\n",
    "    print(corrected_code)\n",
    "else:\n",
    "    print(\"❌ Failed to correct code after 3 attempts\")\n",
    "```\n",
    "\n",
    "**Secrets Detection & Environment Variable Enforcement:**\n",
    "\n",
    "```python\n",
    "import re\n",
    "\n",
    "def detect_secrets(code: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Detect hardcoded secrets and suggest env var usage.\n",
    "    \n",
    "    Patterns:\n",
    "    - API keys (alphanumeric strings 20+ chars)\n",
    "    - Passwords in assignments\n",
    "    - AWS access keys\n",
    "    - Database connection strings with credentials\n",
    "    \"\"\"\n",
    "    \n",
    "    patterns = [\n",
    "        (r'password\\s*=\\s*[\"\\'](.{3,})[\"\\']', 'Hardcoded password'),\n",
    "        (r'api_key\\s*=\\s*[\"\\'](.{10,})[\"\\']', 'Hardcoded API key'),\n",
    "        (r'secret\\s*=\\s*[\"\\'](.{10,})[\"\\']', 'Hardcoded secret'),\n",
    "        (r'token\\s*=\\s*[\"\\'](.{10,})[\"\\']', 'Hardcoded token'),\n",
    "        (r'AKIA[0-9A-Z]{16}', 'AWS Access Key'),\n",
    "        (r'postgres://.*:.*@', 'Database URL with credentials'),\n",
    "    ]\n",
    "    \n",
    "    findings = []\n",
    "    for pattern, description in patterns:\n",
    "        matches = re.findall(pattern, code, re.IGNORECASE)\n",
    "        if matches:\n",
    "            findings.append(f\"❌ {description} detected\")\n",
    "            findings.append(f\"   → Replace with: os.getenv('{description.upper().replace(' ', '_')}')\")\n",
    "    \n",
    "    return findings\n",
    "\n",
    "# Auto-fix: Replace secrets with environment variables\n",
    "def fix_secrets(code: str) -> str:\n",
    "    \"\"\"Automatically replace hardcoded secrets with os.getenv().\"\"\"\n",
    "    \n",
    "    replacements = [\n",
    "        (r'password\\s*=\\s*[\"\\'](.{3,})[\"\\']', 'password = os.getenv(\"DB_PASSWORD\")'),\n",
    "        (r'api_key\\s*=\\s*[\"\\'](.{10,})[\"\\']', 'api_key = os.getenv(\"API_KEY\")'),\n",
    "    ]\n",
    "    \n",
    "    fixed_code = code\n",
    "    needs_import = False\n",
    "    \n",
    "    for pattern, replacement in replacements:\n",
    "        if re.search(pattern, fixed_code, re.IGNORECASE):\n",
    "            fixed_code = re.sub(pattern, replacement, fixed_code, flags=re.IGNORECASE)\n",
    "            needs_import = True\n",
    "    \n",
    "    # Add 'import os' if needed\n",
    "    if needs_import and 'import os' not in fixed_code:\n",
    "        fixed_code = 'import os\\n\\n' + fixed_code\n",
    "    \n",
    "    return fixed_code\n",
    "\n",
    "# Example\n",
    "bad_code = '''\n",
    "def connect_db():\n",
    "    password = \"super_secret_123\"\n",
    "    api_key = \"sk_live_abc123xyz\"\n",
    "    return create_connection(password, api_key)\n",
    "'''\n",
    "\n",
    "secrets = detect_secrets(bad_code)\n",
    "print(\"\\n\".join(secrets))\n",
    "\n",
    "fixed_code = fix_secrets(bad_code)\n",
    "print(\"\\n✅ Fixed code:\")\n",
    "print(fixed_code)\n",
    "```\n",
    "\n",
    "---\n",
    "**Autor:** Luis J. Raigoso V. (LJRV)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413e4971",
   "metadata": {},
   "source": [
    "### 🧪 **Test Generation: Automated Quality Assurance**\n",
    "\n",
    "**Test Generation Strategy:**\n",
    "\n",
    "```\n",
    "Generated ETL Pipeline Code\n",
    "          │\n",
    "          ▼\n",
    "┌──────────────────────────────────┐\n",
    "│  Test Type Selection             │\n",
    "│  ├─ Unit Tests (functions)       │\n",
    "│  ├─ Integration Tests (I/O)      │\n",
    "│  ├─ Property Tests (invariants)  │\n",
    "│  └─ End-to-End Tests (full flow) │\n",
    "└──────────┬───────────────────────┘\n",
    "           │\n",
    "           ▼\n",
    "┌──────────────────────────────────┐\n",
    "│  Test Case Generation (LLM)      │\n",
    "│  ├─ Happy path (normal inputs)   │\n",
    "│  ├─ Edge cases (nulls, empty)    │\n",
    "│  ├─ Error cases (exceptions)     │\n",
    "│  ├─ Boundary values (min/max)    │\n",
    "│  └─ Performance tests (large data)│\n",
    "└──────────┬───────────────────────┘\n",
    "           │\n",
    "           ▼\n",
    "┌──────────────────────────────────┐\n",
    "│  Mock Generation                 │\n",
    "│  ├─ Database connections (mock)  │\n",
    "│  ├─ External APIs (mock)         │\n",
    "│  ├─ File I/O (tmpdir)            │\n",
    "│  └─ Environment variables        │\n",
    "└──────────┬───────────────────────┘\n",
    "           │\n",
    "           ▼\n",
    "┌──────────────────────────────────┐\n",
    "│  Fixtures & Setup                │\n",
    "│  ├─ pytest fixtures              │\n",
    "│  ├─ Test data generation (Faker) │\n",
    "│  ├─ Database seeding             │\n",
    "│  └─ Teardown cleanup             │\n",
    "└──────────┬───────────────────────┘\n",
    "           │\n",
    "           ▼\n",
    "┌──────────────────────────────────┐\n",
    "│  Execution & Coverage            │\n",
    "│  ├─ pytest execution             │\n",
    "│  ├─ Coverage report (pytest-cov) │\n",
    "│  ├─ Assertion analysis           │\n",
    "│  └─ Target: 80%+ coverage        │\n",
    "└──────────────────────────────────┘\n",
    "```\n",
    "\n",
    "**Comprehensive Test Generation Implementation:**\n",
    "\n",
    "```python\n",
    "def generate_tests(\n",
    "    code: str,\n",
    "    test_framework: str = \"pytest\"\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Generate comprehensive test suite for generated code.\n",
    "    \n",
    "    Coverage:\n",
    "    - Unit tests for each function\n",
    "    - Edge cases (nulls, empty, invalid types)\n",
    "    - Error handling (exceptions)\n",
    "    - Mocks for external dependencies\n",
    "    - Integration tests for full pipeline\n",
    "    \"\"\"\n",
    "    \n",
    "    test_generation_prompt = f\"\"\"\n",
    "You are an expert in test-driven development (TDD) and pytest.\n",
    "\n",
    "**Code to Test:**\n",
    "```python\n",
    "{code}\n",
    "```\n",
    "\n",
    "**Generate comprehensive pytest test suite including:**\n",
    "\n",
    "1. **Unit Tests:**\n",
    "   - Test each function with normal inputs (happy path)\n",
    "   - Test with edge cases: None, empty string/list, zeros\n",
    "   - Test boundary values (min, max)\n",
    "   - Test type validation (wrong types should raise errors)\n",
    "\n",
    "2. **Error Handling Tests:**\n",
    "   - Test that exceptions are raised correctly\n",
    "   - Test error messages are descriptive\n",
    "   - Test retry logic (if applicable)\n",
    "\n",
    "3. **Mocks & Fixtures:**\n",
    "   - Mock external dependencies (databases, APIs, file I/O)\n",
    "   - Use @pytest.fixture for test data\n",
    "   - Use unittest.mock.patch for external calls\n",
    "\n",
    "4. **Integration Tests:**\n",
    "   - Test full pipeline with realistic data\n",
    "   - Test data flow from input to output\n",
    "   - Verify side effects (file creation, DB inserts)\n",
    "\n",
    "5. **Property-Based Tests (if applicable):**\n",
    "   - Use hypothesis for property testing\n",
    "   - Test invariants (e.g., output size == input size)\n",
    "\n",
    "**Test Code Standards:**\n",
    "- Use descriptive test names: test_<function>_<scenario>_<expected>\n",
    "- AAA pattern: Arrange, Act, Assert\n",
    "- Parametrize tests with @pytest.mark.parametrize\n",
    "- Target: 80%+ code coverage\n",
    "- Include docstrings for complex test logic\n",
    "\n",
    "**Output Format:**\n",
    "Complete pytest test file with all imports and fixtures.\n",
    "\n",
    "Generate tests:\n",
    "\"\"\"\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[{\"role\": \"user\", \"content\": test_generation_prompt}],\n",
    "        temperature=0.3  # Slightly higher for diverse test cases\n",
    "    )\n",
    "    \n",
    "    test_code = response.choices[0].message.content.strip()\n",
    "    test_code = test_code.replace('```python', '').replace('```', '').strip()\n",
    "    \n",
    "    return test_code\n",
    "\n",
    "\n",
    "# Example: Generate tests for ETL pipeline\n",
    "etl_code = '''\n",
    "import pandas as pd\n",
    "from typing import List, Dict\n",
    "\n",
    "def extract_sales(file_path: str) -> pd.DataFrame:\n",
    "    \"\"\"Extract sales data from CSV file.\"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    if df.empty:\n",
    "        raise ValueError(\"CSV file is empty\")\n",
    "    return df\n",
    "\n",
    "def transform_sales(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Transform sales data: filter, clean, aggregate.\"\"\"\n",
    "    # Filter out negative amounts\n",
    "    df_clean = df[df['amount'] > 0].copy()\n",
    "    \n",
    "    # Add month column\n",
    "    df_clean['month'] = pd.to_datetime(df_clean['date']).dt.to_period('M')\n",
    "    \n",
    "    # Calculate daily totals\n",
    "    df_agg = df_clean.groupby(['date', 'month']).agg({\n",
    "        'amount': 'sum',\n",
    "        'transaction_id': 'count'\n",
    "    }).reset_index()\n",
    "    \n",
    "    return df_agg\n",
    "\n",
    "def load_sales(df: pd.DataFrame, output_path: str) -> None:\n",
    "    \"\"\"Load transformed data to Parquet.\"\"\"\n",
    "    if len(df) == 0:\n",
    "        raise ValueError(\"No data to load\")\n",
    "    \n",
    "    df.to_parquet(output_path, index=False, compression='snappy')\n",
    "\n",
    "def run_etl_pipeline(input_path: str, output_path: str) -> Dict:\n",
    "    \"\"\"Full ETL pipeline orchestration.\"\"\"\n",
    "    df_raw = extract_sales(input_path)\n",
    "    df_transformed = transform_sales(df_raw)\n",
    "    load_sales(df_transformed, output_path)\n",
    "    \n",
    "    return {\n",
    "        'rows_extracted': len(df_raw),\n",
    "        'rows_loaded': len(df_transformed),\n",
    "        'success': True\n",
    "    }\n",
    "'''\n",
    "\n",
    "generated_tests = generate_tests(etl_code)\n",
    "print(\"Generated Test Suite:\")\n",
    "print(generated_tests)\n",
    "```\n",
    "\n",
    "**Advanced Testing Patterns:**\n",
    "\n",
    "```python\n",
    "# 1. Property-Based Testing with Hypothesis\n",
    "from hypothesis import given, strategies as st\n",
    "import pytest\n",
    "\n",
    "@given(st.lists(st.integers(min_value=1, max_value=1000)))\n",
    "def test_transform_preserves_row_count_property(amounts):\n",
    "    \"\"\"Property: transformation doesn't lose rows (if all positive).\"\"\"\n",
    "    df = pd.DataFrame({'amount': amounts, 'date': ['2024-01-01'] * len(amounts)})\n",
    "    result = transform_sales(df)\n",
    "    assert len(result) > 0  # At least one aggregate row\n",
    "\n",
    "# 2. Parametrized Tests for Edge Cases\n",
    "@pytest.mark.parametrize(\"test_input,expected_error\", [\n",
    "    (pd.DataFrame(), ValueError),  # Empty dataframe\n",
    "    (pd.DataFrame({'amount': [-1, -2]}), None),  # All negative (filters to empty)\n",
    "    (pd.DataFrame({'amount': [0, 0]}), None),  # All zeros\n",
    "])\n",
    "def test_transform_edge_cases(test_input, expected_error):\n",
    "    if expected_error:\n",
    "        with pytest.raises(expected_error):\n",
    "            transform_sales(test_input)\n",
    "    else:\n",
    "        result = transform_sales(test_input)\n",
    "        assert isinstance(result, pd.DataFrame)\n",
    "\n",
    "# 3. Integration Test with Test Containers\n",
    "from testcontainers.postgres import PostgresContainer\n",
    "import sqlalchemy\n",
    "\n",
    "@pytest.fixture(scope='session')\n",
    "def postgres_container():\n",
    "    \"\"\"Spin up real PostgreSQL for integration tests.\"\"\"\n",
    "    with PostgresContainer(\"postgres:15\") as postgres:\n",
    "        yield postgres\n",
    "\n",
    "def test_full_pipeline_with_real_db(postgres_container, tmp_path):\n",
    "    \"\"\"Integration test: CSV → Transform → Load to real DB.\"\"\"\n",
    "    # Create test CSV\n",
    "    input_file = tmp_path / \"sales.csv\"\n",
    "    pd.DataFrame({\n",
    "        'transaction_id': [1, 2, 3],\n",
    "        'date': ['2024-01-01', '2024-01-02', '2024-01-03'],\n",
    "        'amount': [100, 200, 150]\n",
    "    }).to_csv(input_file, index=False)\n",
    "    \n",
    "    # Run ETL\n",
    "    output_file = tmp_path / \"output.parquet\"\n",
    "    result = run_etl_pipeline(str(input_file), str(output_file))\n",
    "    \n",
    "    # Verify\n",
    "    assert result['success']\n",
    "    assert result['rows_extracted'] == 3\n",
    "    assert output_file.exists()\n",
    "    \n",
    "    # Load and verify output\n",
    "    df_output = pd.read_parquet(output_file)\n",
    "    assert len(df_output) > 0\n",
    "    assert 'month' in df_output.columns\n",
    "\n",
    "# 4. Performance Test\n",
    "import time\n",
    "\n",
    "def test_pipeline_performance_large_dataset(tmp_path):\n",
    "    \"\"\"Performance test: 1M rows should complete in <10s.\"\"\"\n",
    "    # Generate large dataset\n",
    "    large_df = pd.DataFrame({\n",
    "        'transaction_id': range(1_000_000),\n",
    "        'date': pd.date_range('2024-01-01', periods=1_000_000, freq='s'),\n",
    "        'amount': [100] * 1_000_000\n",
    "    })\n",
    "    \n",
    "    input_file = tmp_path / \"large_sales.csv\"\n",
    "    large_df.to_csv(input_file, index=False)\n",
    "    \n",
    "    # Measure execution time\n",
    "    start = time.time()\n",
    "    output_file = tmp_path / \"output.parquet\"\n",
    "    run_etl_pipeline(str(input_file), str(output_file))\n",
    "    duration = time.time() - start\n",
    "    \n",
    "    assert duration < 10, f\"Pipeline too slow: {duration:.2f}s (expected <10s)\"\n",
    "\n",
    "# 5. Mock External Dependencies\n",
    "from unittest.mock import patch, MagicMock\n",
    "\n",
    "@patch('boto3.client')\n",
    "def test_extract_from_s3_with_mock(mock_boto_client, tmp_path):\n",
    "    \"\"\"Unit test with mocked S3 client.\"\"\"\n",
    "    # Mock S3 download\n",
    "    mock_s3 = MagicMock()\n",
    "    mock_boto_client.return_value = mock_s3\n",
    "    \n",
    "    # Create test file locally\n",
    "    test_file = tmp_path / \"test.csv\"\n",
    "    pd.DataFrame({'amount': [100]}).to_csv(test_file, index=False)\n",
    "    \n",
    "    # Mock download_file to copy local file\n",
    "    def mock_download(bucket, key, local_path):\n",
    "        import shutil\n",
    "        shutil.copy(test_file, local_path)\n",
    "    \n",
    "    mock_s3.download_file.side_effect = mock_download\n",
    "    \n",
    "    # Test extraction (would normally download from S3)\n",
    "    # extract_from_s3('bucket', 'key.csv', '/tmp/output.csv')\n",
    "    \n",
    "    # Verify S3 client was called\n",
    "    # mock_s3.download_file.assert_called_once_with('bucket', 'key.csv', '/tmp/output.csv')\n",
    "```\n",
    "\n",
    "**Test Coverage Analysis & Improvement:**\n",
    "\n",
    "```python\n",
    "import subprocess\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "def run_tests_with_coverage(test_file: str, code_file: str) -> Dict:\n",
    "    \"\"\"\n",
    "    Execute tests and generate coverage report.\n",
    "    \n",
    "    Returns:\n",
    "        {\n",
    "            'coverage_percent': float,\n",
    "            'lines_covered': int,\n",
    "            'lines_total': int,\n",
    "            'missing_lines': List[int],\n",
    "            'passed_tests': int,\n",
    "            'failed_tests': int\n",
    "        }\n",
    "    \"\"\"\n",
    "    \n",
    "    # Run pytest with coverage\n",
    "    result = subprocess.run(\n",
    "        [\n",
    "            'pytest', test_file,\n",
    "            f'--cov={code_file}',\n",
    "            '--cov-report=json',\n",
    "            '--json-report',\n",
    "            '--json-report-file=/tmp/test_report.json'\n",
    "        ],\n",
    "        capture_output=True,\n",
    "        text=True\n",
    "    )\n",
    "    \n",
    "    # Parse coverage JSON\n",
    "    with open('coverage.json') as f:\n",
    "        cov_data = json.load(f)\n",
    "    \n",
    "    file_cov = cov_data['files'][code_file]\n",
    "    \n",
    "    # Parse test results\n",
    "    with open('/tmp/test_report.json') as f:\n",
    "        test_data = json.load(f)\n",
    "    \n",
    "    return {\n",
    "        'coverage_percent': file_cov['summary']['percent_covered'],\n",
    "        'lines_covered': file_cov['summary']['covered_lines'],\n",
    "        'lines_total': file_cov['summary']['num_statements'],\n",
    "        'missing_lines': file_cov['missing_lines'],\n",
    "        'passed_tests': test_data['summary']['passed'],\n",
    "        'failed_tests': test_data['summary']['failed']\n",
    "    }\n",
    "\n",
    "def improve_test_coverage(\n",
    "    code: str,\n",
    "    existing_tests: str,\n",
    "    coverage_report: Dict\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Generate additional tests to improve coverage.\n",
    "    \n",
    "    Strategy:\n",
    "    - Identify uncovered lines from coverage report\n",
    "    - Extract uncovered functions/branches\n",
    "    - Generate targeted tests for missing coverage\n",
    "    \"\"\"\n",
    "    \n",
    "    improvement_prompt = f\"\"\"\n",
    "The following code has {coverage_report['coverage_percent']:.1f}% test coverage.\n",
    "\n",
    "**Code:**\n",
    "```python\n",
    "{code}\n",
    "```\n",
    "\n",
    "**Existing Tests:**\n",
    "```python\n",
    "{existing_tests}\n",
    "```\n",
    "\n",
    "**Uncovered Lines:** {coverage_report['missing_lines']}\n",
    "\n",
    "**Task:**\n",
    "Generate additional pytest tests to cover the missing lines and bring coverage to 80%+.\n",
    "\n",
    "Focus on:\n",
    "- Uncovered branches (if/else not tested)\n",
    "- Exception handling paths\n",
    "- Edge cases not yet covered\n",
    "\n",
    "**Additional Tests:**\n",
    "\"\"\"\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[{\"role\": \"user\", \"content\": improvement_prompt}],\n",
    "        temperature=0.2\n",
    "    )\n",
    "    \n",
    "    additional_tests = response.choices[0].message.content.strip()\n",
    "    return additional_tests\n",
    "\n",
    "# Example: Iterative coverage improvement\n",
    "coverage_report = {\n",
    "    'coverage_percent': 65.0,\n",
    "    'missing_lines': [15, 16, 23, 24, 30],\n",
    "    'passed_tests': 8,\n",
    "    'failed_tests': 0\n",
    "}\n",
    "\n",
    "additional_tests = improve_test_coverage(etl_code, generated_tests, coverage_report)\n",
    "print(\"Additional tests to improve coverage:\")\n",
    "print(additional_tests)\n",
    "```\n",
    "\n",
    "**Test Execution in CI/CD:**\n",
    "\n",
    "```yaml\n",
    "# .github/workflows/test-generated-code.yml\n",
    "name: Test Generated ETL Code\n",
    "\n",
    "on: [push, pull_request]\n",
    "\n",
    "jobs:\n",
    "  test:\n",
    "    runs-on: ubuntu-latest\n",
    "    \n",
    "    steps:\n",
    "      - uses: actions/checkout@v3\n",
    "      \n",
    "      - name: Set up Python\n",
    "        uses: actions/setup-python@v4\n",
    "        with:\n",
    "          python-version: '3.11'\n",
    "      \n",
    "      - name: Install dependencies\n",
    "        run: |\n",
    "          pip install pytest pytest-cov hypothesis pandas\n",
    "      \n",
    "      - name: Run tests with coverage\n",
    "        run: |\n",
    "          pytest tests/ \\\n",
    "            --cov=src/ \\\n",
    "            --cov-report=xml \\\n",
    "            --cov-report=term \\\n",
    "            --cov-fail-under=80\n",
    "      \n",
    "      - name: Upload coverage to Codecov\n",
    "        uses: codecov/codecov-action@v3\n",
    "        with:\n",
    "          files: ./coverage.xml\n",
    "          fail_ci_if_error: true\n",
    "```\n",
    "\n",
    "**Test Quality Metrics:**\n",
    "\n",
    "```python\n",
    "def analyze_test_quality(test_code: str) -> Dict:\n",
    "    \"\"\"\n",
    "    Assess quality of generated tests.\n",
    "    \n",
    "    Metrics:\n",
    "    - Test count\n",
    "    - Assertion count\n",
    "    - Mock usage\n",
    "    - Fixture usage\n",
    "    - Parametrize usage\n",
    "    - Descriptive names\n",
    "    \"\"\"\n",
    "    \n",
    "    tree = ast.parse(test_code)\n",
    "    \n",
    "    test_count = 0\n",
    "    assertion_count = 0\n",
    "    mock_count = 0\n",
    "    fixture_count = 0\n",
    "    parametrize_count = 0\n",
    "    \n",
    "    for node in ast.walk(tree):\n",
    "        # Count test functions\n",
    "        if isinstance(node, ast.FunctionDef) and node.name.startswith('test_'):\n",
    "            test_count += 1\n",
    "            \n",
    "            # Count assertions in each test\n",
    "            for child in ast.walk(node):\n",
    "                if isinstance(child, ast.Assert):\n",
    "                    assertion_count += 1\n",
    "        \n",
    "        # Count mocks\n",
    "        if isinstance(node, ast.Call):\n",
    "            if hasattr(node.func, 'attr') and 'patch' in node.func.attr:\n",
    "                mock_count += 1\n",
    "        \n",
    "        # Count fixtures\n",
    "        if isinstance(node, ast.FunctionDef):\n",
    "            for decorator in node.decorator_list:\n",
    "                if hasattr(decorator, 'attr') and decorator.attr == 'fixture':\n",
    "                    fixture_count += 1\n",
    "                if hasattr(decorator, 'attr') and decorator.attr == 'parametrize':\n",
    "                    parametrize_count += 1\n",
    "    \n",
    "    assertions_per_test = assertion_count / test_count if test_count > 0 else 0\n",
    "    \n",
    "    # Quality score\n",
    "    score = min(100, (\n",
    "        (test_count * 5) +           # More tests is better (up to 20)\n",
    "        (assertions_per_test * 10) +  # ~3 assertions/test is ideal (30)\n",
    "        (mock_count * 8) +            # Good mocking practice (up to 24)\n",
    "        (fixture_count * 6) +         # Reusable fixtures (up to 18)\n",
    "        (parametrize_count * 4)       # Efficient parametrization (up to 8)\n",
    "    ))\n",
    "    \n",
    "    return {\n",
    "        'test_count': test_count,\n",
    "        'assertion_count': assertion_count,\n",
    "        'assertions_per_test': assertions_per_test,\n",
    "        'mock_count': mock_count,\n",
    "        'fixture_count': fixture_count,\n",
    "        'parametrize_count': parametrize_count,\n",
    "        'quality_score': score\n",
    "    }\n",
    "\n",
    "# Analyze generated tests\n",
    "quality = analyze_test_quality(generated_tests)\n",
    "print(f\"Test Quality Score: {quality['quality_score']:.1f}/100\")\n",
    "print(f\"Tests: {quality['test_count']}, Assertions: {quality['assertion_count']}\")\n",
    "```\n",
    "\n",
    "---\n",
    "**Autor:** Luis J. Raigoso V. (LJRV)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09cb2022",
   "metadata": {},
   "source": [
    "### 🚀 **Production Deployment: From Generated Code to Live Pipeline**\n",
    "\n",
    "**End-to-End Production Workflow:**\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────────────┐\n",
    "│  PHASE 1: REQUIREMENTS GATHERING                                │\n",
    "│  ├─ Natural language specification from stakeholder             │\n",
    "│  ├─ Technical constraints (SLA, budget, compliance)             │\n",
    "│  ├─ Data schema documentation                                   │\n",
    "│  └─ Integration requirements (source/target systems)            │\n",
    "└────────────────────┬────────────────────────────────────────────┘\n",
    "                     │\n",
    "┌────────────────────┴────────────────────────────────────────────┐\n",
    "│  PHASE 2: CODE GENERATION (GPT-4 + RAG)                         │\n",
    "│  ├─ Main pipeline code (Python/PySpark)                         │\n",
    "│  ├─ Configuration (YAML/JSON)                                   │\n",
    "│  ├─ Unit tests (pytest, 80%+ coverage)                          │\n",
    "│  ├─ Integration tests (testcontainers)                          │\n",
    "│  ├─ Dockerfile (containerization)                               │\n",
    "│  ├─ CI/CD pipeline (GitHub Actions)                             │\n",
    "│  └─ Documentation (README, API docs)                            │\n",
    "└────────────────────┬────────────────────────────────────────────┘\n",
    "                     │\n",
    "┌────────────────────┴────────────────────────────────────────────┐\n",
    "│  PHASE 3: VALIDATION & QUALITY ASSURANCE                        │\n",
    "│  ├─ Syntax validation (AST parsing)                             │\n",
    "│  ├─ Security scan (bandit, secrets detection)                   │\n",
    "│  ├─ Linting (ruff/flake8)                                       │\n",
    "│  ├─ Type checking (mypy)                                        │\n",
    "│  ├─ Test execution (pytest)                                     │\n",
    "│  ├─ Coverage analysis (pytest-cov > 80%)                        │\n",
    "│  └─ Self-correction loop (max 3 iterations)                     │\n",
    "└────────────────────┬────────────────────────────────────────────┘\n",
    "                     │\n",
    "┌────────────────────┴────────────────────────────────────────────┐\n",
    "│  PHASE 4: HUMAN REVIEW (Mandatory Gate)                         │\n",
    "│  ├─ Code review by senior engineer                              │\n",
    "│  ├─ Business logic verification                                 │\n",
    "│  ├─ Performance review (query plans, partitioning)              │\n",
    "│  ├─ Security audit (data access, PII handling)                  │\n",
    "│  └─ Approval required before deployment                         │\n",
    "└────────────────────┬────────────────────────────────────────────┘\n",
    "                     │\n",
    "┌────────────────────┴────────────────────────────────────────────┐\n",
    "│  PHASE 5: STAGING DEPLOYMENT                                    │\n",
    "│  ├─ Deploy to staging environment (Kubernetes pod)              │\n",
    "│  ├─ Run with production-like data (last 7 days)                 │\n",
    "│  ├─ Monitor metrics (latency, memory, CPU)                      │\n",
    "│  ├─ Compare results with existing pipeline (if any)             │\n",
    "│  ├─ Validate data quality (Great Expectations)                  │\n",
    "│  └─ Smoke tests (end-to-end validation)                         │\n",
    "└────────────────────┬────────────────────────────────────────────┘\n",
    "                     │\n",
    "┌────────────────────┴────────────────────────────────────────────┐\n",
    "│  PHASE 6: PRODUCTION DEPLOYMENT (Blue-Green)                    │\n",
    "│  ├─ Deploy to production (parallel to existing)                 │\n",
    "│  ├─ Gradual traffic shift (0% → 10% → 50% → 100%)               │\n",
    "│  ├─ Real-time monitoring (Prometheus + Grafana)                 │\n",
    "│  ├─ Alerting (PagerDuty for failures)                           │\n",
    "│  ├─ Rollback capability (one-click revert)                      │\n",
    "│  └─ Post-deployment verification (24h monitoring)               │\n",
    "└────────────────────┬────────────────────────────────────────────┘\n",
    "                     │\n",
    "┌────────────────────┴────────────────────────────────────────────┐\n",
    "│  PHASE 7: CONTINUOUS MONITORING & ITERATION                     │\n",
    "│  ├─ Performance metrics (p95 latency, throughput)               │\n",
    "│  ├─ Data quality metrics (null rate, schema drift)              │\n",
    "│  ├─ Cost tracking (compute, storage)                            │\n",
    "│  ├─ Error tracking (Sentry, CloudWatch)                         │\n",
    "│  ├─ User feedback collection                                    │\n",
    "│  └─ Iterative improvements (regenerate with feedback)           │\n",
    "└─────────────────────────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "**Complete Production Pipeline Generator:**\n",
    "\n",
    "```python\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Optional\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "\n",
    "@dataclass\n",
    "class PipelineSpec:\n",
    "    \"\"\"Specification for production ETL pipeline.\"\"\"\n",
    "    name: str\n",
    "    description: str\n",
    "    source: Dict  # {'type': 's3', 'bucket': 'data', 'prefix': 'raw/sales/'}\n",
    "    target: Dict  # {'type': 'snowflake', 'database': 'analytics', 'table': 'sales'}\n",
    "    transformations: List[str]  # ['deduplicate', 'filter_nulls', 'aggregate_daily']\n",
    "    schedule: str  # Cron expression: '0 2 * * *'\n",
    "    sla_minutes: int  # 30\n",
    "    owner: str  # 'data-team@company.com'\n",
    "    compliance: List[str]  # ['GDPR', 'SOC2']\n",
    "\n",
    "class ProductionPipelineGenerator:\n",
    "    \"\"\"\n",
    "    Generates complete production-ready ETL pipeline.\n",
    "    \n",
    "    Outputs:\n",
    "    - pipeline.py (main code)\n",
    "    - config.yaml (configuration)\n",
    "    - test_pipeline.py (tests)\n",
    "    - Dockerfile (container)\n",
    "    - .github/workflows/ci.yml (CI/CD)\n",
    "    - README.md (documentation)\n",
    "    - airflow_dag.py (orchestration)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, spec: PipelineSpec):\n",
    "        self.spec = spec\n",
    "        self.output_dir = Path(f\"pipelines/{spec.name}\")\n",
    "    \n",
    "    def generate_all(self):\n",
    "        \"\"\"Generate complete pipeline structure.\"\"\"\n",
    "        self.output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        print(f\"🚀 Generating pipeline: {self.spec.name}\")\n",
    "        \n",
    "        # 1. Generate main pipeline code\n",
    "        pipeline_code = self._generate_pipeline_code()\n",
    "        self._save_file(\"pipeline.py\", pipeline_code)\n",
    "        print(\"✅ Generated pipeline.py\")\n",
    "        \n",
    "        # 2. Generate configuration\n",
    "        config = self._generate_config()\n",
    "        self._save_file(\"config.yaml\", yaml.dump(config))\n",
    "        print(\"✅ Generated config.yaml\")\n",
    "        \n",
    "        # 3. Generate tests\n",
    "        test_code = self._generate_tests(pipeline_code)\n",
    "        self._save_file(\"test_pipeline.py\", test_code)\n",
    "        print(\"✅ Generated test_pipeline.py\")\n",
    "        \n",
    "        # 4. Generate Dockerfile\n",
    "        dockerfile = self._generate_dockerfile()\n",
    "        self._save_file(\"Dockerfile\", dockerfile)\n",
    "        print(\"✅ Generated Dockerfile\")\n",
    "        \n",
    "        # 5. Generate CI/CD\n",
    "        ci_yaml = self._generate_ci_cd()\n",
    "        self._save_file(\".github/workflows/ci.yml\", ci_yaml)\n",
    "        print(\"✅ Generated CI/CD pipeline\")\n",
    "        \n",
    "        # 6. Generate documentation\n",
    "        readme = self._generate_readme()\n",
    "        self._save_file(\"README.md\", readme)\n",
    "        print(\"✅ Generated README.md\")\n",
    "        \n",
    "        # 7. Generate Airflow DAG\n",
    "        dag_code = self._generate_airflow_dag()\n",
    "        self._save_file(\"airflow_dag.py\", dag_code)\n",
    "        print(\"✅ Generated Airflow DAG\")\n",
    "        \n",
    "        # 8. Validate all generated code\n",
    "        validation_results = self._validate_generated_code()\n",
    "        print(f\"\\n📊 Validation Score: {validation_results['overall_score']}/100\")\n",
    "        \n",
    "        return str(self.output_dir)\n",
    "    \n",
    "    def _generate_pipeline_code(self) -> str:\n",
    "        \"\"\"Generate main ETL pipeline code using LLM.\"\"\"\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "Generate production-ready ETL pipeline code with the following specifications:\n",
    "\n",
    "**Pipeline Name:** {self.spec.name}\n",
    "**Description:** {self.spec.description}\n",
    "\n",
    "**Source:**\n",
    "- Type: {self.spec.source['type']}\n",
    "- Details: {self.spec.source}\n",
    "\n",
    "**Target:**\n",
    "- Type: {self.spec.target['type']}\n",
    "- Details: {self.spec.target}\n",
    "\n",
    "**Transformations:**\n",
    "{chr(10).join(f'- {t}' for t in self.spec.transformations)}\n",
    "\n",
    "**Requirements:**\n",
    "- Python 3.11+ with type hints\n",
    "- Error handling with exponential backoff (max 3 retries)\n",
    "- Structured logging (JSON format)\n",
    "- Metrics instrumentation (Prometheus)\n",
    "- Configuration loaded from YAML\n",
    "- Idempotent (safe to re-run)\n",
    "- SLA: {self.spec.sla_minutes} minutes\n",
    "- Compliance: {', '.join(self.spec.compliance)}\n",
    "\n",
    "**Code Structure:**\n",
    "```python\n",
    "# Imports\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List\n",
    "import logging\n",
    "import yaml\n",
    "\n",
    "# Configuration\n",
    "@dataclass\n",
    "class PipelineConfig:\n",
    "    # Load from config.yaml\n",
    "    pass\n",
    "\n",
    "# Extract\n",
    "def extract(config: PipelineConfig) -> pd.DataFrame:\n",
    "    # Implement with retry logic\n",
    "    pass\n",
    "\n",
    "# Transform\n",
    "def transform(df: pd.DataFrame, config: PipelineConfig) -> pd.DataFrame:\n",
    "    # Implement transformations\n",
    "    pass\n",
    "\n",
    "# Load\n",
    "def load(df: pd.DataFrame, config: PipelineConfig) -> None:\n",
    "    # Implement with transaction\n",
    "    pass\n",
    "\n",
    "# Main\n",
    "def run_pipeline(config_path: str) -> Dict:\n",
    "    # Orchestrate E-T-L\n",
    "    # Return metrics\n",
    "    pass\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    run_pipeline('config.yaml')\n",
    "```\n",
    "\n",
    "Generate complete, production-ready code:\n",
    "\"\"\"\n",
    "        \n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0.2\n",
    "        )\n",
    "        \n",
    "        code = response.choices[0].message.content.strip()\n",
    "        code = code.replace('```python', '').replace('```', '').strip()\n",
    "        \n",
    "        return code\n",
    "    \n",
    "    def _generate_config(self) -> Dict:\n",
    "        \"\"\"Generate YAML configuration.\"\"\"\n",
    "        return {\n",
    "            'pipeline': {\n",
    "                'name': self.spec.name,\n",
    "                'version': '1.0.0',\n",
    "                'owner': self.spec.owner,\n",
    "                'sla_minutes': self.spec.sla_minutes\n",
    "            },\n",
    "            'source': self.spec.source,\n",
    "            'target': self.spec.target,\n",
    "            'transformations': self.spec.transformations,\n",
    "            'retry': {\n",
    "                'max_attempts': 3,\n",
    "                'backoff_factor': 2,\n",
    "                'timeout_seconds': 300\n",
    "            },\n",
    "            'logging': {\n",
    "                'level': 'INFO',\n",
    "                'format': 'json',\n",
    "                'destination': 'stdout'\n",
    "            },\n",
    "            'monitoring': {\n",
    "                'prometheus_port': 9090,\n",
    "                'healthcheck_endpoint': '/health'\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def _generate_tests(self, pipeline_code: str) -> str:\n",
    "        \"\"\"Generate comprehensive test suite.\"\"\"\n",
    "        return generate_tests(pipeline_code)  # Reuse from earlier\n",
    "    \n",
    "    def _generate_dockerfile(self) -> str:\n",
    "        \"\"\"Generate optimized Dockerfile.\"\"\"\n",
    "        return f'''\n",
    "# Multi-stage build for smaller image\n",
    "FROM python:3.11-slim as builder\n",
    "\n",
    "WORKDIR /app\n",
    "\n",
    "# Install dependencies\n",
    "COPY requirements.txt .\n",
    "RUN pip install --no-cache-dir --user -r requirements.txt\n",
    "\n",
    "# Final stage\n",
    "FROM python:3.11-slim\n",
    "\n",
    "WORKDIR /app\n",
    "\n",
    "# Copy dependencies from builder\n",
    "COPY --from=builder /root/.local /root/.local\n",
    "\n",
    "# Copy application code\n",
    "COPY pipeline.py config.yaml ./\n",
    "\n",
    "# Add Python packages to PATH\n",
    "ENV PATH=/root/.local/bin:$PATH\n",
    "\n",
    "# Non-root user for security\n",
    "RUN useradd -m -u 1000 pipeline && chown -R pipeline:pipeline /app\n",
    "USER pipeline\n",
    "\n",
    "# Health check\n",
    "HEALTHCHECK --interval=30s --timeout=3s --start-period=40s \\\\\n",
    "  CMD python -c \"import sys; sys.exit(0)\"\n",
    "\n",
    "# Run pipeline\n",
    "CMD [\"python\", \"pipeline.py\"]\n",
    "'''\n",
    "    \n",
    "    def _generate_ci_cd(self) -> str:\n",
    "        \"\"\"Generate GitHub Actions CI/CD pipeline.\"\"\"\n",
    "        return f'''\n",
    "name: CI/CD Pipeline for {self.spec.name}\n",
    "\n",
    "on:\n",
    "  push:\n",
    "    branches: [main, develop]\n",
    "  pull_request:\n",
    "    branches: [main]\n",
    "\n",
    "jobs:\n",
    "  test:\n",
    "    runs-on: ubuntu-latest\n",
    "    steps:\n",
    "      - uses: actions/checkout@v3\n",
    "      \n",
    "      - name: Set up Python\n",
    "        uses: actions/setup-python@v4\n",
    "        with:\n",
    "          python-version: '3.11'\n",
    "      \n",
    "      - name: Install dependencies\n",
    "        run: |\n",
    "          pip install -r requirements.txt\n",
    "          pip install pytest pytest-cov bandit ruff mypy\n",
    "      \n",
    "      - name: Run linting\n",
    "        run: ruff check pipeline.py\n",
    "      \n",
    "      - name: Run type checking\n",
    "        run: mypy pipeline.py --ignore-missing-imports\n",
    "      \n",
    "      - name: Run security scan\n",
    "        run: bandit -r pipeline.py\n",
    "      \n",
    "      - name: Run tests\n",
    "        run: pytest test_pipeline.py --cov=pipeline --cov-fail-under=80\n",
    "      \n",
    "      - name: Upload coverage\n",
    "        uses: codecov/codecov-action@v3\n",
    "\n",
    "  build:\n",
    "    needs: test\n",
    "    runs-on: ubuntu-latest\n",
    "    steps:\n",
    "      - uses: actions/checkout@v3\n",
    "      \n",
    "      - name: Build Docker image\n",
    "        run: docker build -t {self.spec.name}:${{{{ github.sha }}}} .\n",
    "      \n",
    "      - name: Push to registry\n",
    "        run: |\n",
    "          echo \"${{{{ secrets.DOCKER_PASSWORD }}}}\" | docker login -u \"${{{{ secrets.DOCKER_USERNAME }}}}\" --password-stdin\n",
    "          docker push {self.spec.name}:${{{{ github.sha }}}}\n",
    "\n",
    "  deploy-staging:\n",
    "    needs: build\n",
    "    runs-on: ubuntu-latest\n",
    "    if: github.ref == 'refs/heads/develop'\n",
    "    steps:\n",
    "      - name: Deploy to staging\n",
    "        run: |\n",
    "          kubectl set image deployment/{self.spec.name} app={self.spec.name}:${{{{ github.sha }}}} -n staging\n",
    "\n",
    "  deploy-production:\n",
    "    needs: build\n",
    "    runs-on: ubuntu-latest\n",
    "    if: github.ref == 'refs/heads/main'\n",
    "    environment: production\n",
    "    steps:\n",
    "      - name: Deploy to production\n",
    "        run: |\n",
    "          kubectl set image deployment/{self.spec.name} app={self.spec.name}:${{{{ github.sha }}}} -n production\n",
    "'''\n",
    "    \n",
    "    def _generate_readme(self) -> str:\n",
    "        \"\"\"Generate comprehensive documentation.\"\"\"\n",
    "        return f'''\n",
    "# {self.spec.name}\n",
    "\n",
    "{self.spec.description}\n",
    "\n",
    "## Overview\n",
    "\n",
    "**Owner:** {self.spec.owner}  \n",
    "**Schedule:** {self.spec.schedule}  \n",
    "**SLA:** {self.spec.sla_minutes} minutes  \n",
    "**Compliance:** {', '.join(self.spec.compliance)}\n",
    "\n",
    "## Architecture\n",
    "\n",
    "```\n",
    "{self.spec.source['type']} → Transform → {self.spec.target['type']}\n",
    "```\n",
    "\n",
    "### Transformations\n",
    "\n",
    "{chr(10).join(f'- {t}' for t in self.spec.transformations)}\n",
    "\n",
    "## Local Development\n",
    "\n",
    "```bash\n",
    "# Install dependencies\n",
    "pip install -r requirements.txt\n",
    "\n",
    "# Run tests\n",
    "pytest test_pipeline.py\n",
    "\n",
    "# Run pipeline locally\n",
    "python pipeline.py\n",
    "\n",
    "# Build Docker image\n",
    "docker build -t {self.spec.name} .\n",
    "\n",
    "# Run container\n",
    "docker run {self.spec.name}\n",
    "```\n",
    "\n",
    "## Configuration\n",
    "\n",
    "Edit `config.yaml` to customize pipeline behavior.\n",
    "\n",
    "## Monitoring\n",
    "\n",
    "- **Metrics:** http://localhost:9090/metrics (Prometheus)\n",
    "- **Health:** http://localhost:8080/health\n",
    "\n",
    "## Deployment\n",
    "\n",
    "Automatic via GitHub Actions:\n",
    "- Push to `develop` → deploys to staging\n",
    "- Push to `main` → deploys to production (requires approval)\n",
    "\n",
    "## Troubleshooting\n",
    "\n",
    "See [TROUBLESHOOTING.md](TROUBLESHOOTING.md) for common issues.\n",
    "\n",
    "## Contact\n",
    "\n",
    "Questions? Contact {self.spec.owner}\n",
    "'''\n",
    "    \n",
    "    def _generate_airflow_dag(self) -> str:\n",
    "        \"\"\"Generate Airflow DAG for orchestration.\"\"\"\n",
    "        return f'''\n",
    "from airflow import DAG\n",
    "from airflow.providers.docker.operators.docker import DockerOperator\n",
    "from airflow.operators.python import PythonOperator\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "default_args = {{\n",
    "    'owner': '{self.spec.owner}',\n",
    "    'depends_on_past': False,\n",
    "    'email_on_failure': True,\n",
    "    'email_on_retry': False,\n",
    "    'retries': 3,\n",
    "    'retry_delay': timedelta(minutes=5),\n",
    "    'sla': timedelta(minutes={self.spec.sla_minutes})\n",
    "}}\n",
    "\n",
    "with DAG(\n",
    "    dag_id='{self.spec.name}',\n",
    "    default_args=default_args,\n",
    "    description='{self.spec.description}',\n",
    "    schedule_interval='{self.spec.schedule}',\n",
    "    start_date=datetime(2024, 1, 1),\n",
    "    catchup=False,\n",
    "    tags=['etl', 'generated', '{self.spec.target[\"type\"]}']\n",
    ") as dag:\n",
    "    \n",
    "    run_pipeline = DockerOperator(\n",
    "        task_id='run_{self.spec.name}',\n",
    "        image='{self.spec.name}:latest',\n",
    "        auto_remove=True,\n",
    "        docker_url='unix://var/run/docker.sock',\n",
    "        network_mode='bridge'\n",
    "    )\n",
    "    \n",
    "    def send_success_notification(**context):\n",
    "        # Send Slack/email notification\n",
    "        print(f\"✅ Pipeline {self.spec.name} completed successfully\")\n",
    "    \n",
    "    notify = PythonOperator(\n",
    "        task_id='notify_success',\n",
    "        python_callable=send_success_notification\n",
    "    )\n",
    "    \n",
    "    run_pipeline >> notify\n",
    "'''\n",
    "    \n",
    "    def _save_file(self, filename: str, content: str):\n",
    "        \"\"\"Save file to output directory.\"\"\"\n",
    "        file_path = self.output_dir / filename\n",
    "        file_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        file_path.write_text(content)\n",
    "    \n",
    "    def _validate_generated_code(self) -> Dict:\n",
    "        \"\"\"Validate all generated code.\"\"\"\n",
    "        validator = CodeValidator()\n",
    "        pipeline_code = (self.output_dir / \"pipeline.py\").read_text()\n",
    "        return validator.validate_all(pipeline_code)\n",
    "\n",
    "# Example: Generate complete production pipeline\n",
    "spec = PipelineSpec(\n",
    "    name='daily_sales_aggregation',\n",
    "    description='Aggregate daily sales from Postgres to Snowflake',\n",
    "    source={\n",
    "        'type': 'postgresql',\n",
    "        'host': 'db.company.com',\n",
    "        'database': 'sales',\n",
    "        'table': 'raw_transactions'\n",
    "    },\n",
    "    target={\n",
    "        'type': 'snowflake',\n",
    "        'account': 'company',\n",
    "        'database': 'analytics',\n",
    "        'schema': 'marts',\n",
    "        'table': 'daily_sales'\n",
    "    },\n",
    "    transformations=[\n",
    "        'Deduplicate by transaction_id',\n",
    "        'Filter out refunds (amount < 0)',\n",
    "        'Enrich with customer tier from Redis',\n",
    "        'Aggregate by date and customer tier',\n",
    "        'Calculate rolling 7-day average'\n",
    "    ],\n",
    "    schedule='0 2 * * *',  # 2 AM daily\n",
    "    sla_minutes=30,\n",
    "    owner='data-engineering@company.com',\n",
    "    compliance=['GDPR', 'SOC2']\n",
    ")\n",
    "\n",
    "generator = ProductionPipelineGenerator(spec)\n",
    "output_path = generator.generate_all()\n",
    "\n",
    "print(f\"\\n✅ Pipeline generated successfully at: {output_path}\")\n",
    "print(f\"\\nNext steps:\")\n",
    "print(f\"1. Review generated code: cd {output_path}\")\n",
    "print(f\"2. Run tests: pytest test_pipeline.py\")\n",
    "print(f\"3. Commit to Git: git add {output_path} && git commit\")\n",
    "print(f\"4. Push to GitHub: git push (CI/CD will auto-deploy)\")\n",
    "```\n",
    "\n",
    "**Cost Optimization Strategies:**\n",
    "\n",
    "```python\n",
    "# Strategy 1: Prompt caching (reduces cost 90%)\n",
    "@lru_cache(maxsize=100)\n",
    "def generate_pipeline_cached(spec_hash: str) -> str:\n",
    "    \"\"\"Cache generated code for similar specifications.\"\"\"\n",
    "    return generate_pipeline(spec)\n",
    "\n",
    "# Strategy 2: Use cheaper models for simple pipelines\n",
    "def select_model_by_complexity(spec: PipelineSpec) -> str:\n",
    "    \"\"\"Choose model based on pipeline complexity.\"\"\"\n",
    "    complexity_score = (\n",
    "        len(spec.transformations) * 10 +\n",
    "        (1 if spec.source['type'] == 'kafka' else 0) * 20 +\n",
    "        (1 if 'HIPAA' in spec.compliance else 0) * 15\n",
    "    )\n",
    "    \n",
    "    if complexity_score > 50:\n",
    "        return \"gpt-4o\"  # Complex pipelines\n",
    "    elif complexity_score > 20:\n",
    "        return \"gpt-4o-mini\"  # Medium complexity\n",
    "    else:\n",
    "        return \"gpt-3.5-turbo\"  # Simple pipelines (80% cheaper)\n",
    "\n",
    "# Strategy 3: Incremental generation (generate only changed parts)\n",
    "def generate_incremental(old_spec: PipelineSpec, new_spec: PipelineSpec) -> str:\n",
    "    \"\"\"Only regenerate changed components.\"\"\"\n",
    "    changes = []\n",
    "    if old_spec.source != new_spec.source:\n",
    "        changes.append(\"extract function\")\n",
    "    if old_spec.transformations != new_spec.transformations:\n",
    "        changes.append(\"transform function\")\n",
    "    if old_spec.target != new_spec.target:\n",
    "        changes.append(\"load function\")\n",
    "    \n",
    "    # Only regenerate changed functions (saves 60% tokens)\n",
    "    return generate_partial(new_spec, components=changes)\n",
    "```\n",
    "\n",
    "**Production Monitoring Dashboard (Grafana):**\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"dashboard\": {\n",
    "    \"title\": \"Generated ETL Pipeline Monitoring\",\n",
    "    \"panels\": [\n",
    "      {\n",
    "        \"title\": \"Pipeline Executions\",\n",
    "        \"targets\": [{\n",
    "          \"expr\": \"rate(pipeline_executions_total[5m])\"\n",
    "        }]\n",
    "      },\n",
    "      {\n",
    "        \"title\": \"Success Rate\",\n",
    "        \"targets\": [{\n",
    "          \"expr\": \"rate(pipeline_executions_total{status='success'}[1h]) / rate(pipeline_executions_total[1h])\"\n",
    "        }]\n",
    "      },\n",
    "      {\n",
    "        \"title\": \"P95 Latency\",\n",
    "        \"targets\": [{\n",
    "          \"expr\": \"histogram_quantile(0.95, pipeline_duration_seconds_bucket)\"\n",
    "        }]\n",
    "      },\n",
    "      {\n",
    "        \"title\": \"Rows Processed\",\n",
    "        \"targets\": [{\n",
    "          \"expr\": \"sum(pipeline_rows_processed_total)\"\n",
    "        }]\n",
    "      },\n",
    "      {\n",
    "        \"title\": \"Cost per Execution\",\n",
    "        \"targets\": [{\n",
    "          \"expr\": \"rate(pipeline_cost_dollars[1d])\"\n",
    "        }]\n",
    "      }\n",
    "    ]\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "---\n",
    "**Autor:** Luis J. Raigoso V. (LJRV)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38c3632",
   "metadata": {},
   "source": [
    "## 1. Generación de función ETL básica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165223b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))\n",
    "\n",
    "def generate_etl_code(description: str) -> str:\n",
    "    prompt = f'''\n",
    "Eres un experto en Python y pipelines ETL. Genera código Python completo y ejecutable.\n",
    "\n",
    "Requerimientos:\n",
    "{description}\n",
    "\n",
    "Incluye:\n",
    "- Imports necesarios\n",
    "- Manejo de errores\n",
    "- Logging básico\n",
    "- Docstrings\n",
    "- Type hints\n",
    "\n",
    "Código:\n",
    "'''\n",
    "    resp = client.chat.completions.create(\n",
    "        model='gpt-4',\n",
    "        messages=[{'role':'user','content':prompt}],\n",
    "        temperature=0.2\n",
    "    )\n",
    "    return resp.choices[0].message.content.strip().replace('```python','').replace('```','')\n",
    "\n",
    "desc = '''\n",
    "Función que:\n",
    "1. Lee CSV de ventas desde S3 (boto3)\n",
    "2. Filtra filas con total > 0\n",
    "3. Agrega columna \"mes\" (YYYY-MM) desde \"fecha\"\n",
    "4. Escribe a Parquet particionado por mes\n",
    "'''\n",
    "\n",
    "code = generate_etl_code(desc)\n",
    "print(code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81dda91b",
   "metadata": {},
   "source": [
    "## 2. Generación de transformación Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355e3bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformation_spec = '''\n",
    "Dataset: transacciones bancarias (CSV)\n",
    "Columnas: trans_id, fecha, monto, tipo (debito/credito), cuenta_id\n",
    "\n",
    "Transformaciones:\n",
    "1. Convertir fecha a datetime\n",
    "2. Crear columna \"anio_mes\" (formato YYYY-MM)\n",
    "3. Calcular saldo acumulado por cuenta_id ordenado por fecha\n",
    "4. Agregar flag is_anomaly si monto > 3 desviaciones estándar de la media de esa cuenta\n",
    "5. Exportar a CSV con encoding UTF-8\n",
    "'''\n",
    "\n",
    "transform_code = generate_etl_code(transformation_spec)\n",
    "print(transform_code[:500] + '...')  # Preview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e2f97d",
   "metadata": {},
   "source": [
    "## 3. Validación de código generado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cd3b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import subprocess\n",
    "\n",
    "def validate_python_syntax(code: str) -> tuple[bool, str]:\n",
    "    \"\"\"Valida sintaxis Python sin ejecutar.\"\"\"\n",
    "    try:\n",
    "        ast.parse(code)\n",
    "        return True, 'Sintaxis válida'\n",
    "    except SyntaxError as e:\n",
    "        return False, f'Error de sintaxis: {e}'\n",
    "\n",
    "def lint_code(code: str, tool='flake8') -> str:\n",
    "    \"\"\"Ejecuta linter (requiere instalado).\"\"\"\n",
    "    try:\n",
    "        with open('/tmp/temp_code.py', 'w') as f:\n",
    "            f.write(code)\n",
    "        result = subprocess.run([tool, '/tmp/temp_code.py'], capture_output=True, text=True)\n",
    "        return result.stdout if result.returncode == 0 else result.stderr\n",
    "    except Exception as e:\n",
    "        return f'Error linting: {e}'\n",
    "\n",
    "valid, msg = validate_python_syntax(code)\n",
    "print(f'{\"✅\" if valid else \"❌\"} {msg}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78453daa",
   "metadata": {},
   "source": [
    "## 4. Generación de DAG de Airflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08a31e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dag_spec = '''\n",
    "DAG de Airflow para:\n",
    "- Nombre: ventas_daily_etl\n",
    "- Schedule: diario a las 2 AM\n",
    "- Tareas:\n",
    "  1. extract_s3: descarga ventas.csv de S3\n",
    "  2. validate: Great Expectations (columnas no nulas, total > 0)\n",
    "  3. transform: agrega mes, calcula métricas\n",
    "  4. load_db: inserta en PostgreSQL (tabla ventas_daily)\n",
    "  5. send_alert: email si falla cualquier paso\n",
    "- Retries: 2 con delay de 5 min\n",
    "'''\n",
    "\n",
    "dag_code = generate_etl_code(dag_spec)\n",
    "print(dag_code[:600] + '...')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c217a9",
   "metadata": {},
   "source": [
    "## 5. Iteración y mejora con feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b9cf3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def refine_code(original_code: str, feedback: str) -> str:\n",
    "    prompt = f'''\n",
    "Mejora este código Python según el feedback:\n",
    "\n",
    "Código original:\n",
    "{original_code}\n",
    "\n",
    "Feedback:\n",
    "{feedback}\n",
    "\n",
    "Código mejorado:\n",
    "'''\n",
    "    resp = client.chat.completions.create(\n",
    "        model='gpt-4',\n",
    "        messages=[{'role':'user','content':prompt}],\n",
    "        temperature=0.1\n",
    "    )\n",
    "    return resp.choices[0].message.content.strip().replace('```python','').replace('```','')\n",
    "\n",
    "feedback_example = '''\n",
    "- Añadir retry con exponential backoff en la descarga de S3\n",
    "- Usar context manager para conexión a DB\n",
    "- Loggear número de filas procesadas\n",
    "'''\n",
    "\n",
    "improved = refine_code(code, feedback_example)\n",
    "print(improved[:400] + '...')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d455aad6",
   "metadata": {},
   "source": [
    "## 6. Generación de tests unitarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7956fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tests(code: str) -> str:\n",
    "    prompt = f'''\n",
    "Genera tests unitarios con pytest para este código:\n",
    "\n",
    "{code}\n",
    "\n",
    "Incluye:\n",
    "- Test de caso normal (happy path)\n",
    "- Test con datos vacíos\n",
    "- Test con errores (valores nulos, tipos incorrectos)\n",
    "- Mocks para I/O externo (S3, DB)\n",
    "\n",
    "Tests:\n",
    "'''\n",
    "    resp = client.chat.completions.create(\n",
    "        model='gpt-4',\n",
    "        messages=[{'role':'user','content':prompt}],\n",
    "        temperature=0.1\n",
    "    )\n",
    "    return resp.choices[0].message.content.strip().replace('```python','').replace('```','')\n",
    "\n",
    "test_code = generate_tests(code)\n",
    "print(test_code[:500] + '...')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba35a34c",
   "metadata": {},
   "source": [
    "## 7. Buenas prácticas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee1e9a8",
   "metadata": {},
   "source": [
    "- **Revisar siempre**: nunca ejecutes código generado sin inspección humana.\n",
    "- **Validación automática**: sintaxis, linting, tests.\n",
    "- **Versionado**: guarda código generado en Git con mensaje descriptivo.\n",
    "- **Plantillas**: usa templates para estructura consistente.\n",
    "- **Iteración**: refina con feedback humano y re-generación.\n",
    "- **Documentación**: genera README y comentarios junto con código."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2fae6a5",
   "metadata": {},
   "source": [
    "## 8. Ejercicios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89411c7c",
   "metadata": {},
   "source": [
    "1. Genera un script que migre datos de MongoDB a PostgreSQL.\n",
    "2. Crea un pipeline Spark (PySpark) que lea Parquet y escriba Delta Lake.\n",
    "3. Automatiza generación de un data quality report con Great Expectations.\n",
    "4. Construye un CLI (Click/Typer) generado por LLM para ejecutar ETLs."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
