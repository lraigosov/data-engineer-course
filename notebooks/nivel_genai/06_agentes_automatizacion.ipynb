{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a03361ea",
   "metadata": {},
   "source": [
    "# 🤖 Agentes Autónomos para Automatización\n",
    "\n",
    "Objetivo: construir agentes con LangGraph y AutoGen que automaticen tareas complejas de ingeniería de datos: debugging, optimización de queries, orquestación de pipelines.\n",
    "\n",
    "- Duración: 120-150 min\n",
    "- Dificultad: Alta\n",
    "- Stack: LangChain, LangGraph, AutoGen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0cf9a0",
   "metadata": {},
   "source": [
    "## 1. Agente simple con LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402b834e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install langchain langgraph openai\n",
    "import os\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
    "from langchain.tools import tool\n",
    "from langchain import hub\n",
    "\n",
    "llm = ChatOpenAI(model='gpt-4', temperature=0, openai_api_key=os.getenv('OPENAI_API_KEY'))\n",
    "\n",
    "@tool\n",
    "def get_table_row_count(table_name: str) -> str:\n",
    "    \"\"\"Devuelve el número de filas de una tabla.\"\"\"\n",
    "    # Simulación\n",
    "    counts = {'ventas': 1250000, 'clientes': 50000, 'productos': 8500}\n",
    "    return f'La tabla {table_name} tiene {counts.get(table_name, 0)} filas.'\n",
    "\n",
    "@tool\n",
    "def get_table_schema(table_name: str) -> str:\n",
    "    \"\"\"Devuelve el esquema de una tabla.\"\"\"\n",
    "    schemas = {\n",
    "        'ventas': 'venta_id (BIGINT), fecha (DATE), producto_id (INT), total (DECIMAL)',\n",
    "        'clientes': 'cliente_id (INT), nombre (VARCHAR), email (VARCHAR), ciudad (VARCHAR)'\n",
    "    }\n",
    "    return schemas.get(table_name, 'Tabla no encontrada')\n",
    "\n",
    "tools = [get_table_row_count, get_table_schema]\n",
    "\n",
    "# Prompt\n",
    "prompt = hub.pull('hwchase17/openai-tools-agent')\n",
    "\n",
    "# Crear agente\n",
    "agent = create_openai_tools_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "result = agent_executor.invoke({\n",
    "    'input': '¿Cuántas filas tiene la tabla ventas y cuál es su esquema?'\n",
    "})\n",
    "\n",
    "print('\\nRespuesta final:', result['output'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d5e773",
   "metadata": {},
   "source": [
    "## 2. Agente para debugging de SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb254dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def validate_sql_syntax(query: str) -> str:\n",
    "    \"\"\"Valida sintaxis SQL.\"\"\"\n",
    "    # Simulación simple\n",
    "    errors = []\n",
    "    if 'SELCT' in query.upper():\n",
    "        errors.append('Typo: SELCT debería ser SELECT')\n",
    "    if query.count('(') != query.count(')'):\n",
    "        errors.append('Paréntesis desbalanceados')\n",
    "    return 'Errores: ' + ', '.join(errors) if errors else 'Sintaxis válida'\n",
    "\n",
    "@tool\n",
    "def suggest_sql_optimization(query: str) -> str:\n",
    "    \"\"\"Sugiere optimizaciones.\"\"\"\n",
    "    tips = []\n",
    "    if 'SELECT *' in query.upper():\n",
    "        tips.append('Evita SELECT *, especifica columnas')\n",
    "    if 'WHERE' not in query.upper() and 'JOIN' in query.upper():\n",
    "        tips.append('Considera agregar WHERE para filtrar resultados')\n",
    "    return 'Sugerencias: ' + ', '.join(tips) if tips else 'Query está bien optimizada'\n",
    "\n",
    "debug_tools = [validate_sql_syntax, suggest_sql_optimization]\n",
    "\n",
    "debug_agent = create_openai_tools_agent(llm, debug_tools, prompt)\n",
    "debug_executor = AgentExecutor(agent=debug_agent, tools=debug_tools, verbose=True)\n",
    "\n",
    "broken_query = 'SELCT * FROM ventas JOIN productos'\n",
    "\n",
    "result = debug_executor.invoke({\n",
    "    'input': f'Analiza esta query y sugiere mejoras: {broken_query}'\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4c4b80",
   "metadata": {},
   "source": [
    "## 3. LangGraph: workflow con estados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef212087",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, Annotated\n",
    "import operator\n",
    "\n",
    "class ETLState(TypedDict):\n",
    "    query: str\n",
    "    validated: bool\n",
    "    optimized: bool\n",
    "    result: str\n",
    "    errors: Annotated[list, operator.add]\n",
    "\n",
    "def validate_node(state: ETLState) -> ETLState:\n",
    "    \"\"\"Nodo de validación.\"\"\"\n",
    "    if 'SELECT' not in state['query'].upper():\n",
    "        state['errors'].append('Query no es SELECT')\n",
    "        state['validated'] = False\n",
    "    else:\n",
    "        state['validated'] = True\n",
    "    return state\n",
    "\n",
    "def optimize_node(state: ETLState) -> ETLState:\n",
    "    \"\"\"Nodo de optimización.\"\"\"\n",
    "    if state['validated']:\n",
    "        # Simulación\n",
    "        state['query'] = state['query'].replace('SELECT *', 'SELECT id, nombre')\n",
    "        state['optimized'] = True\n",
    "    return state\n",
    "\n",
    "def execute_node(state: ETLState) -> ETLState:\n",
    "    \"\"\"Nodo de ejecución.\"\"\"\n",
    "    if state['optimized']:\n",
    "        state['result'] = f'Query ejecutada: {state[\"query\"]}'\n",
    "    else:\n",
    "        state['result'] = 'Ejecución cancelada por errores'\n",
    "    return state\n",
    "\n",
    "# Crear grafo\n",
    "workflow = StateGraph(ETLState)\n",
    "workflow.add_node('validate', validate_node)\n",
    "workflow.add_node('optimize', optimize_node)\n",
    "workflow.add_node('execute', execute_node)\n",
    "\n",
    "workflow.set_entry_point('validate')\n",
    "workflow.add_edge('validate', 'optimize')\n",
    "workflow.add_edge('optimize', 'execute')\n",
    "workflow.add_edge('execute', END)\n",
    "\n",
    "app = workflow.compile()\n",
    "\n",
    "# Ejecutar\n",
    "initial_state = {\n",
    "    'query': 'SELECT * FROM ventas',\n",
    "    'validated': False,\n",
    "    'optimized': False,\n",
    "    'result': '',\n",
    "    'errors': []\n",
    "}\n",
    "\n",
    "final_state = app.invoke(initial_state)\n",
    "print('Estado final:', final_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68cc64f",
   "metadata": {},
   "source": [
    "## 4. AutoGen: múltiples agentes colaborativos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984980b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pyautogen\n",
    "import autogen\n",
    "\n",
    "config_list = [{\n",
    "    'model': 'gpt-4',\n",
    "    'api_key': os.getenv('OPENAI_API_KEY')\n",
    "}]\n",
    "\n",
    "# Agente 1: Data Engineer\n",
    "data_engineer = autogen.AssistantAgent(\n",
    "    name='DataEngineer',\n",
    "    llm_config={'config_list': config_list},\n",
    "    system_message='''\n",
    "Eres un ingeniero de datos experto. Tu tarea es:\n",
    "1. Diseñar pipelines ETL\n",
    "2. Escribir queries SQL optimizadas\n",
    "3. Proponer arquitecturas de datos\n",
    "'''\n",
    ")\n",
    "\n",
    "# Agente 2: QA Engineer\n",
    "qa_engineer = autogen.AssistantAgent(\n",
    "    name='QAEngineer',\n",
    "    llm_config={'config_list': config_list},\n",
    "    system_message='''\n",
    "Eres un ingeniero de calidad. Tu tarea es:\n",
    "1. Revisar código y queries\n",
    "2. Identificar bugs y problemas de rendimiento\n",
    "3. Sugerir tests\n",
    "'''\n",
    ")\n",
    "\n",
    "# Agente 3: User Proxy (humano)\n",
    "user_proxy = autogen.UserProxyAgent(\n",
    "    name='User',\n",
    "    human_input_mode='NEVER',\n",
    "    max_consecutive_auto_reply=0\n",
    ")\n",
    "\n",
    "# Conversación\n",
    "task = '''\n",
    "Diseña un pipeline que:\n",
    "1. Extraiga datos de API de ventas\n",
    "2. Transforme (agregue por día)\n",
    "3. Cargue en Redshift\n",
    "Luego revisa el diseño.\n",
    "'''\n",
    "\n",
    "# Iniciar chat grupal\n",
    "groupchat = autogen.GroupChat(\n",
    "    agents=[user_proxy, data_engineer, qa_engineer],\n",
    "    messages=[],\n",
    "    max_round=5\n",
    ")\n",
    "\n",
    "manager = autogen.GroupChatManager(groupchat=groupchat, llm_config={'config_list': config_list})\n",
    "\n",
    "user_proxy.initiate_chat(manager, message=task)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b51a15",
   "metadata": {},
   "source": [
    "## 5. Agente para monitoreo de data quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327a8e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def check_null_rate(table: str, column: str) -> str:\n",
    "    \"\"\"Verifica tasa de nulos.\"\"\"\n",
    "    # Simulación\n",
    "    rates = {('ventas', 'total'): 0.5, ('clientes', 'email'): 15.2}\n",
    "    rate = rates.get((table, column), 0)\n",
    "    return f'Tasa de nulos en {table}.{column}: {rate}%'\n",
    "\n",
    "@tool\n",
    "def check_duplicates(table: str) -> str:\n",
    "    \"\"\"Verifica duplicados.\"\"\"\n",
    "    dup_counts = {'ventas': 120, 'clientes': 5}\n",
    "    count = dup_counts.get(table, 0)\n",
    "    return f'Duplicados en {table}: {count}'\n",
    "\n",
    "quality_tools = [check_null_rate, check_duplicates]\n",
    "\n",
    "quality_agent = create_openai_tools_agent(llm, quality_tools, prompt)\n",
    "quality_executor = AgentExecutor(agent=quality_agent, tools=quality_tools, verbose=True)\n",
    "\n",
    "quality_result = quality_executor.invoke({\n",
    "    'input': 'Revisa la calidad de la tabla ventas: nulos y duplicados'\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d979b017",
   "metadata": {},
   "source": [
    "## 6. Agente reactivo con memoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123d1599",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)\n",
    "\n",
    "agent_with_memory = create_openai_tools_agent(llm, tools, prompt)\n",
    "executor_with_memory = AgentExecutor(\n",
    "    agent=agent_with_memory,\n",
    "    tools=tools,\n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Conversación\n",
    "executor_with_memory.invoke({'input': 'Cuántas filas tiene ventas?'})\n",
    "executor_with_memory.invoke({'input': 'Y cuál es su esquema?'})  # Contexto previo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f813ba35",
   "metadata": {},
   "source": [
    "## 7. Buenas prácticas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0f7824",
   "metadata": {},
   "source": [
    "- **Tools específicas**: cada tool debe hacer UNA cosa bien.\n",
    "- **Validación de outputs**: verifica respuestas antes de acciones críticas.\n",
    "- **Human-in-the-loop**: aprobación humana para operaciones destructivas.\n",
    "- **Observabilidad**: loggea cada decisión del agente.\n",
    "- **Fallback**: maneja errores de LLM o tools.\n",
    "- **Testing**: prueba agentes con casos edge.\n",
    "- **Costos**: limita llamadas y usa modelos pequeños cuando posible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b7b1fd",
   "metadata": {},
   "source": [
    "## 8. Ejercicios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5addc59",
   "metadata": {},
   "source": [
    "1. Crea un agente que automatice la investigación de incidentes en pipelines.\n",
    "2. Construye un agente que genere data quality reports diarios.\n",
    "3. Implementa un sistema multi-agente para code review de PRs.\n",
    "4. Desarrolla un agente que optimice queries en producción automáticamente."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
