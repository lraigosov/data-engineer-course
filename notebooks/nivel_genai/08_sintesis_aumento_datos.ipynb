{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3cc95f4",
   "metadata": {},
   "source": [
    "# 🎲 Generación de Datos Sintéticos con LLMs\n",
    "\n",
    "Objetivo: usar IA generativa para crear datos realistas de prueba, aumentar datasets, anonimizar datos sensibles, y generar casos edge para testing.\n",
    "\n",
    "- Duración: 90 min\n",
    "- Dificultad: Media\n",
    "- Stack: OpenAI, Faker, SDV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087f407f",
   "metadata": {},
   "source": [
    "## 1. Generación simple de registros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6ceb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))\n",
    "\n",
    "def generate_synthetic_records(schema: dict, count: int) -> list:\n",
    "    \"\"\"Genera registros sintéticos según esquema.\"\"\"\n",
    "    prompt = f'''\n",
    "Genera {count} registros de datos realistas en formato JSON según este esquema:\n",
    "\n",
    "{json.dumps(schema, indent=2)}\n",
    "\n",
    "Devuelve un array JSON con {count} objetos.\n",
    "'''\n",
    "    \n",
    "    resp = client.chat.completions.create(\n",
    "        model='gpt-4',\n",
    "        messages=[{'role':'user','content':prompt}],\n",
    "        temperature=0.8\n",
    "    )\n",
    "    \n",
    "    return json.loads(resp.choices[0].message.content)\n",
    "\n",
    "# Esquema de clientes\n",
    "customer_schema = {\n",
    "    'customer_id': 'int',\n",
    "    'name': 'string (nombre completo realista)',\n",
    "    'email': 'string (email válido)',\n",
    "    'age': 'int (18-75)',\n",
    "    'city': 'string (ciudad de USA)',\n",
    "    'signup_date': 'date (YYYY-MM-DD, últimos 2 años)'\n",
    "}\n",
    "\n",
    "customers = generate_synthetic_records(customer_schema, 5)\n",
    "print(json.dumps(customers, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18a4935",
   "metadata": {},
   "source": [
    "## 2. Generación con contexto de negocio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd3f6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sales_data(num_records: int, context: str) -> list:\n",
    "    \"\"\"Genera datos de ventas con contexto.\"\"\"\n",
    "    prompt = f'''\n",
    "Contexto de negocio: {context}\n",
    "\n",
    "Genera {num_records} transacciones de venta realistas con:\n",
    "- transaction_id (UUID)\n",
    "- date (últimos 30 días)\n",
    "- product (nombre coherente con el contexto)\n",
    "- quantity (int)\n",
    "- unit_price (float)\n",
    "- total (quantity * unit_price)\n",
    "- payment_method (cash, card, online)\n",
    "\n",
    "JSON array:\n",
    "'''\n",
    "    \n",
    "    resp = client.chat.completions.create(\n",
    "        model='gpt-4',\n",
    "        messages=[{'role':'user','content':prompt}],\n",
    "        temperature=0.7\n",
    "    )\n",
    "    \n",
    "    return json.loads(resp.choices[0].message.content)\n",
    "\n",
    "sales = generate_sales_data(\n",
    "    num_records=3,\n",
    "    context='Tienda de electrónica especializada en laptops y accesorios'\n",
    ")\n",
    "\n",
    "for sale in sales:\n",
    "    print(sale)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063ed1df",
   "metadata": {},
   "source": [
    "## 3. Generación de casos edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceca631b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_edge_cases(normal_schema: dict) -> list:\n",
    "    \"\"\"Genera casos extremos para testing.\"\"\"\n",
    "    prompt = f'''\n",
    "Genera 10 casos edge/extremos para testing basados en este esquema:\n",
    "\n",
    "{json.dumps(normal_schema, indent=2)}\n",
    "\n",
    "Incluye casos como:\n",
    "- Valores nulos\n",
    "- Strings vacíos\n",
    "- Números negativos/cero\n",
    "- Fechas futuras/pasadas extremas\n",
    "- Caracteres especiales\n",
    "- Valores muy largos\n",
    "\n",
    "JSON array con campo adicional 'edge_case_type':\n",
    "'''\n",
    "    \n",
    "    resp = client.chat.completions.create(\n",
    "        model='gpt-4',\n",
    "        messages=[{'role':'user','content':prompt}],\n",
    "        temperature=0.5\n",
    "    )\n",
    "    \n",
    "    return json.loads(resp.choices[0].message.content)\n",
    "\n",
    "edge_cases = generate_edge_cases(customer_schema)\n",
    "print(f'Generados {len(edge_cases)} casos edge:\\n')\n",
    "for case in edge_cases[:3]:\n",
    "    print(f\"Tipo: {case.get('edge_case_type')}\")\n",
    "    print(case)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c50869c",
   "metadata": {},
   "source": [
    "## 4. Anonimización inteligente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efbc7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def anonymize_data(sensitive_records: list) -> list:\n",
    "    \"\"\"Anonimiza datos manteniendo realismo.\"\"\"\n",
    "    prompt = f'''\n",
    "Anonimiza estos registros manteniendo la estructura y realismo:\n",
    "- Reemplaza nombres con nombres ficticios\n",
    "- Cambia emails pero mantén el formato\n",
    "- Altera IDs pero mantén el tipo\n",
    "- Preserva patrones estadísticos (edades, fechas)\n",
    "\n",
    "Datos originales:\n",
    "{json.dumps(sensitive_records, indent=2)}\n",
    "\n",
    "Datos anonimizados (mismo formato JSON):\n",
    "'''\n",
    "    \n",
    "    resp = client.chat.completions.create(\n",
    "        model='gpt-4',\n",
    "        messages=[{'role':'user','content':prompt}],\n",
    "        temperature=0.7\n",
    "    )\n",
    "    \n",
    "    return json.loads(resp.choices[0].message.content)\n",
    "\n",
    "real_data = [\n",
    "    {'id': 12345, 'name': 'John Smith', 'email': 'john@company.com', 'salary': 75000},\n",
    "    {'id': 12346, 'name': 'Maria Garcia', 'email': 'maria@company.com', 'salary': 82000}\n",
    "]\n",
    "\n",
    "anonymized = anonymize_data(real_data)\n",
    "print('Original:', real_data[0])\n",
    "print('Anonimizado:', anonymized[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863b9c5c",
   "metadata": {},
   "source": [
    "## 5. Aumento de datos (data augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d80175d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_dataset(original_records: list, target_count: int) -> list:\n",
    "    \"\"\"Aumenta dataset generando variaciones.\"\"\"\n",
    "    prompt = f'''\n",
    "Tienes estos {len(original_records)} registros originales:\n",
    "\n",
    "{json.dumps(original_records, indent=2)}\n",
    "\n",
    "Genera {target_count} registros nuevos similares pero con variaciones realistas.\n",
    "Mantén distribuciones y patrones.\n",
    "\n",
    "JSON array:\n",
    "'''\n",
    "    \n",
    "    resp = client.chat.completions.create(\n",
    "        model='gpt-4',\n",
    "        messages=[{'role':'user','content':prompt}],\n",
    "        temperature=0.8\n",
    "    )\n",
    "    \n",
    "    return json.loads(resp.choices[0].message.content)\n",
    "\n",
    "original_products = [\n",
    "    {'name': 'Laptop Pro 15', 'category': 'Electronics', 'price': 1299},\n",
    "    {'name': 'Wireless Mouse', 'category': 'Accessories', 'price': 29}\n",
    "]\n",
    "\n",
    "augmented = augment_dataset(original_products, 5)\n",
    "print(f'Dataset aumentado a {len(augmented)} registros:\\n')\n",
    "for item in augmented:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de472c0",
   "metadata": {},
   "source": [
    "## 6. Generación de series temporales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05629531",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_timeseries(metric_name: str, days: int, pattern: str) -> list:\n",
    "    \"\"\"Genera serie temporal sintética.\"\"\"\n",
    "    prompt = f'''\n",
    "Genera una serie temporal de {days} días para la métrica: {metric_name}\n",
    "Patrón: {pattern}\n",
    "\n",
    "Formato JSON:\n",
    "[\n",
    "  {{\"date\": \"YYYY-MM-DD\", \"value\": float}},\n",
    "  ...\n",
    "]\n",
    "\n",
    "Los valores deben seguir el patrón descrito.\n",
    "'''\n",
    "    \n",
    "    resp = client.chat.completions.create(\n",
    "        model='gpt-4',\n",
    "        messages=[{'role':'user','content':prompt}],\n",
    "        temperature=0.5\n",
    "    )\n",
    "    \n",
    "    return json.loads(resp.choices[0].message.content)\n",
    "\n",
    "revenue_data = generate_timeseries(\n",
    "    metric_name='daily_revenue',\n",
    "    days=7,\n",
    "    pattern='Tendencia creciente con picos los fines de semana, valores entre 5000-15000'\n",
    ")\n",
    "\n",
    "for entry in revenue_data:\n",
    "    print(f\"{entry['date']}: ${entry['value']:,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a753a4",
   "metadata": {},
   "source": [
    "## 7. Integración con Faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60007cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install faker\n",
    "from faker import Faker\n",
    "import pandas as pd\n",
    "\n",
    "fake = Faker()\n",
    "\n",
    "def generate_hybrid_dataset(count: int) -> pd.DataFrame:\n",
    "    \"\"\"Combina Faker (estructura) + LLM (semántica).\"\"\"\n",
    "    # Estructura base con Faker\n",
    "    base_data = [{\n",
    "        'user_id': fake.uuid4(),\n",
    "        'name': fake.name(),\n",
    "        'email': fake.email(),\n",
    "        'city': fake.city()\n",
    "    } for _ in range(count)]\n",
    "    \n",
    "    # Enriquecer con LLM (ej: generar bio coherente)\n",
    "    for record in base_data:\n",
    "        prompt = f\"Genera una bio de 1 frase para {record['name']}, vive en {record['city']}, trabaja en tech.\"\n",
    "        resp = client.chat.completions.create(\n",
    "            model='gpt-3.5-turbo',\n",
    "            messages=[{'role':'user','content':prompt}],\n",
    "            temperature=0.7,\n",
    "            max_tokens=50\n",
    "        )\n",
    "        record['bio'] = resp.choices[0].message.content.strip()\n",
    "    \n",
    "    return pd.DataFrame(base_data)\n",
    "\n",
    "df_hybrid = generate_hybrid_dataset(3)\n",
    "print(df_hybrid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1bc31f0",
   "metadata": {},
   "source": [
    "## 8. Buenas prácticas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7105efae",
   "metadata": {},
   "source": [
    "- **Validación**: verifica que datos sintéticos cumplan constraints.\n",
    "- **Distribuciones**: compara estadísticas con datos reales.\n",
    "- **Diversidad**: usa temperature alta para mayor variedad.\n",
    "- **Lotes**: genera en batches para eficiencia.\n",
    "- **Costos**: usa GPT-3.5 para volumen, GPT-4 para calidad.\n",
    "- **Complementar**: combina LLMs con bibliotecas tradicionales (Faker, SDV).\n",
    "- **Testing**: valida con Great Expectations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0ebefa",
   "metadata": {},
   "source": [
    "## 9. Ejercicios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93bca64",
   "metadata": {},
   "source": [
    "1. Genera un dataset completo de e-commerce (clientes, productos, pedidos) con relaciones coherentes.\n",
    "2. Crea un generador de logs de aplicación realistas para testing de pipelines.\n",
    "3. Implementa anonimización que preserve privacidad diferencial.\n",
    "4. Construye un augmentador de datos para entrenar modelos de ML con pocos ejemplos."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
