{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3cc95f4",
   "metadata": {},
   "source": [
    "# üé≤ Generaci√≥n de Datos Sint√©ticos con LLMs\n",
    "\n",
    "Objetivo: usar IA generativa para crear datos realistas de prueba, aumentar datasets, anonimizar datos sensibles, y generar casos edge para testing.\n",
    "\n",
    "- Duraci√≥n: 90 min\n",
    "- Dificultad: Media\n",
    "- Stack: OpenAI, Faker, SDV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087f407f",
   "metadata": {},
   "source": [
    "## 1. Generaci√≥n simple de registros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6ceb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))\n",
    "\n",
    "def generate_synthetic_records(schema: dict, count: int) -> list:\n",
    "    \"\"\"Genera registros sint√©ticos seg√∫n esquema.\"\"\"\n",
    "    prompt = f'''\n",
    "Genera {count} registros de datos realistas en formato JSON seg√∫n este esquema:\n",
    "\n",
    "{json.dumps(schema, indent=2)}\n",
    "\n",
    "Devuelve un array JSON con {count} objetos.\n",
    "'''\n",
    "    \n",
    "    resp = client.chat.completions.create(\n",
    "        model='gpt-4',\n",
    "        messages=[{'role':'user','content':prompt}],\n",
    "        temperature=0.8\n",
    "    )\n",
    "    \n",
    "    return json.loads(resp.choices[0].message.content)\n",
    "\n",
    "# Esquema de clientes\n",
    "customer_schema = {\n",
    "    'customer_id': 'int',\n",
    "    'name': 'string (nombre completo realista)',\n",
    "    'email': 'string (email v√°lido)',\n",
    "    'age': 'int (18-75)',\n",
    "    'city': 'string (ciudad de USA)',\n",
    "    'signup_date': 'date (YYYY-MM-DD, √∫ltimos 2 a√±os)'\n",
    "}\n",
    "\n",
    "customers = generate_synthetic_records(customer_schema, 5)\n",
    "print(json.dumps(customers, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18a4935",
   "metadata": {},
   "source": [
    "## 2. Generaci√≥n con contexto de negocio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd3f6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sales_data(num_records: int, context: str) -> list:\n",
    "    \"\"\"Genera datos de ventas con contexto.\"\"\"\n",
    "    prompt = f'''\n",
    "Contexto de negocio: {context}\n",
    "\n",
    "Genera {num_records} transacciones de venta realistas con:\n",
    "- transaction_id (UUID)\n",
    "- date (√∫ltimos 30 d√≠as)\n",
    "- product (nombre coherente con el contexto)\n",
    "- quantity (int)\n",
    "- unit_price (float)\n",
    "- total (quantity * unit_price)\n",
    "- payment_method (cash, card, online)\n",
    "\n",
    "JSON array:\n",
    "'''\n",
    "    \n",
    "    resp = client.chat.completions.create(\n",
    "        model='gpt-4',\n",
    "        messages=[{'role':'user','content':prompt}],\n",
    "        temperature=0.7\n",
    "    )\n",
    "    \n",
    "    return json.loads(resp.choices[0].message.content)\n",
    "\n",
    "sales = generate_sales_data(\n",
    "    num_records=3,\n",
    "    context='Tienda de electr√≥nica especializada en laptops y accesorios'\n",
    ")\n",
    "\n",
    "for sale in sales:\n",
    "    print(sale)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063ed1df",
   "metadata": {},
   "source": [
    "## 3. Generaci√≥n de casos edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceca631b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_edge_cases(normal_schema: dict) -> list:\n",
    "    \"\"\"Genera casos extremos para testing.\"\"\"\n",
    "    prompt = f'''\n",
    "Genera 10 casos edge/extremos para testing basados en este esquema:\n",
    "\n",
    "{json.dumps(normal_schema, indent=2)}\n",
    "\n",
    "Incluye casos como:\n",
    "- Valores nulos\n",
    "- Strings vac√≠os\n",
    "- N√∫meros negativos/cero\n",
    "- Fechas futuras/pasadas extremas\n",
    "- Caracteres especiales\n",
    "- Valores muy largos\n",
    "\n",
    "JSON array con campo adicional 'edge_case_type':\n",
    "'''\n",
    "    \n",
    "    resp = client.chat.completions.create(\n",
    "        model='gpt-4',\n",
    "        messages=[{'role':'user','content':prompt}],\n",
    "        temperature=0.5\n",
    "    )\n",
    "    \n",
    "    return json.loads(resp.choices[0].message.content)\n",
    "\n",
    "edge_cases = generate_edge_cases(customer_schema)\n",
    "print(f'Generados {len(edge_cases)} casos edge:\\n')\n",
    "for case in edge_cases[:3]:\n",
    "    print(f\"Tipo: {case.get('edge_case_type')}\")\n",
    "    print(case)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c50869c",
   "metadata": {},
   "source": [
    "## 4. Anonimizaci√≥n inteligente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efbc7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def anonymize_data(sensitive_records: list) -> list:\n",
    "    \"\"\"Anonimiza datos manteniendo realismo.\"\"\"\n",
    "    prompt = f'''\n",
    "Anonimiza estos registros manteniendo la estructura y realismo:\n",
    "- Reemplaza nombres con nombres ficticios\n",
    "- Cambia emails pero mant√©n el formato\n",
    "- Altera IDs pero mant√©n el tipo\n",
    "- Preserva patrones estad√≠sticos (edades, fechas)\n",
    "\n",
    "Datos originales:\n",
    "{json.dumps(sensitive_records, indent=2)}\n",
    "\n",
    "Datos anonimizados (mismo formato JSON):\n",
    "'''\n",
    "    \n",
    "    resp = client.chat.completions.create(\n",
    "        model='gpt-4',\n",
    "        messages=[{'role':'user','content':prompt}],\n",
    "        temperature=0.7\n",
    "    )\n",
    "    \n",
    "    return json.loads(resp.choices[0].message.content)\n",
    "\n",
    "real_data = [\n",
    "    {'id': 12345, 'name': 'John Smith', 'email': 'john@company.com', 'salary': 75000},\n",
    "    {'id': 12346, 'name': 'Maria Garcia', 'email': 'maria@company.com', 'salary': 82000}\n",
    "]\n",
    "\n",
    "anonymized = anonymize_data(real_data)\n",
    "print('Original:', real_data[0])\n",
    "print('Anonimizado:', anonymized[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863b9c5c",
   "metadata": {},
   "source": [
    "## 5. Aumento de datos (data augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d80175d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_dataset(original_records: list, target_count: int) -> list:\n",
    "    \"\"\"Aumenta dataset generando variaciones.\"\"\"\n",
    "    prompt = f'''\n",
    "Tienes estos {len(original_records)} registros originales:\n",
    "\n",
    "{json.dumps(original_records, indent=2)}\n",
    "\n",
    "Genera {target_count} registros nuevos similares pero con variaciones realistas.\n",
    "Mant√©n distribuciones y patrones.\n",
    "\n",
    "JSON array:\n",
    "'''\n",
    "    \n",
    "    resp = client.chat.completions.create(\n",
    "        model='gpt-4',\n",
    "        messages=[{'role':'user','content':prompt}],\n",
    "        temperature=0.8\n",
    "    )\n",
    "    \n",
    "    return json.loads(resp.choices[0].message.content)\n",
    "\n",
    "original_products = [\n",
    "    {'name': 'Laptop Pro 15', 'category': 'Electronics', 'price': 1299},\n",
    "    {'name': 'Wireless Mouse', 'category': 'Accessories', 'price': 29}\n",
    "]\n",
    "\n",
    "augmented = augment_dataset(original_products, 5)\n",
    "print(f'Dataset aumentado a {len(augmented)} registros:\\n')\n",
    "for item in augmented:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de472c0",
   "metadata": {},
   "source": [
    "## 6. Generaci√≥n de series temporales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05629531",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_timeseries(metric_name: str, days: int, pattern: str) -> list:\n",
    "    \"\"\"Genera serie temporal sint√©tica.\"\"\"\n",
    "    prompt = f'''\n",
    "Genera una serie temporal de {days} d√≠as para la m√©trica: {metric_name}\n",
    "Patr√≥n: {pattern}\n",
    "\n",
    "Formato JSON:\n",
    "[\n",
    "  {{\"date\": \"YYYY-MM-DD\", \"value\": float}},\n",
    "  ...\n",
    "]\n",
    "\n",
    "Los valores deben seguir el patr√≥n descrito.\n",
    "'''\n",
    "    \n",
    "    resp = client.chat.completions.create(\n",
    "        model='gpt-4',\n",
    "        messages=[{'role':'user','content':prompt}],\n",
    "        temperature=0.5\n",
    "    )\n",
    "    \n",
    "    return json.loads(resp.choices[0].message.content)\n",
    "\n",
    "revenue_data = generate_timeseries(\n",
    "    metric_name='daily_revenue',\n",
    "    days=7,\n",
    "    pattern='Tendencia creciente con picos los fines de semana, valores entre 5000-15000'\n",
    ")\n",
    "\n",
    "for entry in revenue_data:\n",
    "    print(f\"{entry['date']}: ${entry['value']:,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a753a4",
   "metadata": {},
   "source": [
    "## 7. Integraci√≥n con Faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60007cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install faker\n",
    "from faker import Faker\n",
    "import pandas as pd\n",
    "\n",
    "fake = Faker()\n",
    "\n",
    "def generate_hybrid_dataset(count: int) -> pd.DataFrame:\n",
    "    \"\"\"Combina Faker (estructura) + LLM (sem√°ntica).\"\"\"\n",
    "    # Estructura base con Faker\n",
    "    base_data = [{\n",
    "        'user_id': fake.uuid4(),\n",
    "        'name': fake.name(),\n",
    "        'email': fake.email(),\n",
    "        'city': fake.city()\n",
    "    } for _ in range(count)]\n",
    "    \n",
    "    # Enriquecer con LLM (ej: generar bio coherente)\n",
    "    for record in base_data:\n",
    "        prompt = f\"Genera una bio de 1 frase para {record['name']}, vive en {record['city']}, trabaja en tech.\"\n",
    "        resp = client.chat.completions.create(\n",
    "            model='gpt-3.5-turbo',\n",
    "            messages=[{'role':'user','content':prompt}],\n",
    "            temperature=0.7,\n",
    "            max_tokens=50\n",
    "        )\n",
    "        record['bio'] = resp.choices[0].message.content.strip()\n",
    "    \n",
    "    return pd.DataFrame(base_data)\n",
    "\n",
    "df_hybrid = generate_hybrid_dataset(3)\n",
    "print(df_hybrid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1bc31f0",
   "metadata": {},
   "source": [
    "## 8. Buenas pr√°cticas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7105efae",
   "metadata": {},
   "source": [
    "- **Validaci√≥n**: verifica que datos sint√©ticos cumplan constraints.\n",
    "- **Distribuciones**: compara estad√≠sticas con datos reales.\n",
    "- **Diversidad**: usa temperature alta para mayor variedad.\n",
    "- **Lotes**: genera en batches para eficiencia.\n",
    "- **Costos**: usa GPT-3.5 para volumen, GPT-4 para calidad.\n",
    "- **Complementar**: combina LLMs con bibliotecas tradicionales (Faker, SDV).\n",
    "- **Testing**: valida con Great Expectations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0ebefa",
   "metadata": {},
   "source": [
    "## 9. Ejercicios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93bca64",
   "metadata": {},
   "source": [
    "1. Genera un dataset completo de e-commerce (clientes, productos, pedidos) con relaciones coherentes.\n",
    "2. Crea un generador de logs de aplicaci√≥n realistas para testing de pipelines.\n",
    "3. Implementa anonimizaci√≥n que preserve privacidad diferencial.\n",
    "4. Construye un augmentador de datos para entrenar modelos de ML con pocos ejemplos."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
