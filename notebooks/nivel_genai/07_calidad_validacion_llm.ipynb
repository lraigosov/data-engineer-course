{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29150ce4",
   "metadata": {},
   "source": [
    "# ✅ Validación de Datos con LLMs\n",
    "\n",
    "Objetivo: usar LLMs para detectar anomalías, validar calidad de datos, clasificar errores, y generar reglas de validación de forma inteligente.\n",
    "\n",
    "- Duración: 90 min\n",
    "- Dificultad: Media/Alta\n",
    "- Stack: OpenAI, Great Expectations, Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db249c09",
   "metadata": {},
   "source": [
    "## 1. Detección de anomalías semánticas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78572e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))\n",
    "\n",
    "def detect_anomaly(value: str, context: str) -> dict:\n",
    "    \"\"\"Detecta si un valor es anómalo en su contexto.\"\"\"\n",
    "    prompt = f'''\n",
    "Contexto: {context}\n",
    "Valor: {value}\n",
    "\n",
    "¿Es este valor anómalo o incorrecto? Responde en JSON:\n",
    "{{\n",
    "  \"is_anomaly\": true/false,\n",
    "  \"confidence\": 0-100,\n",
    "  \"reason\": \"explicación\",\n",
    "  \"suggested_fix\": \"valor corregido o null\"\n",
    "}}\n",
    "'''\n",
    "    resp = client.chat.completions.create(\n",
    "        model='gpt-4',\n",
    "        messages=[{'role':'user','content':prompt}],\n",
    "        temperature=0\n",
    "    )\n",
    "    import json\n",
    "    return json.loads(resp.choices[0].message.content)\n",
    "\n",
    "# Ejemplos\n",
    "casos = [\n",
    "    {'valor': 'Nueva Yorkk', 'contexto': 'Columna: ciudad (ciudades de USA)'},\n",
    "    {'valor': '999', 'contexto': 'Columna: edad (años de personas)'},\n",
    "    {'valor': 'admin@example.com', 'contexto': 'Columna: email de clientes reales'}\n",
    "]\n",
    "\n",
    "for caso in casos:\n",
    "    result = detect_anomaly(caso['valor'], caso['contexto'])\n",
    "    print(f\"Valor: {caso['valor']}\")\n",
    "    print(f\"Anomalía: {result['is_anomaly']} (confianza={result['confidence']}%)\")\n",
    "    print(f\"Razón: {result['reason']}\")\n",
    "    if result['suggested_fix']:\n",
    "        print(f\"Sugerencia: {result['suggested_fix']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40dcd6b",
   "metadata": {},
   "source": [
    "## 2. Clasificación de errores en datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc1c9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_data_issue(issue_description: str) -> str:\n",
    "    \"\"\"Clasifica el tipo de problema de datos.\"\"\"\n",
    "    prompt = f'''\n",
    "Clasifica este problema de datos en UNA categoría:\n",
    "- DUPLICATES: registros duplicados\n",
    "- NULLS: valores faltantes\n",
    "- FORMAT: formato incorrecto\n",
    "- OUTLIER: valores fuera de rango\n",
    "- INCONSISTENCY: datos inconsistentes entre fuentes\n",
    "- FRESHNESS: datos desactualizados\n",
    "\n",
    "Problema: {issue_description}\n",
    "\n",
    "Categoría:\n",
    "'''\n",
    "    resp = client.chat.completions.create(\n",
    "        model='gpt-3.5-turbo',\n",
    "        messages=[{'role':'user','content':prompt}],\n",
    "        temperature=0\n",
    "    )\n",
    "    return resp.choices[0].message.content.strip()\n",
    "\n",
    "issues = [\n",
    "    'La tabla tiene 500 filas con cliente_id = NULL',\n",
    "    'Fechas en formato DD/MM/YYYY pero esperamos YYYY-MM-DD',\n",
    "    'Última actualización hace 7 días pero debe ser diaria',\n",
    "    'Misma transacción aparece 3 veces con diferentes IDs'\n",
    "]\n",
    "\n",
    "for issue in issues:\n",
    "    categoria = classify_data_issue(issue)\n",
    "    print(f'➡️ \"{issue}\"')\n",
    "    print(f'   Categoría: {categoria}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb562809",
   "metadata": {},
   "source": [
    "## 3. Generación de reglas de validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e3c7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_validation_rules(column_name: str, sample_data: list, description: str = '') -> str:\n",
    "    \"\"\"Genera reglas de Great Expectations.\"\"\"\n",
    "    prompt = f'''\n",
    "Genera expectativas de Great Expectations (Python) para validar esta columna:\n",
    "\n",
    "Columna: {column_name}\n",
    "Descripción: {description}\n",
    "Muestra de datos: {sample_data}\n",
    "\n",
    "Genera código Python con expect_* methods. Ejemplos:\n",
    "- expect_column_values_to_not_be_null\n",
    "- expect_column_values_to_be_between\n",
    "- expect_column_values_to_match_regex\n",
    "\n",
    "Código:\n",
    "'''\n",
    "    resp = client.chat.completions.create(\n",
    "        model='gpt-4',\n",
    "        messages=[{'role':'user','content':prompt}],\n",
    "        temperature=0.1\n",
    "    )\n",
    "    return resp.choices[0].message.content.strip().replace('```python','').replace('```','')\n",
    "\n",
    "# Ejemplo\n",
    "rules = generate_validation_rules(\n",
    "    column_name='email',\n",
    "    sample_data=['user@example.com', 'admin@test.org', 'info@company.co'],\n",
    "    description='Emails de clientes'\n",
    ")\n",
    "\n",
    "print(rules)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cecde61",
   "metadata": {},
   "source": [
    "## 4. Validación batch con LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cef1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_batch(df: pd.DataFrame, rules: dict) -> pd.DataFrame:\n",
    "    \"\"\"Valida DataFrame según reglas inferidas por LLM.\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for col, rule_desc in rules.items():\n",
    "        sample = df[col].dropna().head(10).tolist()\n",
    "        \n",
    "        prompt = f'''\n",
    "Valida si estos valores cumplen la regla:\n",
    "Regla: {rule_desc}\n",
    "Valores: {sample}\n",
    "\n",
    "Responde con porcentaje de conformidad (0-100) y problemas encontrados.\n",
    "'''\n",
    "        \n",
    "        resp = client.chat.completions.create(\n",
    "            model='gpt-3.5-turbo',\n",
    "            messages=[{'role':'user','content':prompt}],\n",
    "            temperature=0\n",
    "        )\n",
    "        \n",
    "        results.append({\n",
    "            'columna': col,\n",
    "            'regla': rule_desc,\n",
    "            'resultado': resp.choices[0].message.content\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Datos de prueba\n",
    "df_test = pd.DataFrame({\n",
    "    'edad': [25, 30, 200, 45, -5],\n",
    "    'email': ['a@b.com', 'invalido', 'test@x.org', None, 'ok@mail.com']\n",
    "})\n",
    "\n",
    "validation_rules = {\n",
    "    'edad': 'Debe estar entre 0 y 120',\n",
    "    'email': 'Debe ser email válido o null'\n",
    "}\n",
    "\n",
    "validation_report = validate_batch(df_test, validation_rules)\n",
    "print(validation_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00de5039",
   "metadata": {},
   "source": [
    "## 5. Explicación de anomalías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058d734b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain_outlier(value: float, stats: dict) -> str:\n",
    "    \"\"\"Explica por qué un valor es outlier en lenguaje natural.\"\"\"\n",
    "    prompt = f'''\n",
    "Valor: {value}\n",
    "Estadísticas de la columna:\n",
    "- Media: {stats['mean']}\n",
    "- Desviación estándar: {stats['std']}\n",
    "- Min: {stats['min']}\n",
    "- Max: {stats['max']}\n",
    "\n",
    "Explica en 2-3 frases por qué este valor es anómalo y qué puede indicar.\n",
    "'''\n",
    "    resp = client.chat.completions.create(\n",
    "        model='gpt-4',\n",
    "        messages=[{'role':'user','content':prompt}],\n",
    "        temperature=0.3\n",
    "    )\n",
    "    return resp.choices[0].message.content.strip()\n",
    "\n",
    "# Ejemplo\n",
    "outlier_explanation = explain_outlier(\n",
    "    value=50000,\n",
    "    stats={'mean': 120, 'std': 35, 'min': 50, 'max': 250}\n",
    ")\n",
    "\n",
    "print('Explicación del outlier:')\n",
    "print(outlier_explanation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9b80d2",
   "metadata": {},
   "source": [
    "## 6. Sugerencia de limpieza de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5c773b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def suggest_data_cleaning(df_sample: pd.DataFrame) -> str:\n",
    "    \"\"\"Sugiere pasos de limpieza basados en muestra.\"\"\"\n",
    "    info = {\n",
    "        'columns': df_sample.columns.tolist(),\n",
    "        'dtypes': df_sample.dtypes.astype(str).to_dict(),\n",
    "        'nulls': df_sample.isnull().sum().to_dict(),\n",
    "        'sample': df_sample.head(3).to_dict()\n",
    "    }\n",
    "    \n",
    "    prompt = f'''\n",
    "Analiza este DataFrame y sugiere pasos de limpieza en orden de prioridad:\n",
    "\n",
    "{info}\n",
    "\n",
    "Lista numerada de acciones de limpieza con código Pandas cuando sea relevante.\n",
    "'''\n",
    "    \n",
    "    resp = client.chat.completions.create(\n",
    "        model='gpt-4',\n",
    "        messages=[{'role':'user','content':prompt}],\n",
    "        temperature=0.2\n",
    "    )\n",
    "    \n",
    "    return resp.choices[0].message.content\n",
    "\n",
    "messy_df = pd.DataFrame({\n",
    "    'fecha': ['2024-01-01', '01/02/2024', None, '2024-03-15'],\n",
    "    'monto': ['100', '200.5', 'N/A', '300'],\n",
    "    'categoria': ['  ventas', 'VENTAS', 'Ventas ', 'marketing']\n",
    "})\n",
    "\n",
    "cleaning_plan = suggest_data_cleaning(messy_df)\n",
    "print(cleaning_plan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d205e02",
   "metadata": {},
   "source": [
    "## 7. Validación de coherencia entre tablas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc895787",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_referential_integrity(parent_ids: list, child_ids: list, relationship: str) -> dict:\n",
    "    \"\"\"Valida integridad referencial con explicación.\"\"\"\n",
    "    orphans = set(child_ids) - set(parent_ids)\n",
    "    \n",
    "    prompt = f'''\n",
    "Relación: {relationship}\n",
    "IDs huérfanos (en tabla hija pero no en padre): {list(orphans)[:10]}\n",
    "Total huérfanos: {len(orphans)}\n",
    "\n",
    "Explica el problema y sugiere 3 posibles causas.\n",
    "'''\n",
    "    \n",
    "    resp = client.chat.completions.create(\n",
    "        model='gpt-4',\n",
    "        messages=[{'role':'user','content':prompt}],\n",
    "        temperature=0.2\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        'orphans_count': len(orphans),\n",
    "        'orphan_sample': list(orphans)[:5],\n",
    "        'explanation': resp.choices[0].message.content\n",
    "    }\n",
    "\n",
    "# Ejemplo\n",
    "productos_ids = [1, 2, 3, 4, 5]\n",
    "ventas_producto_ids = [1, 2, 3, 99, 100, 5]\n",
    "\n",
    "integrity_check = validate_referential_integrity(\n",
    "    parent_ids=productos_ids,\n",
    "    child_ids=ventas_producto_ids,\n",
    "    relationship='ventas.producto_id -> productos.producto_id'\n",
    ")\n",
    "\n",
    "print(f\"Huérfanos: {integrity_check['orphans_count']}\")\n",
    "print(f\"Muestra: {integrity_check['orphan_sample']}\")\n",
    "print(f\"\\nExplicación:\\n{integrity_check['explanation']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808646c6",
   "metadata": {},
   "source": [
    "## 8. Buenas prácticas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af78399a",
   "metadata": {},
   "source": [
    "- **Complementar, no reemplazar**: LLMs complementan herramientas tradicionales (GE, pandas profiling).\n",
    "- **Validación humana**: revisa sugerencias antes de aplicar.\n",
    "- **Umbrales**: define confidence thresholds para automatización.\n",
    "- **Logging**: registra todas las decisiones del LLM.\n",
    "- **Costos**: cachea validaciones comunes.\n",
    "- **Testing**: valida el validador con datos conocidos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37ea8ee",
   "metadata": {},
   "source": [
    "## 9. Ejercicios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9702d2f9",
   "metadata": {},
   "source": [
    "1. Construye un sistema de auto-reparación de datos usando LLM suggestions.\n",
    "2. Genera un data quality dashboard con explicaciones en lenguaje natural.\n",
    "3. Implementa detección de PII (datos sensibles) con LLMs.\n",
    "4. Crea un agente que diagnostique problemas de data quality y proponga fixes."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
