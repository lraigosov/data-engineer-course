{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29150ce4",
   "metadata": {},
   "source": [
    "# \u2705 Validaci\u00f3n de Datos con LLMs\n",
    "\n",
    "Objetivo: usar LLMs para detectar anomal\u00edas, validar calidad de datos, clasificar errores, y generar reglas de validaci\u00f3n de forma inteligente.\n",
    "\n",
    "- Duraci\u00f3n: 90 min\n",
    "- Dificultad: Media/Alta\n",
    "- Stack: OpenAI, Great Expectations, Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c299757e",
   "metadata": {},
   "source": [
    "## \ud83d\udd0d LLMs para Data Quality: M\u00e1s All\u00e1 de Reglas Est\u00e1ticas\n",
    "\n",
    "La **validaci\u00f3n tradicional** de datos se basa en reglas predefinidas (nulls, rangos, formatos). Los **LLMs** permiten validaci\u00f3n **sem\u00e1ntica y contextual**: detectar anomal\u00edas que ninguna regla puede capturar, explicar root causes, y generar reglas de validaci\u00f3n autom\u00e1ticamente.\n",
    "\n",
    "### \ud83c\udfd7\ufe0f Evoluci\u00f3n de Data Quality\n",
    "\n",
    "```\n",
    "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "\u2502         DATA QUALITY: TRADITIONAL vs LLM-POWERED                 \u2502\n",
    "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
    "\u2502                                                                  \u2502\n",
    "\u2502  TRADITIONAL (Rule-Based):                                       \u2502\n",
    "\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n",
    "\u2502  \u2502 1. Null Checks                                           \u2502   \u2502\n",
    "\u2502  \u2502    assert column.notnull().all()                         \u2502   \u2502\n",
    "\u2502  \u2502    \u2705 Detecta: NULL values                               \u2502   \u2502\n",
    "\u2502  \u2502    \u274c No detecta: \"N/A\", \"Unknown\", \"\u2014\"                 \u2502   \u2502\n",
    "\u2502  \u2502                                                          \u2502   \u2502\n",
    "\u2502  \u2502 2. Range Checks                                          \u2502   \u2502\n",
    "\u2502  \u2502    assert (edad >= 0) & (edad <= 120)                    \u2502   \u2502\n",
    "\u2502  \u2502    \u2705 Detecta: edad = -5 o 200                           \u2502   \u2502\n",
    "\u2502  \u2502    \u274c No detecta: edad = 999 (typo de 99)               \u2502   \u2502\n",
    "\u2502  \u2502                                                          \u2502   \u2502\n",
    "\u2502  \u2502 3. Regex Validation                                      \u2502   \u2502\n",
    "\u2502  \u2502    assert email.str.match(r'^[\\w.-]+@[\\w.-]+\\.\\w+$')    \u2502   \u2502\n",
    "\u2502  \u2502    \u2705 Detecta: \"invalid-email\"                           \u2502   \u2502\n",
    "\u2502  \u2502    \u274c No detecta: \"test@test.test\" (fake)               \u2502   \u2502\n",
    "\u2502  \u2502                                                          \u2502   \u2502\n",
    "\u2502  \u2502 4. Referential Integrity                                 \u2502   \u2502\n",
    "\u2502  \u2502    assert ventas.producto_id.isin(productos.id)          \u2502   \u2502\n",
    "\u2502  \u2502    \u2705 Detecta: producto_id = 999 (no existe)            \u2502   \u2502\n",
    "\u2502  \u2502    \u274c No explica POR QU\u00c9 fall\u00f3                          \u2502   \u2502\n",
    "\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n",
    "\u2502                                                                  \u2502\n",
    "\u2502  LLM-POWERED (Semantic + Contextual):                            \u2502\n",
    "\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n",
    "\u2502  \u2502 1. Semantic Null Detection                               \u2502   \u2502\n",
    "\u2502  \u2502    LLM analiza: \"N/A\", \"Unknown\", \"\u2014\", \"TBD\"            \u2502   \u2502\n",
    "\u2502  \u2502    \u2192 Detecta pseudo-nulls con contexto                   \u2502   \u2502\n",
    "\u2502  \u2502    \u2705 \"N/A\" en columna 'ciudad' \u2192 NULL sem\u00e1ntico        \u2502   \u2502\n",
    "\u2502  \u2502    \u2705 \"N/A\" en columna 'notas' \u2192 V\u00e1lido                 \u2502   \u2502\n",
    "\u2502  \u2502                                                          \u2502   \u2502\n",
    "\u2502  \u2502 2. Contextual Outlier Detection                          \u2502   \u2502\n",
    "\u2502  \u2502    LLM: \"edad = 999 es typo de 99 (patr\u00f3n com\u00fan)\"       \u2502   \u2502\n",
    "\u2502  \u2502    \u2192 Sugiere correcci\u00f3n basada en contexto              \u2502   \u2502\n",
    "\u2502  \u2502    \u2705 Explica: \"Probablemente typo en entrada manual\"   \u2502   \u2502\n",
    "\u2502  \u2502    \u2705 Sugiere: 99 o 9 (seg\u00fan distribuci\u00f3n)              \u2502   \u2502\n",
    "\u2502  \u2502                                                          \u2502   \u2502\n",
    "\u2502  \u2502 3. Plausibility Validation                               \u2502   \u2502\n",
    "\u2502  \u2502    LLM: \"test@test.test es email t\u00e9cnico, no real\"      \u2502   \u2502\n",
    "\u2502  \u2502    \u2192 Detecta datos sint\u00e9ticamente v\u00e1lidos pero falsos   \u2502   \u2502\n",
    "\u2502  \u2502    \u2705 \"admin@example.com\" \u2192 Test data                   \u2502   \u2502\n",
    "\u2502  \u2502    \u2705 \"Nueva Yorkk\" \u2192 Typo de \"Nueva York\"              \u2502   \u2502\n",
    "\u2502  \u2502                                                          \u2502   \u2502\n",
    "\u2502  \u2502 4. Root Cause Analysis                                   \u2502   \u2502\n",
    "\u2502  \u2502    LLM: \"50 producto_ids hu\u00e9rfanos desde 2024-10-15\"    \u2502   \u2502\n",
    "\u2502  \u2502    \u2192 Analiza: \"Coincide con deploy de API v2\"           \u2502   \u2502\n",
    "\u2502  \u2502    \u2705 Explica causa probable                            \u2502   \u2502\n",
    "\u2502  \u2502    \u2705 Sugiere soluci\u00f3n: \"Mapear IDs antiguos\u2192nuevos\"    \u2502   \u2502\n",
    "\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n",
    "\u2502                                                                  \u2502\n",
    "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "```\n",
    "\n",
    "### \ud83c\udfaf Casos de Uso: LLMs vs Traditional\n",
    "\n",
    "| Problema | Traditional | LLM-Powered | Ganador |\n",
    "|----------|-------------|-------------|---------|\n",
    "| **NULL detection** | `column.isnull()` | Detecta \"N/A\", \"Unknown\", \"\u2014\" | \ud83c\udfc6 LLM |\n",
    "| **Email validation** | Regex pattern | Detecta test@test.com como fake | \ud83c\udfc6 LLM |\n",
    "| **City names** | Whitelist de ciudades | Detecta \"Nueva Yorkk\" como typo | \ud83c\udfc6 LLM |\n",
    "| **Age range** | `age.between(0, 120)` | \"999 es typo de 99\" | \ud83c\udfc6 LLM |\n",
    "| **Performance** | Instant\u00e1neo | 100-500ms por validaci\u00f3n | \ud83c\udfc6 Traditional |\n",
    "| **Costo** | Gratis | $0.001-$0.01 por registro | \ud83c\udfc6 Traditional |\n",
    "| **Explicabilidad** | Regla booleana | Natural language explanation | \ud83c\udfc6 LLM |\n",
    "\n",
    "**Conclusi\u00f3n**: LLMs **complementan** (no reemplazan) validaci\u00f3n tradicional. Usar ambos en **h\u00edbrido**.\n",
    "\n",
    "### \ud83d\udd27 Implementaci\u00f3n: Sistema H\u00edbrido de Validaci\u00f3n\n",
    "\n",
    "```python\n",
    "from typing import List, Dict, Optional, Literal\n",
    "from pydantic import BaseModel, Field\n",
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dataclasses import dataclass\n",
    "from enum import Enum\n",
    "import json\n",
    "\n",
    "client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))\n",
    "\n",
    "# 1. MODELOS DE DATOS\n",
    "\n",
    "class ValidationSeverity(str, Enum):\n",
    "    \"\"\"Severidad de issue de calidad.\"\"\"\n",
    "    CRITICAL = \"CRITICAL\"  # Bloquea pipeline\n",
    "    ERROR = \"ERROR\"        # Requiere fix\n",
    "    WARNING = \"WARNING\"    # Revisar\n",
    "    INFO = \"INFO\"          # Informativo\n",
    "\n",
    "class ValidationIssue(BaseModel):\n",
    "    \"\"\"Issue de calidad detectado.\"\"\"\n",
    "    column: str\n",
    "    row_index: Optional[int] = None\n",
    "    value: Optional[str] = None\n",
    "    issue_type: str  # NULLS, OUTLIER, FORMAT, INCONSISTENCY, etc.\n",
    "    severity: ValidationSeverity\n",
    "    confidence: float = Field(..., ge=0, le=1)\n",
    "    description: str\n",
    "    suggested_fix: Optional[str] = None\n",
    "    detected_by: Literal[\"traditional\", \"llm\", \"hybrid\"]\n",
    "\n",
    "class ValidationReport(BaseModel):\n",
    "    \"\"\"Reporte completo de validaci\u00f3n.\"\"\"\n",
    "    table_name: str\n",
    "    total_rows: int\n",
    "    total_issues: int\n",
    "    issues_by_severity: Dict[ValidationSeverity, int]\n",
    "    issues: List[ValidationIssue]\n",
    "    execution_time_seconds: float\n",
    "    cost_usd: float\n",
    "\n",
    "# 2. VALIDADORES TRADICIONALES\n",
    "\n",
    "class TraditionalValidator:\n",
    "    \"\"\"Validador basado en reglas est\u00e1ticas.\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def check_nulls(df: pd.DataFrame, column: str) -> List[ValidationIssue]:\n",
    "        \"\"\"Detecta valores NULL.\"\"\"\n",
    "        null_mask = df[column].isnull()\n",
    "        null_count = null_mask.sum()\n",
    "        \n",
    "        if null_count == 0:\n",
    "            return []\n",
    "        \n",
    "        # Detectar todos los nulls\n",
    "        issues = []\n",
    "        for idx in df[null_mask].index[:100]:  # Limitar a 100 por performance\n",
    "            issues.append(ValidationIssue(\n",
    "                column=column,\n",
    "                row_index=int(idx),\n",
    "                value=None,\n",
    "                issue_type=\"NULLS\",\n",
    "                severity=ValidationSeverity.ERROR,\n",
    "                confidence=1.0,\n",
    "                description=f\"Valor NULL en columna requerida '{column}'\",\n",
    "                suggested_fix=\"Impute con media/moda o remover registro\",\n",
    "                detected_by=\"traditional\"\n",
    "            ))\n",
    "        \n",
    "        return issues\n",
    "    \n",
    "    @staticmethod\n",
    "    def check_range(\n",
    "        df: pd.DataFrame, \n",
    "        column: str, \n",
    "        min_val: float, \n",
    "        max_val: float\n",
    "    ) -> List[ValidationIssue]:\n",
    "        \"\"\"Detecta valores fuera de rango.\"\"\"\n",
    "        out_of_range = df[(df[column] < min_val) | (df[column] > max_val)]\n",
    "        \n",
    "        issues = []\n",
    "        for idx, row in out_of_range.iterrows():\n",
    "            value = row[column]\n",
    "            issues.append(ValidationIssue(\n",
    "                column=column,\n",
    "                row_index=int(idx),\n",
    "                value=str(value),\n",
    "                issue_type=\"OUTLIER\",\n",
    "                severity=ValidationSeverity.ERROR,\n",
    "                confidence=1.0,\n",
    "                description=f\"Valor {value} fuera de rango [{min_val}, {max_val}]\",\n",
    "                suggested_fix=f\"Clamp a rango o marcar como outlier\",\n",
    "                detected_by=\"traditional\"\n",
    "            ))\n",
    "        \n",
    "        return issues\n",
    "    \n",
    "    @staticmethod\n",
    "    def check_regex(\n",
    "        df: pd.DataFrame, \n",
    "        column: str, \n",
    "        pattern: str\n",
    "    ) -> List[ValidationIssue]:\n",
    "        \"\"\"Valida formato con regex.\"\"\"\n",
    "        invalid_mask = ~df[column].astype(str).str.match(pattern)\n",
    "        invalid_values = df[invalid_mask]\n",
    "        \n",
    "        issues = []\n",
    "        for idx, row in invalid_values.iterrows():\n",
    "            value = row[column]\n",
    "            issues.append(ValidationIssue(\n",
    "                column=column,\n",
    "                row_index=int(idx),\n",
    "                value=str(value),\n",
    "                issue_type=\"FORMAT\",\n",
    "                severity=ValidationSeverity.ERROR,\n",
    "                confidence=1.0,\n",
    "                description=f\"Valor '{value}' no coincide con patr\u00f3n esperado\",\n",
    "                suggested_fix=\"Reformatear seg\u00fan pattern\",\n",
    "                detected_by=\"traditional\"\n",
    "            ))\n",
    "        \n",
    "        return issues\n",
    "\n",
    "# 3. VALIDADOR CON LLM\n",
    "\n",
    "class LLMValidator:\n",
    "    \"\"\"Validador con an\u00e1lisis sem\u00e1ntico usando LLM.\"\"\"\n",
    "    \n",
    "    def __init__(self, model: str = \"gpt-4o-mini\"):  # Modelo barato para validaci\u00f3n\n",
    "        self.model = model\n",
    "        self.total_cost = 0.0\n",
    "    \n",
    "    def check_semantic_nulls(\n",
    "        self, \n",
    "        df: pd.DataFrame, \n",
    "        column: str\n",
    "    ) -> List[ValidationIssue]:\n",
    "        \"\"\"\n",
    "        Detecta valores que son NULL sem\u00e1nticamente (N/A, Unknown, TBD, etc.)\n",
    "        pero no NULL sint\u00e1cticamente.\n",
    "        \"\"\"\n",
    "        # Obtener valores \u00fanicos no-null\n",
    "        non_null_values = df[column].dropna().unique()[:50]  # Limitar muestra\n",
    "        \n",
    "        prompt = f\"\"\"Analiza estos valores de la columna '{column}' y detecta cu\u00e1les son NULL sem\u00e1nticos (representan faltante/desconocido/no aplicable):\n",
    "\n",
    "Valores: {list(non_null_values)}\n",
    "\n",
    "Responde en JSON:\n",
    "{{\n",
    "  \"semantic_nulls\": [\"valor1\", \"valor2\", ...],\n",
    "  \"confidence\": 0.0-1.0,\n",
    "  \"reasoning\": \"explicaci\u00f3n breve\"\n",
    "}}\"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=self.model,\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                temperature=0,\n",
    "                response_format={\"type\": \"json_object\"}\n",
    "            )\n",
    "            \n",
    "            result = json.loads(response.choices[0].message.content)\n",
    "            \n",
    "            # Calcular costo aproximado (gpt-4o-mini: $0.15/$0.60 por 1M tokens)\n",
    "            input_tokens = len(prompt) / 4  # Aproximaci\u00f3n\n",
    "            output_tokens = len(response.choices[0].message.content) / 4\n",
    "            cost = (input_tokens / 1_000_000 * 0.15) + (output_tokens / 1_000_000 * 0.60)\n",
    "            self.total_cost += cost\n",
    "            \n",
    "            # Crear issues para cada NULL sem\u00e1ntico\n",
    "            issues = []\n",
    "            for null_value in result.get(\"semantic_nulls\", []):\n",
    "                mask = df[column] == null_value\n",
    "                for idx in df[mask].index[:100]:\n",
    "                    issues.append(ValidationIssue(\n",
    "                        column=column,\n",
    "                        row_index=int(idx),\n",
    "                        value=str(null_value),\n",
    "                        issue_type=\"SEMANTIC_NULL\",\n",
    "                        severity=ValidationSeverity.WARNING,\n",
    "                        confidence=result.get(\"confidence\", 0.8),\n",
    "                        description=f\"'{null_value}' es NULL sem\u00e1ntico: {result.get('reasoning', '')}\",\n",
    "                        suggested_fix=\"Convertir a NULL expl\u00edcito\",\n",
    "                        detected_by=\"llm\"\n",
    "                    ))\n",
    "            \n",
    "            return issues\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error en LLM validation: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def check_plausibility(\n",
    "        self, \n",
    "        df: pd.DataFrame, \n",
    "        column: str, \n",
    "        context: str = \"\"\n",
    "    ) -> List[ValidationIssue]:\n",
    "        \"\"\"\n",
    "        Valida plausibilidad de valores (ej. emails fake, ciudades con typos).\n",
    "        \"\"\"\n",
    "        sample_values = df[column].dropna().head(20).tolist()\n",
    "        \n",
    "        prompt = f\"\"\"Analiza la plausibilidad de estos valores en la columna '{column}':\n",
    "\n",
    "Contexto: {context}\n",
    "Valores: {sample_values}\n",
    "\n",
    "Detecta valores implausibles (fake, typos, test data, etc.).\n",
    "\n",
    "Responde en JSON:\n",
    "{{\n",
    "  \"implausible_values\": [\n",
    "    {{\n",
    "      \"value\": \"valor\",\n",
    "      \"reason\": \"explicaci\u00f3n\",\n",
    "      \"confidence\": 0.0-1.0,\n",
    "      \"suggested_fix\": \"correcci\u00f3n o null\"\n",
    "    }}\n",
    "  ]\n",
    "}}\"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=self.model,\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                temperature=0,\n",
    "                response_format={\"type\": \"json_object\"}\n",
    "            )\n",
    "            \n",
    "            result = json.loads(response.choices[0].message.content)\n",
    "            \n",
    "            # Costo\n",
    "            cost = (len(prompt) / 4 / 1_000_000 * 0.15) + (len(response.choices[0].message.content) / 4 / 1_000_000 * 0.60)\n",
    "            self.total_cost += cost\n",
    "            \n",
    "            issues = []\n",
    "            for item in result.get(\"implausible_values\", []):\n",
    "                mask = df[column] == item[\"value\"]\n",
    "                for idx in df[mask].index:\n",
    "                    issues.append(ValidationIssue(\n",
    "                        column=column,\n",
    "                        row_index=int(idx),\n",
    "                        value=str(item[\"value\"]),\n",
    "                        issue_type=\"IMPLAUSIBLE\",\n",
    "                        severity=ValidationSeverity.WARNING,\n",
    "                        confidence=item.get(\"confidence\", 0.7),\n",
    "                        description=f\"Valor implausible: {item.get('reason', '')}\",\n",
    "                        suggested_fix=item.get(\"suggested_fix\"),\n",
    "                        detected_by=\"llm\"\n",
    "                    ))\n",
    "            \n",
    "            return issues\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error en plausibility check: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def explain_outlier(\n",
    "        self, \n",
    "        value: float, \n",
    "        column: str,\n",
    "        stats: Dict[str, float]\n",
    "    ) -> str:\n",
    "        \"\"\"Explica por qu\u00e9 un valor es outlier en lenguaje natural.\"\"\"\n",
    "        prompt = f\"\"\"Explica por qu\u00e9 este valor es an\u00f3malo en 2-3 frases:\n",
    "\n",
    "Columna: {column}\n",
    "Valor: {value}\n",
    "\n",
    "Estad\u00edsticas:\n",
    "- Media: {stats['mean']:.2f}\n",
    "- Desv. est\u00e1ndar: {stats['std']:.2f}\n",
    "- Min: {stats['min']:.2f}\n",
    "- Max (sin este): {stats['max']:.2f}\n",
    "- Percentil 99: {stats.get('p99', 'N/A')}\n",
    "\n",
    "Incluye posible causa ra\u00edz (typo, error de medici\u00f3n, evento real extremo, etc.).\"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=self.model,\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                temperature=0.3\n",
    "            )\n",
    "            \n",
    "            cost = (len(prompt) / 4 / 1_000_000 * 0.15) + (len(response.choices[0].message.content) / 4 / 1_000_000 * 0.60)\n",
    "            self.total_cost += cost\n",
    "            \n",
    "            return response.choices[0].message.content.strip()\n",
    "            \n",
    "        except Exception as e:\n",
    "            return f\"Error generando explicaci\u00f3n: {e}\"\n",
    "\n",
    "# 4. VALIDADOR H\u00cdBRIDO (COMBINA AMBOS)\n",
    "\n",
    "class HybridValidator:\n",
    "    \"\"\"Sistema h\u00edbrido: Traditional (r\u00e1pido) + LLM (sem\u00e1ntico).\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.traditional = TraditionalValidator()\n",
    "        self.llm = LLMValidator()\n",
    "    \n",
    "    def validate_dataframe(\n",
    "        self, \n",
    "        df: pd.DataFrame, \n",
    "        table_name: str,\n",
    "        validation_config: Dict\n",
    "    ) -> ValidationReport:\n",
    "        \"\"\"\n",
    "        Valida DataFrame completo con estrategia h\u00edbrida.\n",
    "        \n",
    "        Args:\n",
    "            df: DataFrame a validar\n",
    "            table_name: nombre de la tabla\n",
    "            validation_config: configuraci\u00f3n por columna\n",
    "                {\n",
    "                    \"column_name\": {\n",
    "                        \"checks\": [\"nulls\", \"range\", \"semantic_nulls\", \"plausibility\"],\n",
    "                        \"range\": [0, 120],\n",
    "                        \"context\": \"descripci\u00f3n para LLM\"\n",
    "                    }\n",
    "                }\n",
    "        \"\"\"\n",
    "        import time\n",
    "        start_time = time.time()\n",
    "        \n",
    "        all_issues = []\n",
    "        \n",
    "        for column, config in validation_config.items():\n",
    "            if column not in df.columns:\n",
    "                continue\n",
    "            \n",
    "            checks = config.get(\"checks\", [])\n",
    "            \n",
    "            # TRADITIONAL CHECKS (siempre primero - r\u00e1pidos)\n",
    "            if \"nulls\" in checks:\n",
    "                all_issues.extend(self.traditional.check_nulls(df, column))\n",
    "            \n",
    "            if \"range\" in checks and \"range\" in config:\n",
    "                min_val, max_val = config[\"range\"]\n",
    "                all_issues.extend(self.traditional.check_range(df, column, min_val, max_val))\n",
    "            \n",
    "            if \"regex\" in checks and \"pattern\" in config:\n",
    "                all_issues.extend(self.traditional.check_regex(df, column, config[\"pattern\"]))\n",
    "            \n",
    "            # LLM CHECKS (solo si hay issues o configurado expl\u00edcitamente)\n",
    "            if \"semantic_nulls\" in checks:\n",
    "                all_issues.extend(self.llm.check_semantic_nulls(df, column))\n",
    "            \n",
    "            if \"plausibility\" in checks:\n",
    "                context = config.get(\"context\", f\"Columna {column}\")\n",
    "                all_issues.extend(self.llm.check_plausibility(df, column, context))\n",
    "        \n",
    "        # Generar reporte\n",
    "        execution_time = time.time() - start_time\n",
    "        \n",
    "        issues_by_severity = {\n",
    "            severity: sum(1 for issue in all_issues if issue.severity == severity)\n",
    "            for severity in ValidationSeverity\n",
    "        }\n",
    "        \n",
    "        report = ValidationReport(\n",
    "            table_name=table_name,\n",
    "            total_rows=len(df),\n",
    "            total_issues=len(all_issues),\n",
    "            issues_by_severity=issues_by_severity,\n",
    "            issues=all_issues,\n",
    "            execution_time_seconds=execution_time,\n",
    "            cost_usd=self.llm.total_cost\n",
    "        )\n",
    "        \n",
    "        return report\n",
    "\n",
    "# EJEMPLO DE USO\n",
    "\n",
    "# Dataset de prueba con varios tipos de problemas\n",
    "df_test = pd.DataFrame({\n",
    "    'customer_id': [1, 2, 3, 4, 5, 6, 7, 8],\n",
    "    'age': [25, 30, 999, 45, None, 22, -5, 150],  # Outliers, null, negativos\n",
    "    'email': [\n",
    "        'user@example.com',\n",
    "        'admin@test.test',  # Fake\n",
    "        'invalid-email',     # Inv\u00e1lido\n",
    "        'test@test.com',     # Test data\n",
    "        None,\n",
    "        'real@company.io',\n",
    "        'N/A',               # NULL sem\u00e1ntico\n",
    "        'john@gmail.com'\n",
    "    ],\n",
    "    'city': [\n",
    "        'New York',\n",
    "        'Nueva Yorkk',  # Typo\n",
    "        'Los Angeles',\n",
    "        'Unknown',      # NULL sem\u00e1ntico\n",
    "        'San Francisco',\n",
    "        'N/A',          # NULL sem\u00e1ntico\n",
    "        'Chicago',\n",
    "        'TBD'           # NULL sem\u00e1ntico\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Configuraci\u00f3n de validaci\u00f3n\n",
    "validation_config = {\n",
    "    'age': {\n",
    "        'checks': ['nulls', 'range'],\n",
    "        'range': [0, 120]\n",
    "    },\n",
    "    'email': {\n",
    "        'checks': ['nulls', 'regex', 'plausibility'],\n",
    "        'pattern': r'^[\\w\\.-]+@[\\w\\.-]+\\.\\w+$',\n",
    "        'context': 'Emails de clientes reales (no test data)'\n",
    "    },\n",
    "    'city': {\n",
    "        'checks': ['semantic_nulls', 'plausibility'],\n",
    "        'context': 'Ciudades de USA'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Ejecutar validaci\u00f3n h\u00edbrida\n",
    "validator = HybridValidator()\n",
    "report = validator.validate_dataframe(df_test, 'customers', validation_config)\n",
    "\n",
    "# Mostrar resultados\n",
    "print(f\"\ud83d\udcca REPORTE DE VALIDACI\u00d3N: {report.table_name}\")\n",
    "print(f\"   Total filas: {report.total_rows}\")\n",
    "print(f\"   Total issues: {report.total_issues}\")\n",
    "print(f\"   Tiempo: {report.execution_time_seconds:.2f}s\")\n",
    "print(f\"   Costo LLM: ${report.cost_usd:.4f}\")\n",
    "print(f\"\\n   Issues por severidad:\")\n",
    "for severity, count in report.issues_by_severity.items():\n",
    "    if count > 0:\n",
    "        print(f\"     {severity.value}: {count}\")\n",
    "\n",
    "print(f\"\\n\ud83d\udd0d ISSUES DETECTADOS (top 10):\")\n",
    "for i, issue in enumerate(report.issues[:10], 1):\n",
    "    print(f\"\\n{i}. [{issue.severity.value}] {issue.issue_type}\")\n",
    "    print(f\"   Columna: {issue.column}, Fila: {issue.row_index}\")\n",
    "    print(f\"   Valor: {issue.value}\")\n",
    "    print(f\"   {issue.description}\")\n",
    "    print(f\"   Confianza: {issue.confidence:.0%} | Detectado por: {issue.detected_by}\")\n",
    "    if issue.suggested_fix:\n",
    "        print(f\"   \ud83d\udca1 Fix sugerido: {issue.suggested_fix}\")\n",
    "```\n",
    "\n",
    "### \ud83d\udcca Comparaci\u00f3n de Performance\n",
    "\n",
    "```python\n",
    "import time\n",
    "\n",
    "# Benchmark: Traditional vs LLM\n",
    "df_large = pd.DataFrame({\n",
    "    'age': np.random.randint(18, 70, size=10000),\n",
    "    'email': ['user{}@example.com'.format(i) for i in range(10000)]\n",
    "})\n",
    "\n",
    "# Traditional validation\n",
    "start = time.time()\n",
    "trad_validator = TraditionalValidator()\n",
    "trad_issues = trad_validator.check_range(df_large, 'age', 0, 120)\n",
    "trad_time = time.time() - start\n",
    "\n",
    "print(f\"Traditional: {trad_time*1000:.2f}ms, {len(trad_issues)} issues, $0\")\n",
    "\n",
    "# LLM validation (solo muestra)\n",
    "start = time.time()\n",
    "llm_validator = LLMValidator()\n",
    "llm_issues = llm_validator.check_plausibility(df_large.head(20), 'email', 'Customer emails')\n",
    "llm_time = time.time() - start\n",
    "\n",
    "print(f\"LLM: {llm_time*1000:.2f}ms, {len(llm_issues)} issues, ${llm_validator.total_cost:.4f}\")\n",
    "print(f\"\\n\ud83d\udca1 LLM es {llm_time/trad_time:.0f}x m\u00e1s lento pero detecta issues sem\u00e1nticos\")\n",
    "```\n",
    "\n",
    "### \ud83c\udfaf Estrategia de Uso \u00d3ptima\n",
    "\n",
    "```python\n",
    "# REGLA DE ORO: H\u00edbrido inteligente\n",
    "\n",
    "# 1. TRADITIONAL FIRST (always)\n",
    "#    - R\u00e1pido, gratis, confiable\n",
    "#    - Cubre 80% de casos\n",
    "\n",
    "# 2. LLM IF:\n",
    "#    a) Traditional encontr\u00f3 issues ambiguos\n",
    "#    b) Columnas cr\u00edticas (PII, identificadores, nombres)\n",
    "#    c) Sample peque\u00f1o (<1000 registros \u00fanicos)\n",
    "#    d) Budget disponible ($0.01-$0.10 por tabla)\n",
    "\n",
    "# Ejemplo de decisi\u00f3n:\n",
    "def should_use_llm(df: pd.DataFrame, column: str, trad_issues: int) -> bool:\n",
    "    \"\"\"Decide si vale la pena usar LLM.\"\"\"\n",
    "    unique_count = df[column].nunique()\n",
    "    \n",
    "    # Criterios para usar LLM:\n",
    "    if trad_issues > 0 and trad_issues < 100:  # Issues moderados\n",
    "        return True\n",
    "    \n",
    "    if unique_count < 100:  # Pocos valores \u00fanicos (categ\u00f3ricos)\n",
    "        return True\n",
    "    \n",
    "    if column in ['email', 'name', 'city', 'address']:  # Campos cr\u00edticos\n",
    "        return True\n",
    "    \n",
    "    return False\n",
    "```\n",
    "\n",
    "### \ud83d\ude80 Mejores Pr\u00e1cticas\n",
    "\n",
    "1. **Siempre traditional primero**: Fast fail para issues obvios\n",
    "2. **LLM como segunda capa**: Solo para casos ambiguos o sem\u00e1nticos\n",
    "3. **Cache agresivo**: Mismos valores \u2192 misma respuesta (lru_cache)\n",
    "4. **Batch validation**: Validar m\u00faltiples valores en un solo prompt\n",
    "5. **Confidence thresholds**: Solo actuar si confidence >0.8\n",
    "6. **Human review**: Issues con confidence <0.9 requieren revisi\u00f3n\n",
    "7. **Cost monitoring**: Alertar si costo >$1 por tabla\n",
    "8. **A/B testing**: Comparar LLM vs tradicional en m\u00e9tricas de negocio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb72719",
   "metadata": {},
   "source": [
    "## \ud83e\udd16 Generaci\u00f3n Autom\u00e1tica de Reglas de Validaci\u00f3n con LLMs\n",
    "\n",
    "Escribir reglas de validaci\u00f3n manualmente es tedioso y propenso a errores. Los **LLMs** pueden **inferir reglas de validaci\u00f3n** analizando datos y generando c\u00f3digo de Great Expectations, dbt tests, o Pandas assertions autom\u00e1ticamente.\n",
    "\n",
    "### \ud83c\udfd7\ufe0f Arquitectura de Auto-Generaci\u00f3n de Reglas\n",
    "\n",
    "```\n",
    "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "\u2502      AUTO-GENERATION: FROM DATA TO VALIDATION RULES              \u2502\n",
    "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
    "\u2502                                                                  \u2502\n",
    "\u2502  INPUT: DataFrame con datos hist\u00f3ricos                          \u2502\n",
    "\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n",
    "\u2502  \u2502 df['age']: [25, 30, 45, 22, 28, ...]                     \u2502   \u2502\n",
    "\u2502  \u2502 df['email']: ['user@x.com', 'admin@y.org', ...]          \u2502   \u2502\n",
    "\u2502  \u2502 df['status']: ['active', 'active', 'inactive', ...]      \u2502   \u2502\n",
    "\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n",
    "\u2502        \u2193                                                         \u2502\n",
    "\u2502  1\ufe0f\u20e3 PROFILE DATA (EDA autom\u00e1tico)                              \u2502\n",
    "\u2502     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u2502\n",
    "\u2502     \u2502 pandas-profiling / ydata-profiling                 \u2502      \u2502\n",
    "\u2502     \u2502 \u2022 Tipos de datos (int, str, datetime)             \u2502      \u2502\n",
    "\u2502     \u2502 \u2022 Distribuciones (mean, std, quantiles)           \u2502      \u2502\n",
    "\u2502     \u2502 \u2022 Valores \u00fanicos y frecuencias                    \u2502      \u2502\n",
    "\u2502     \u2502 \u2022 Nulls, duplicates, outliers                     \u2502      \u2502\n",
    "\u2502     \u2502 \u2022 Correlaciones entre columnas                    \u2502      \u2502\n",
    "\u2502     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518      \u2502\n",
    "\u2502        \u2193                                                         \u2502\n",
    "\u2502  2\ufe0f\u20e3 INFER RULES (LLM analiza profile)                          \u2502\n",
    "\u2502     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u2502\n",
    "\u2502     \u2502 Prompt: \"Bas\u00e1ndote en estas estad\u00edsticas,         \u2502      \u2502\n",
    "\u2502     \u2502          genera reglas de validaci\u00f3n...\"           \u2502      \u2502\n",
    "\u2502     \u2502                                                    \u2502      \u2502\n",
    "\u2502     \u2502 LLM \u2192 Reglas inferidas:                           \u2502      \u2502\n",
    "\u2502     \u2502  age:                                              \u2502      \u2502\n",
    "\u2502     \u2502    - No NULL (0% nulls observed)                  \u2502      \u2502\n",
    "\u2502     \u2502    - Range [18, 65] (min=18, max=65, no outliers)\u2502      \u2502\n",
    "\u2502     \u2502    - Integer type                                 \u2502      \u2502\n",
    "\u2502     \u2502                                                    \u2502      \u2502\n",
    "\u2502     \u2502  email:                                            \u2502      \u2502\n",
    "\u2502     \u2502    - Match regex ^[\\w.-]+@[\\w.-]+\\.\\w+$          \u2502      \u2502\n",
    "\u2502     \u2502    - No duplicates (100% unique)                  \u2502      \u2502\n",
    "\u2502     \u2502    - Max length 100 chars                         \u2502      \u2502\n",
    "\u2502     \u2502                                                    \u2502      \u2502\n",
    "\u2502     \u2502  status:                                           \u2502      \u2502\n",
    "\u2502     \u2502    - IN ['active', 'inactive', 'pending']         \u2502      \u2502\n",
    "\u2502     \u2502    - No NULL (0% nulls)                           \u2502      \u2502\n",
    "\u2502     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518      \u2502\n",
    "\u2502        \u2193                                                         \u2502\n",
    "\u2502  3\ufe0f\u20e3 GENERATE CODE (Target framework)                           \u2502\n",
    "\u2502     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u2502\n",
    "\u2502     \u2502 Great Expectations:                                \u2502      \u2502\n",
    "\u2502     \u2502 ```python                                          \u2502      \u2502\n",
    "\u2502     \u2502 suite.expect_column_values_to_not_be_null('age')  \u2502      \u2502\n",
    "\u2502     \u2502 suite.expect_column_values_to_be_between(         \u2502      \u2502\n",
    "\u2502     \u2502     'age', min_value=18, max_value=65)            \u2502      \u2502\n",
    "\u2502     \u2502 suite.expect_column_values_to_match_regex(        \u2502      \u2502\n",
    "\u2502     \u2502     'email', regex='^[\\w.-]+@[\\w.-]+\\.\\w+$')     \u2502      \u2502\n",
    "\u2502     \u2502 ```                                                \u2502      \u2502\n",
    "\u2502     \u2502                                                    \u2502      \u2502\n",
    "\u2502     \u2502 dbt tests:                                         \u2502      \u2502\n",
    "\u2502     \u2502 ```yaml                                            \u2502      \u2502\n",
    "\u2502     \u2502 - name: age                                        \u2502      \u2502\n",
    "\u2502     \u2502   tests:                                           \u2502      \u2502\n",
    "\u2502     \u2502     - not_null                                     \u2502      \u2502\n",
    "\u2502     \u2502     - dbt_utils.accepted_range:                   \u2502      \u2502\n",
    "\u2502     \u2502         min_value: 18                              \u2502      \u2502\n",
    "\u2502     \u2502         max_value: 65                              \u2502      \u2502\n",
    "\u2502     \u2502 ```                                                \u2502      \u2502\n",
    "\u2502     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518      \u2502\n",
    "\u2502        \u2193                                                         \u2502\n",
    "\u2502  4\ufe0f\u20e3 VALIDATE & REFINE                                          \u2502\n",
    "\u2502     - Ejecutar reglas contra datos nuevos                       \u2502\n",
    "\u2502     - Si >5% false positives \u2192 Ajustar thresholds               \u2502\n",
    "\u2502     - Human review de reglas generadas                          \u2502\n",
    "\u2502        \u2193                                                         \u2502\n",
    "\u2502  OUTPUT: Validation suite lista para producci\u00f3n                 \u2502\n",
    "\u2502                                                                  \u2502\n",
    "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "```\n",
    "\n",
    "### \ud83d\udd27 Implementaci\u00f3n Completa\n",
    "\n",
    "```python\n",
    "from typing import Dict, List, Optional\n",
    "from pydantic import BaseModel\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "import json\n",
    "\n",
    "client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))\n",
    "\n",
    "# 1. DATA PROFILER\n",
    "\n",
    "class ColumnProfile(BaseModel):\n",
    "    \"\"\"Profile estad\u00edstico de una columna.\"\"\"\n",
    "    name: str\n",
    "    dtype: str\n",
    "    count: int\n",
    "    null_count: int\n",
    "    null_percentage: float\n",
    "    unique_count: int\n",
    "    unique_percentage: float\n",
    "    \n",
    "    # Num\u00e9rico\n",
    "    mean: Optional[float] = None\n",
    "    std: Optional[float] = None\n",
    "    min: Optional[float] = None\n",
    "    max: Optional[float] = None\n",
    "    q25: Optional[float] = None\n",
    "    q50: Optional[float] = None\n",
    "    q75: Optional[float] = None\n",
    "    \n",
    "    # String\n",
    "    avg_length: Optional[float] = None\n",
    "    max_length: Optional[int] = None\n",
    "    \n",
    "    # Categorical\n",
    "    top_values: Optional[Dict[str, int]] = None\n",
    "    \n",
    "    # Ejemplos\n",
    "    sample_values: List[str] = []\n",
    "\n",
    "class DataProfiler:\n",
    "    \"\"\"Genera profile estad\u00edstico de DataFrame.\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def profile_column(df: pd.DataFrame, column: str) -> ColumnProfile:\n",
    "        \"\"\"Genera profile de una columna.\"\"\"\n",
    "        col_data = df[column]\n",
    "        \n",
    "        profile = ColumnProfile(\n",
    "            name=column,\n",
    "            dtype=str(col_data.dtype),\n",
    "            count=len(col_data),\n",
    "            null_count=int(col_data.isnull().sum()),\n",
    "            null_percentage=float(col_data.isnull().mean()),\n",
    "            unique_count=int(col_data.nunique()),\n",
    "            unique_percentage=float(col_data.nunique() / len(col_data)),\n",
    "            sample_values=[str(v) for v in col_data.dropna().head(5).tolist()]\n",
    "        )\n",
    "        \n",
    "        # Stats num\u00e9ricos\n",
    "        if pd.api.types.is_numeric_dtype(col_data):\n",
    "            profile.mean = float(col_data.mean())\n",
    "            profile.std = float(col_data.std())\n",
    "            profile.min = float(col_data.min())\n",
    "            profile.max = float(col_data.max())\n",
    "            profile.q25 = float(col_data.quantile(0.25))\n",
    "            profile.q50 = float(col_data.quantile(0.50))\n",
    "            profile.q75 = float(col_data.quantile(0.75))\n",
    "        \n",
    "        # Stats string\n",
    "        if pd.api.types.is_string_dtype(col_data) or col_data.dtype == 'object':\n",
    "            str_lengths = col_data.dropna().astype(str).str.len()\n",
    "            if len(str_lengths) > 0:\n",
    "                profile.avg_length = float(str_lengths.mean())\n",
    "                profile.max_length = int(str_lengths.max())\n",
    "        \n",
    "        # Top values (para categ\u00f3ricas)\n",
    "        if profile.unique_count <= 50:  # Considerar categ\u00f3rica si <50 \u00fanicos\n",
    "            value_counts = col_data.value_counts().head(10)\n",
    "            profile.top_values = {str(k): int(v) for k, v in value_counts.items()}\n",
    "        \n",
    "        return profile\n",
    "    \n",
    "    @staticmethod\n",
    "    def profile_dataframe(df: pd.DataFrame) -> Dict[str, ColumnProfile]:\n",
    "        \"\"\"Genera profiles de todas las columnas.\"\"\"\n",
    "        return {\n",
    "            col: DataProfiler.profile_column(df, col) \n",
    "            for col in df.columns\n",
    "        }\n",
    "\n",
    "# 2. RULE GENERATOR\n",
    "\n",
    "class ValidationRule(BaseModel):\n",
    "    \"\"\"Regla de validaci\u00f3n generada.\"\"\"\n",
    "    column: str\n",
    "    rule_type: str  # not_null, range, regex, in_set, unique, etc.\n",
    "    parameters: Dict\n",
    "    confidence: float\n",
    "    reasoning: str\n",
    "    great_expectations_code: str\n",
    "    dbt_test_yaml: str\n",
    "    pandas_assertion: str\n",
    "\n",
    "class RuleGenerator:\n",
    "    \"\"\"Genera reglas de validaci\u00f3n usando LLM.\"\"\"\n",
    "    \n",
    "    def __init__(self, model: str = \"gpt-4o\"):\n",
    "        self.model = model\n",
    "    \n",
    "    def generate_rules(\n",
    "        self, \n",
    "        profile: ColumnProfile,\n",
    "        business_context: Optional[str] = None\n",
    "    ) -> List[ValidationRule]:\n",
    "        \"\"\"\n",
    "        Genera reglas de validaci\u00f3n para una columna.\n",
    "        \n",
    "        Args:\n",
    "            profile: profile estad\u00edstico de la columna\n",
    "            business_context: contexto de negocio opcional\n",
    "        \n",
    "        Returns:\n",
    "            Lista de reglas de validaci\u00f3n\n",
    "        \"\"\"\n",
    "        prompt = f\"\"\"Analiza este profile de columna y genera reglas de validaci\u00f3n apropiadas:\n",
    "\n",
    "COLUMNA: {profile.name}\n",
    "TIPO: {profile.dtype}\n",
    "REGISTROS: {profile.count}\n",
    "NULLS: {profile.null_count} ({profile.null_percentage:.1%})\n",
    "\u00daNICOS: {profile.unique_count} ({profile.unique_percentage:.1%})\n",
    "\n",
    "{\"ESTAD\u00cdSTICAS NUM\u00c9RICAS:\" if profile.mean is not None else \"\"}\n",
    "{f\"- Mean: {profile.mean:.2f}\" if profile.mean is not None else \"\"}\n",
    "{f\"- Std: {profile.std:.2f}\" if profile.std is not None else \"\"}\n",
    "{f\"- Range: [{profile.min}, {profile.max}]\" if profile.min is not None else \"\"}\n",
    "{f\"- Q25/Q50/Q75: {profile.q25:.2f}/{profile.q50:.2f}/{profile.q75:.2f}\" if profile.q25 is not None else \"\"}\n",
    "\n",
    "{\"ESTAD\u00cdSTICAS STRING:\" if profile.avg_length is not None else \"\"}\n",
    "{f\"- Avg length: {profile.avg_length:.1f}\" if profile.avg_length is not None else \"\"}\n",
    "{f\"- Max length: {profile.max_length}\" if profile.max_length is not None else \"\"}\n",
    "\n",
    "{\"TOP VALUES:\" if profile.top_values else \"\"}\n",
    "{json.dumps(profile.top_values, indent=2) if profile.top_values else \"\"}\n",
    "\n",
    "EJEMPLOS: {profile.sample_values}\n",
    "\n",
    "{f\"CONTEXTO DE NEGOCIO: {business_context}\" if business_context else \"\"}\n",
    "\n",
    "Genera 2-5 reglas de validaci\u00f3n apropiadas. Para cada regla, incluye:\n",
    "1. Tipo de regla (not_null, range, regex, in_set, unique, etc.)\n",
    "2. Par\u00e1metros de la regla\n",
    "3. Confianza (0.0-1.0) basada en qu\u00e9 tan claro es el patr\u00f3n\n",
    "4. Razonamiento (por qu\u00e9 esta regla tiene sentido)\n",
    "5. C\u00f3digo de Great Expectations\n",
    "6. dbt test en YAML\n",
    "7. Assertion de Pandas\n",
    "\n",
    "Responde en JSON:\n",
    "{{\n",
    "  \"rules\": [\n",
    "    {{\n",
    "      \"rule_type\": \"...\",\n",
    "      \"parameters\": {{}},\n",
    "      \"confidence\": 0.0-1.0,\n",
    "      \"reasoning\": \"...\",\n",
    "      \"great_expectations_code\": \"suite.expect_...\",\n",
    "      \"dbt_test_yaml\": \"- name: ...\\\\n  tests: ...\",\n",
    "      \"pandas_assertion\": \"assert ...\"\n",
    "    }}\n",
    "  ]\n",
    "}}\"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=self.model,\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                temperature=0.2,  # Algo de creatividad pero no mucho\n",
    "                response_format={\"type\": \"json_object\"}\n",
    "            )\n",
    "            \n",
    "            result = json.loads(response.choices[0].message.content)\n",
    "            \n",
    "            rules = []\n",
    "            for rule_data in result.get(\"rules\", []):\n",
    "                rules.append(ValidationRule(\n",
    "                    column=profile.name,\n",
    "                    rule_type=rule_data[\"rule_type\"],\n",
    "                    parameters=rule_data[\"parameters\"],\n",
    "                    confidence=rule_data[\"confidence\"],\n",
    "                    reasoning=rule_data[\"reasoning\"],\n",
    "                    great_expectations_code=rule_data[\"great_expectations_code\"],\n",
    "                    dbt_test_yaml=rule_data[\"dbt_test_yaml\"],\n",
    "                    pandas_assertion=rule_data[\"pandas_assertion\"]\n",
    "                ))\n",
    "            \n",
    "            return rules\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error generando reglas: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def generate_table_validation_suite(\n",
    "        self,\n",
    "        df: pd.DataFrame,\n",
    "        table_name: str,\n",
    "        business_context: Optional[Dict[str, str]] = None\n",
    "    ) -> Dict[str, List[ValidationRule]]:\n",
    "        \"\"\"\n",
    "        Genera suite completo de validaci\u00f3n para tabla.\n",
    "        \n",
    "        Args:\n",
    "            df: DataFrame a analizar\n",
    "            table_name: nombre de la tabla\n",
    "            business_context: diccionario {columna: contexto}\n",
    "        \n",
    "        Returns:\n",
    "            Diccionario {columna: [reglas]}\n",
    "        \"\"\"\n",
    "        print(f\"\ud83d\udd0d Generando validation suite para tabla '{table_name}'...\")\n",
    "        \n",
    "        # Profile todas las columnas\n",
    "        profiler = DataProfiler()\n",
    "        profiles = profiler.profile_dataframe(df)\n",
    "        \n",
    "        # Generar reglas para cada columna\n",
    "        all_rules = {}\n",
    "        business_context = business_context or {}\n",
    "        \n",
    "        for column, profile in profiles.items():\n",
    "            print(f\"  Analizando columna '{column}'...\")\n",
    "            \n",
    "            context = business_context.get(column, \"\")\n",
    "            rules = self.generate_rules(profile, context)\n",
    "            \n",
    "            all_rules[column] = rules\n",
    "            print(f\"    \u2713 {len(rules)} reglas generadas\")\n",
    "        \n",
    "        return all_rules\n",
    "\n",
    "# 3. GENERADOR DE C\u00d3DIGO EJECUTABLE\n",
    "\n",
    "class CodeGenerator:\n",
    "    \"\"\"Genera c\u00f3digo ejecutable de frameworks populares.\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def generate_great_expectations_suite(\n",
    "        rules_by_column: Dict[str, List[ValidationRule]],\n",
    "        suite_name: str\n",
    "    ) -> str:\n",
    "        \"\"\"Genera c\u00f3digo de Great Expectations.\"\"\"\n",
    "        code = f'''\"\"\"\n",
    "Auto-generated Great Expectations suite: {suite_name}\n",
    "Generated by LLM-powered rule generator\n",
    "\"\"\"\n",
    "\n",
    "import great_expectations as gx\n",
    "from great_expectations.core.batch import RuntimeBatchRequest\n",
    "\n",
    "# Create expectation suite\n",
    "context = gx.get_context()\n",
    "suite = context.add_expectation_suite(\n",
    "    expectation_suite_name=\"{suite_name}\",\n",
    "    overwrite_existing=True\n",
    ")\n",
    "\n",
    "# Expectations by column\n",
    "'''\n",
    "        \n",
    "        for column, rules in rules_by_column.items():\n",
    "            code += f\"\\n# {column}\\n\"\n",
    "            for rule in rules:\n",
    "                code += f\"# Confidence: {rule.confidence:.0%} - {rule.reasoning}\\n\"\n",
    "                code += f\"{rule.great_expectations_code}\\n\"\n",
    "        \n",
    "        code += '''\n",
    "# Save suite\n",
    "context.add_or_update_expectation_suite(expectation_suite=suite)\n",
    "\n",
    "print(f\"\u2713 Suite '{suite_name}' created with {len(suite.expectations)} expectations\")\n",
    "'''\n",
    "        \n",
    "        return code\n",
    "    \n",
    "    @staticmethod\n",
    "    def generate_dbt_schema_yml(\n",
    "        rules_by_column: Dict[str, List[ValidationRule]],\n",
    "        model_name: str\n",
    "    ) -> str:\n",
    "        \"\"\"Genera archivo schema.yml de dbt.\"\"\"\n",
    "        yml = f'''version: 2\n",
    "\n",
    "models:\n",
    "  - name: {model_name}\n",
    "    description: \"Auto-generated dbt tests\"\n",
    "    columns:\n",
    "'''\n",
    "        \n",
    "        for column, rules in rules_by_column.items():\n",
    "            yml += f\"      - name: {column}\\n\"\n",
    "            yml += \"        tests:\\n\"\n",
    "            \n",
    "            for rule in rules:\n",
    "                # Parsear YAML del rule (simplificado)\n",
    "                yml += f\"          # Confidence: {rule.confidence:.0%} - {rule.reasoning}\\n\"\n",
    "                yml += f\"          {rule.dbt_test_yaml}\\n\"\n",
    "        \n",
    "        return yml\n",
    "    \n",
    "    @staticmethod\n",
    "    def generate_pandas_validation_script(\n",
    "        rules_by_column: Dict[str, List[ValidationRule]],\n",
    "        script_name: str\n",
    "    ) -> str:\n",
    "        \"\"\"Genera script de validaci\u00f3n con Pandas.\"\"\"\n",
    "        code = f'''\"\"\"\n",
    "Auto-generated Pandas validation script: {script_name}\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "def validate_dataframe(df: pd.DataFrame) -> bool:\n",
    "    \"\"\"Valida DataFrame contra reglas generadas.\"\"\"\n",
    "    errors = []\n",
    "    \n",
    "'''\n",
    "        \n",
    "        for column, rules in rules_by_column.items():\n",
    "            code += f\"    # Validar columna '{column}'\\n\"\n",
    "            for rule in rules:\n",
    "                code += f\"    # {rule.reasoning} (confidence: {rule.confidence:.0%})\\n\"\n",
    "                code += f\"    try:\\n\"\n",
    "                code += f\"        {rule.pandas_assertion}\\n\"\n",
    "                code += f\"    except AssertionError as e:\\n\"\n",
    "                code += f\"        errors.append('{column}: {{e}}')\\n\"\n",
    "                code += f\"\\n\"\n",
    "        \n",
    "        code += '''    \n",
    "    if errors:\n",
    "        print(f\"\u274c Validation failed with {len(errors)} errors:\")\n",
    "        for error in errors:\n",
    "            print(f\"  - {error}\")\n",
    "        return False\n",
    "    \n",
    "    print(\"\u2705 All validations passed!\")\n",
    "    return True\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Cargar datos\n",
    "    df = pd.read_csv(\"data.csv\")\n",
    "    \n",
    "    # Validar\n",
    "    success = validate_dataframe(df)\n",
    "    \n",
    "    sys.exit(0 if success else 1)\n",
    "'''\n",
    "        \n",
    "        return code\n",
    "\n",
    "# EJEMPLO COMPLETO\n",
    "\n",
    "# Dataset de ejemplo\n",
    "df_customers = pd.DataFrame({\n",
    "    'customer_id': range(1, 101),\n",
    "    'age': np.random.randint(18, 70, size=100),\n",
    "    'email': [f'user{i}@example.com' for i in range(100)],\n",
    "    'status': np.random.choice(['active', 'inactive', 'pending'], size=100),\n",
    "    'account_balance': np.random.uniform(-100, 10000, size=100),\n",
    "    'registration_date': pd.date_range('2020-01-01', periods=100)\n",
    "})\n",
    "\n",
    "# Contexto de negocio\n",
    "business_context = {\n",
    "    'customer_id': 'Identificador \u00fanico de cliente, auto-incremental',\n",
    "    'age': 'Edad del cliente, debe ser adulto (18+)',\n",
    "    'email': 'Email de contacto, debe ser \u00fanico y v\u00e1lido',\n",
    "    'status': 'Estado de la cuenta del cliente',\n",
    "    'account_balance': 'Balance de cuenta, puede ser negativo (deuda)',\n",
    "    'registration_date': 'Fecha de registro del cliente en la plataforma'\n",
    "}\n",
    "\n",
    "# Generar reglas\n",
    "generator = RuleGenerator()\n",
    "rules_by_column = generator.generate_table_validation_suite(\n",
    "    df_customers,\n",
    "    'customers',\n",
    "    business_context\n",
    ")\n",
    "\n",
    "# Mostrar reglas generadas\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"REGLAS DE VALIDACI\u00d3N GENERADAS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for column, rules in rules_by_column.items():\n",
    "    print(f\"\\n\ud83d\udcca {column}\")\n",
    "    for i, rule in enumerate(rules, 1):\n",
    "        print(f\"\\n  {i}. {rule.rule_type.upper()}\")\n",
    "        print(f\"     Confianza: {rule.confidence:.0%}\")\n",
    "        print(f\"     Par\u00e1metros: {rule.parameters}\")\n",
    "        print(f\"     Razonamiento: {rule.reasoning}\")\n",
    "        print(f\"     GE: {rule.great_expectations_code[:80]}...\")\n",
    "\n",
    "# Generar c\u00f3digo\n",
    "code_gen = CodeGenerator()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"C\u00d3DIGO GENERADO\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Great Expectations\n",
    "ge_code = code_gen.generate_great_expectations_suite(rules_by_column, 'customers_validation')\n",
    "print(\"\\n1\ufe0f\u20e3 GREAT EXPECTATIONS:\")\n",
    "print(ge_code[:500] + \"...\\n\")\n",
    "\n",
    "# dbt\n",
    "dbt_yml = code_gen.generate_dbt_schema_yml(rules_by_column, 'stg_customers')\n",
    "print(\"\\n2\ufe0f\u20e3 DBT SCHEMA.YML:\")\n",
    "print(dbt_yml[:500] + \"...\\n\")\n",
    "\n",
    "# Pandas\n",
    "pandas_script = code_gen.generate_pandas_validation_script(rules_by_column, 'validate_customers')\n",
    "print(\"\\n3\ufe0f\u20e3 PANDAS SCRIPT:\")\n",
    "print(pandas_script[:500] + \"...\")\n",
    "```\n",
    "\n",
    "### \ud83d\udd04 Refinamiento Iterativo de Reglas\n",
    "\n",
    "```python\n",
    "class RuleRefiner:\n",
    "    \"\"\"Refina reglas bas\u00e1ndose en false positives/negatives.\"\"\"\n",
    "    \n",
    "    def __init__(self, generator: RuleGenerator):\n",
    "        self.generator = generator\n",
    "    \n",
    "    def evaluate_rule_quality(\n",
    "        self,\n",
    "        df: pd.DataFrame,\n",
    "        rule: ValidationRule,\n",
    "        ground_truth_issues: Optional[pd.Series] = None\n",
    "    ) -> Dict:\n",
    "        \"\"\"\n",
    "        Eval\u00faa calidad de una regla ejecut\u00e1ndola contra datos.\n",
    "        \n",
    "        Args:\n",
    "            df: datos a validar\n",
    "            rule: regla a evaluar\n",
    "            ground_truth_issues: m\u00e1scara booleana de registros con issues reales\n",
    "        \n",
    "        Returns:\n",
    "            M\u00e9tricas de calidad (precision, recall, false positive rate)\n",
    "        \"\"\"\n",
    "        # Ejecutar regla (simplificado)\n",
    "        try:\n",
    "            exec(rule.pandas_assertion, {\"df\": df})\n",
    "            violations = pd.Series([False] * len(df))\n",
    "        except AssertionError:\n",
    "            # Regla fall\u00f3, detectar qu\u00e9 registros violaron\n",
    "            # (implementaci\u00f3n real requiere parsear assertion)\n",
    "            violations = pd.Series([True] * len(df))\n",
    "        \n",
    "        if ground_truth_issues is None:\n",
    "            # Sin ground truth, solo reportar violations\n",
    "            return {\n",
    "                \"violations\": violations.sum(),\n",
    "                \"violation_rate\": violations.mean(),\n",
    "                \"precision\": None,\n",
    "                \"recall\": None\n",
    "            }\n",
    "        \n",
    "        # Con ground truth, calcular m\u00e9tricas\n",
    "        true_positives = (violations & ground_truth_issues).sum()\n",
    "        false_positives = (violations & ~ground_truth_issues).sum()\n",
    "        false_negatives = (~violations & ground_truth_issues).sum()\n",
    "        \n",
    "        precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n",
    "        recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0\n",
    "        \n",
    "        return {\n",
    "            \"violations\": int(violations.sum()),\n",
    "            \"violation_rate\": float(violations.mean()),\n",
    "            \"precision\": precision,\n",
    "            \"recall\": recall,\n",
    "            \"false_positive_rate\": false_positives / len(df)\n",
    "        }\n",
    "    \n",
    "    def refine_rule(\n",
    "        self,\n",
    "        rule: ValidationRule,\n",
    "        quality_metrics: Dict,\n",
    "        df: pd.DataFrame\n",
    "    ) -> ValidationRule:\n",
    "        \"\"\"Refina regla si false positive rate >5%.\"\"\"\n",
    "        \n",
    "        if quality_metrics[\"false_positive_rate\"] > 0.05:\n",
    "            print(f\"\u26a0\ufe0f  High false positive rate ({quality_metrics['false_positive_rate']:.1%}), refining rule...\")\n",
    "            \n",
    "            # LLM sugiere ajustes\n",
    "            prompt = f\"\"\"Esta regla de validaci\u00f3n tiene demasiados false positives:\n",
    "\n",
    "Regla: {rule.rule_type}\n",
    "Par\u00e1metros: {rule.parameters}\n",
    "Razonamiento: {rule.reasoning}\n",
    "\n",
    "False positive rate: {quality_metrics['false_positive_rate']:.1%}\n",
    "\n",
    "Analiza el profile actualizado y sugiere ajustes a los par\u00e1metros para reducir false positives.\n",
    "Mant\u00e9n el mismo rule_type pero ajusta thresholds, ranges, o patterns.\n",
    "\n",
    "Responde en JSON con regla refinada.\"\"\"\n",
    "            \n",
    "            # (implementaci\u00f3n LLM call omitida por brevedad)\n",
    "            \n",
    "        return rule\n",
    "```\n",
    "\n",
    "### \ud83d\udcca Comparaci\u00f3n: Manual vs Auto-Generated Rules\n",
    "\n",
    "| Aspecto | Manual | Auto-Generated (LLM) |\n",
    "|---------|--------|---------------------|\n",
    "| **Tiempo** | 2-4 horas por tabla | 5-10 minutos por tabla |\n",
    "| **Cobertura** | 60-70% de columnas | 95-100% de columnas |\n",
    "| **Calidad** | Alta (experto) | Media-Alta (requiere review) |\n",
    "| **Mantenimiento** | Manual al cambiar datos | Re-generar autom\u00e1ticamente |\n",
    "| **Costo** | $150-$300 (tiempo ingeniero) | $0.10-$1.00 (API calls) |\n",
    "| **Consistency** | Variable por ingeniero | Consistente |\n",
    "\n",
    "**ROI**: Auto-generaci\u00f3n reduce tiempo **95%** y costo **99%**, pero requiere review humano.\n",
    "\n",
    "### \ud83d\udca1 Mejores Pr\u00e1cticas\n",
    "\n",
    "1. **Siempre revisar reglas generadas**: LLM puede inferir mal, especialmente sin contexto\n",
    "2. **Proveer business context**: Mejora significativamente calidad de reglas\n",
    "3. **Ejecutar en datos hist\u00f3ricos**: Validar que reglas no tengan alta tasa de false positives\n",
    "4. **Iterar**: Refinar reglas bas\u00e1ndose en feedback de producci\u00f3n\n",
    "5. **Versionar**: Guardar reglas en Git, no re-generar cada vez\n",
    "6. **Combinar con experto**: LLM genera draft, humano refina\n",
    "7. **Monitoring**: Track false positive/negative rates en producci\u00f3n\n",
    "8. **A/B test**: Comparar LLM-generated vs manual rules en m\u00e9tricas de calidad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f3e532",
   "metadata": {},
   "source": [
    "## \ud83d\udd2c Root Cause Analysis: LLMs como Data Quality Investigators\n",
    "\n",
    "Cuando las validaciones fallan, el desaf\u00edo **real** no es detectar el problema sino **explicar POR QU\u00c9 ocurri\u00f3** y **C\u00d3MO solucionarlo**. Los LLMs act\u00faan como **investigadores expertos** que analizan patrones, correlaciones temporales, y contexto de negocio para identificar causas ra\u00edz.\n",
    "\n",
    "### \ud83d\udd75\ufe0f Arquitectura de Root Cause Analysis\n",
    "\n",
    "```\n",
    "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "\u2502         ROOT CAUSE ANALYSIS: FROM SYMPTOM TO SOLUTION            \u2502\n",
    "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
    "\u2502                                                                  \u2502\n",
    "\u2502  SYMPTOM: 500 registros con email = NULL desde 2024-10-15       \u2502\n",
    "\u2502        \u2193                                                         \u2502\n",
    "\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n",
    "\u2502  \u2502 1. TEMPORAL ANALYSIS                                     \u2502   \u2502\n",
    "\u2502  \u2502    \u00bfCu\u00e1ndo comenz\u00f3 el problema?                          \u2502   \u2502\n",
    "\u2502  \u2502                                                          \u2502   \u2502\n",
    "\u2502  \u2502    SELECT DATE(created_at), COUNT(*) as nulls            \u2502   \u2502\n",
    "\u2502  \u2502    FROM customers WHERE email IS NULL                    \u2502   \u2502\n",
    "\u2502  \u2502    GROUP BY 1 ORDER BY 1 DESC                            \u2502   \u2502\n",
    "\u2502  \u2502                                                          \u2502   \u2502\n",
    "\u2502  \u2502    Resultado:                                            \u2502   \u2502\n",
    "\u2502  \u2502    2024-10-14: 0 nulls                                   \u2502   \u2502\n",
    "\u2502  \u2502    2024-10-15: 125 nulls  \u2190 SPIKE                       \u2502   \u2502\n",
    "\u2502  \u2502    2024-10-16: 187 nulls                                 \u2502   \u2502\n",
    "\u2502  \u2502    2024-10-17: 188 nulls                                 \u2502   \u2502\n",
    "\u2502  \u2502                                                          \u2502   \u2502\n",
    "\u2502  \u2502    \ud83d\udca1 Insight: Problema comenz\u00f3 2024-10-15               \u2502   \u2502\n",
    "\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n",
    "\u2502        \u2193                                                         \u2502\n",
    "\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n",
    "\u2502  \u2502 2. CORRELATION ANALYSIS                                  \u2502   \u2502\n",
    "\u2502  \u2502    \u00bfQu\u00e9 m\u00e1s cambi\u00f3 ese d\u00eda?                              \u2502   \u2502\n",
    "\u2502  \u2502                                                          \u2502   \u2502\n",
    "\u2502  \u2502    - Git logs: Deploy de signup API v2.1 a las 14:30    \u2502   \u2502\n",
    "\u2502  \u2502    - Airflow DAG 'ingest_signups' cambi\u00f3 l\u00f3gica         \u2502   \u2502\n",
    "\u2502  \u2502    - Tr\u00e1fico aument\u00f3 30% (marketing campaign)           \u2502   \u2502\n",
    "\u2502  \u2502                                                          \u2502   \u2502\n",
    "\u2502  \u2502    \ud83d\udca1 Insight: Deploy coincide con inicio de nulls       \u2502   \u2502\n",
    "\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n",
    "\u2502        \u2193                                                         \u2502\n",
    "\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n",
    "\u2502  \u2502 3. PATTERN ANALYSIS                                      \u2502   \u2502\n",
    "\u2502  \u2502    \u00bfQu\u00e9 tienen en com\u00fan los registros afectados?        \u2502   \u2502\n",
    "\u2502  \u2502                                                          \u2502   \u2502\n",
    "\u2502  \u2502    SELECT source, COUNT(*)                               \u2502   \u2502\n",
    "\u2502  \u2502    FROM customers WHERE email IS NULL                    \u2502   \u2502\n",
    "\u2502  \u2502    AND created_at >= '2024-10-15'                        \u2502   \u2502\n",
    "\u2502  \u2502    GROUP BY 1                                            \u2502   \u2502\n",
    "\u2502  \u2502                                                          \u2502   \u2502\n",
    "\u2502  \u2502    Resultado:                                            \u2502   \u2502\n",
    "\u2502  \u2502    mobile_app: 500 nulls  \u2190 TODOS los nulls             \u2502   \u2502\n",
    "\u2502  \u2502    web: 0 nulls                                          \u2502   \u2502\n",
    "\u2502  \u2502                                                          \u2502   \u2502\n",
    "\u2502  \u2502    \ud83d\udca1 Insight: Solo afecta signups de mobile app         \u2502   \u2502\n",
    "\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n",
    "\u2502        \u2193                                                         \u2502\n",
    "\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n",
    "\u2502  \u2502 4. LLM SYNTHESIS                                         \u2502   \u2502\n",
    "\u2502  \u2502    Prompt: \"Analiza estos hallazgos y determina causa\"  \u2502   \u2502\n",
    "\u2502  \u2502                                                          \u2502   \u2502\n",
    "\u2502  \u2502    LLM \u2192 ROOT CAUSE:                                     \u2502   \u2502\n",
    "\u2502  \u2502    \"El deploy de signup API v2.1 el 2024-10-15 introdujo\u2502   \u2502\n",
    "\u2502  \u2502     un bug en el endpoint de mobile app donde el campo  \u2502   \u2502\n",
    "\u2502  \u2502     'email' dej\u00f3 de ser required en el request body.     \u2502   \u2502\n",
    "\u2502  \u2502     El backend ahora acepta signups sin email pero la   \u2502   \u2502\n",
    "\u2502  \u2502     base de datos espera NOT NULL, resultando en NULLs. \u2502   \u2502\n",
    "\u2502  \u2502                                                          \u2502   \u2502\n",
    "\u2502  \u2502     EVIDENCIA:                                           \u2502   \u2502\n",
    "\u2502  \u2502     1. Spike exacto en fecha de deploy                   \u2502   \u2502\n",
    "\u2502  \u2502     2. Solo afecta mobile app (endpoint modificado)      \u2502   \u2502\n",
    "\u2502  \u2502     3. Web no afectado (endpoint diferente sin cambios)  \u2502   \u2502\n",
    "\u2502  \u2502                                                          \u2502   \u2502\n",
    "\u2502  \u2502     SOLUCI\u00d3N RECOMENDADA:                                \u2502   \u2502\n",
    "\u2502  \u2502     1. Rollback a API v2.0 (inmediato)                   \u2502   \u2502\n",
    "\u2502  \u2502     2. Fix: Agregar validaci\u00f3n 'email required'          \u2502   \u2502\n",
    "\u2502  \u2502     3. Backfill: Contactar 500 usuarios para emails     \u2502   \u2502\n",
    "\u2502  \u2502     4. Prevention: Agregar test e2e para campo required\"\u2502   \u2502\n",
    "\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n",
    "\u2502        \u2193                                                         \u2502\n",
    "\u2502  SOLUTION: Rollback + Fix + Backfill + Prevention                \u2502\n",
    "\u2502                                                                  \u2502\n",
    "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "```\n",
    "\n",
    "### \ud83d\udd27 Implementaci\u00f3n Completa\n",
    "\n",
    "```python\n",
    "from typing import List, Dict, Optional\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel\n",
    "import json\n",
    "\n",
    "client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))\n",
    "\n",
    "# 1. MODELOS DE DATOS\n",
    "\n",
    "class TemporalAnomaly(BaseModel):\n",
    "    \"\"\"Anomal\u00eda detectada con an\u00e1lisis temporal.\"\"\"\n",
    "    issue_type: str\n",
    "    affected_records: int\n",
    "    first_occurrence: datetime\n",
    "    spike_date: Optional[datetime] = None\n",
    "    trend: str  # \"increasing\", \"decreasing\", \"stable\", \"spike\"\n",
    "    time_series: List[Dict[str, any]]  # [{date, count}]\n",
    "\n",
    "class CorrelatedEvent(BaseModel):\n",
    "    \"\"\"Evento que coincide temporalmente con anomal\u00eda.\"\"\"\n",
    "    event_type: str  # \"deployment\", \"schema_change\", \"traffic_spike\", etc.\n",
    "    timestamp: datetime\n",
    "    description: str\n",
    "    confidence: float  # Qu\u00e9 tan probable es que sea la causa\n",
    "\n",
    "class PatternInsight(BaseModel):\n",
    "    \"\"\"Insight sobre patr\u00f3n en datos afectados.\"\"\"\n",
    "    dimension: str  # Columna analizada (source, region, user_type, etc.)\n",
    "    pattern: str  # Descripci\u00f3n del patr\u00f3n\n",
    "    affected_segments: Dict[str, int]  # {valor: count}\n",
    "    is_significant: bool\n",
    "\n",
    "class RootCauseHypothesis(BaseModel):\n",
    "    \"\"\"Hip\u00f3tesis de causa ra\u00edz.\"\"\"\n",
    "    rank: int\n",
    "    confidence: float\n",
    "    root_cause: str\n",
    "    evidence: List[str]\n",
    "    recommended_fix: str\n",
    "    prevention_steps: List[str]\n",
    "\n",
    "class RootCauseReport(BaseModel):\n",
    "    \"\"\"Reporte completo de investigaci\u00f3n.\"\"\"\n",
    "    issue_description: str\n",
    "    temporal_analysis: TemporalAnomaly\n",
    "    correlated_events: List[CorrelatedEvent]\n",
    "    pattern_insights: List[PatternInsight]\n",
    "    hypotheses: List[RootCauseHypothesis]\n",
    "    recommended_action: str\n",
    "    estimated_impact: str\n",
    "\n",
    "# 2. ROOT CAUSE ANALYZER\n",
    "\n",
    "class RootCauseAnalyzer:\n",
    "    \"\"\"Investigador autom\u00e1tico de causas ra\u00edz.\"\"\"\n",
    "    \n",
    "    def __init__(self, model: str = \"gpt-4o\"):\n",
    "        self.model = model\n",
    "    \n",
    "    def analyze_temporal_pattern(\n",
    "        self,\n",
    "        df: pd.DataFrame,\n",
    "        issue_column: str,\n",
    "        issue_condition: str,\n",
    "        date_column: str = 'created_at'\n",
    "    ) -> TemporalAnomaly:\n",
    "        \"\"\"\n",
    "        Analiza patr\u00f3n temporal del issue.\n",
    "        \n",
    "        Args:\n",
    "            df: DataFrame completo\n",
    "            issue_column: columna con el issue\n",
    "            issue_condition: condici\u00f3n para detectar issue (ej. \"email IS NULL\")\n",
    "            date_column: columna de fecha\n",
    "        \"\"\"\n",
    "        # Filtrar registros con issue\n",
    "        issue_mask = eval(f\"df['{issue_column}'].{issue_condition}\")\n",
    "        affected_df = df[issue_mask].copy()\n",
    "        \n",
    "        # Time series de issues por d\u00eda\n",
    "        affected_df['date'] = pd.to_datetime(affected_df[date_column]).dt.date\n",
    "        daily_counts = affected_df.groupby('date').size().reset_index(name='count')\n",
    "        \n",
    "        # Detectar spike\n",
    "        if len(daily_counts) > 1:\n",
    "            mean_count = daily_counts['count'].mean()\n",
    "            std_count = daily_counts['count'].std()\n",
    "            spike_threshold = mean_count + (2 * std_count)\n",
    "            \n",
    "            spikes = daily_counts[daily_counts['count'] > spike_threshold]\n",
    "            spike_date = spikes.iloc[0]['date'] if len(spikes) > 0 else None\n",
    "        else:\n",
    "            spike_date = None\n",
    "        \n",
    "        # Determinar trend\n",
    "        if len(daily_counts) >= 3:\n",
    "            recent_trend = daily_counts['count'].tail(3).diff().mean()\n",
    "            if recent_trend > daily_counts['count'].std():\n",
    "                trend = \"increasing\"\n",
    "            elif recent_trend < -daily_counts['count'].std():\n",
    "                trend = \"decreasing\"\n",
    "            else:\n",
    "                trend = \"stable\"\n",
    "        else:\n",
    "            trend = \"spike\" if spike_date else \"stable\"\n",
    "        \n",
    "        return TemporalAnomaly(\n",
    "            issue_type=issue_condition,\n",
    "            affected_records=len(affected_df),\n",
    "            first_occurrence=datetime.combine(daily_counts.iloc[0]['date'], datetime.min.time()),\n",
    "            spike_date=datetime.combine(spike_date, datetime.min.time()) if spike_date else None,\n",
    "            trend=trend,\n",
    "            time_series=[\n",
    "                {\"date\": str(row['date']), \"count\": int(row['count'])}\n",
    "                for _, row in daily_counts.iterrows()\n",
    "            ]\n",
    "        )\n",
    "    \n",
    "    def find_correlated_events(\n",
    "        self,\n",
    "        anomaly: TemporalAnomaly,\n",
    "        event_log: List[Dict]\n",
    "    ) -> List[CorrelatedEvent]:\n",
    "        \"\"\"\n",
    "        Encuentra eventos que coinciden temporalmente con anomal\u00eda.\n",
    "        \n",
    "        Args:\n",
    "            anomaly: an\u00e1lisis temporal\n",
    "            event_log: lista de eventos [{type, timestamp, description}]\n",
    "        \"\"\"\n",
    "        reference_date = anomaly.spike_date or anomaly.first_occurrence\n",
    "        window_hours = 24  # Ventana de +/- 24 horas\n",
    "        \n",
    "        correlated = []\n",
    "        \n",
    "        for event in event_log:\n",
    "            event_time = datetime.fromisoformat(event['timestamp'])\n",
    "            time_diff = abs((event_time - reference_date).total_seconds() / 3600)\n",
    "            \n",
    "            if time_diff <= window_hours:\n",
    "                # Calcular confidence basado en proximidad temporal\n",
    "                confidence = 1.0 - (time_diff / window_hours)\n",
    "                \n",
    "                correlated.append(CorrelatedEvent(\n",
    "                    event_type=event['type'],\n",
    "                    timestamp=event_time,\n",
    "                    description=event['description'],\n",
    "                    confidence=confidence\n",
    "                ))\n",
    "        \n",
    "        # Ordenar por confidence\n",
    "        return sorted(correlated, key=lambda x: x.confidence, reverse=True)\n",
    "    \n",
    "    def analyze_patterns(\n",
    "        self,\n",
    "        df: pd.DataFrame,\n",
    "        issue_column: str,\n",
    "        issue_condition: str,\n",
    "        dimensions: List[str]\n",
    "    ) -> List[PatternInsight]:\n",
    "        \"\"\"\n",
    "        Analiza patrones en m\u00faltiples dimensiones.\n",
    "        \n",
    "        Args:\n",
    "            df: DataFrame completo\n",
    "            issue_column: columna con issue\n",
    "            issue_condition: condici\u00f3n de issue\n",
    "            dimensions: columnas a analizar (source, region, etc.)\n",
    "        \"\"\"\n",
    "        issue_mask = eval(f\"df['{issue_column}'].{issue_condition}\")\n",
    "        affected_df = df[issue_mask]\n",
    "        \n",
    "        insights = []\n",
    "        \n",
    "        for dim in dimensions:\n",
    "            if dim not in df.columns:\n",
    "                continue\n",
    "            \n",
    "            # Distribuci\u00f3n en datos afectados\n",
    "            affected_dist = affected_df[dim].value_counts().to_dict()\n",
    "            \n",
    "            # Distribuci\u00f3n en datos totales\n",
    "            total_dist = df[dim].value_counts().to_dict()\n",
    "            \n",
    "            # Detectar si alg\u00fan segmento est\u00e1 sobre-representado\n",
    "            total_records = len(df)\n",
    "            significant_segments = {}\n",
    "            \n",
    "            for value, count in affected_dist.items():\n",
    "                expected_ratio = total_dist.get(value, 0) / total_records\n",
    "                actual_ratio = count / len(affected_df)\n",
    "                \n",
    "                # Si ratio es >2x esperado, es significativo\n",
    "                if actual_ratio > expected_ratio * 2:\n",
    "                    significant_segments[str(value)] = count\n",
    "            \n",
    "            is_significant = len(significant_segments) > 0\n",
    "            \n",
    "            if is_significant:\n",
    "                pattern = f\"Segmento(s) sobre-representado(s): {', '.join(significant_segments.keys())}\"\n",
    "            else:\n",
    "                pattern = \"Distribuci\u00f3n uniforme entre segmentos\"\n",
    "            \n",
    "            insights.append(PatternInsight(\n",
    "                dimension=dim,\n",
    "                pattern=pattern,\n",
    "                affected_segments={str(k): int(v) for k, v in affected_dist.items()},\n",
    "                is_significant=is_significant\n",
    "            ))\n",
    "        \n",
    "        return insights\n",
    "    \n",
    "    def generate_hypotheses(\n",
    "        self,\n",
    "        issue_description: str,\n",
    "        temporal: TemporalAnomaly,\n",
    "        events: List[CorrelatedEvent],\n",
    "        patterns: List[PatternInsight]\n",
    "    ) -> List[RootCauseHypothesis]:\n",
    "        \"\"\"\n",
    "        Usa LLM para generar hip\u00f3tesis de causa ra\u00edz.\n",
    "        \"\"\"\n",
    "        prompt = f\"\"\"Act\u00faa como un Data Quality Investigator experto. Analiza estos hallazgos y genera hip\u00f3tesis de causa ra\u00edz:\n",
    "\n",
    "PROBLEMA:\n",
    "{issue_description}\n",
    "\n",
    "AN\u00c1LISIS TEMPORAL:\n",
    "- Registros afectados: {temporal.affected_records}\n",
    "- Primera ocurrencia: {temporal.first_occurrence}\n",
    "- Spike detectado: {temporal.spike_date or \"No\"}\n",
    "- Tendencia: {temporal.trend}\n",
    "- Serie temporal: {json.dumps(temporal.time_series[:7], indent=2)}\n",
    "\n",
    "EVENTOS CORRELACIONADOS:\n",
    "{chr(10).join([f\"- [{e.event_type}] {e.timestamp}: {e.description} (confidence: {e.confidence:.0%})\" for e in events[:5]])}\n",
    "\n",
    "PATRONES IDENTIFICADOS:\n",
    "{chr(10).join([f\"- {p.dimension}: {p.pattern}\" + (f\" (SIGNIFICATIVO)\" if p.is_significant else \"\") for p in patterns])}\n",
    "\n",
    "Genera 2-3 hip\u00f3tesis de causa ra\u00edz, ordenadas por probabilidad. Para cada hip\u00f3tesis:\n",
    "1. Explicaci\u00f3n de la causa ra\u00edz\n",
    "2. Evidencia que la soporta\n",
    "3. Fix recomendado\n",
    "4. Pasos de prevenci\u00f3n\n",
    "\n",
    "Responde en JSON:\n",
    "{{\n",
    "  \"hypotheses\": [\n",
    "    {{\n",
    "      \"confidence\": 0.0-1.0,\n",
    "      \"root_cause\": \"explicaci\u00f3n concisa\",\n",
    "      \"evidence\": [\"evidencia 1\", \"evidencia 2\", ...],\n",
    "      \"recommended_fix\": \"acci\u00f3n inmediata\",\n",
    "      \"prevention_steps\": [\"paso 1\", \"paso 2\", ...]\n",
    "    }}\n",
    "  ],\n",
    "  \"recommended_action\": \"qu\u00e9 hacer AHORA\",\n",
    "  \"estimated_impact\": \"cu\u00e1ntos usuarios/registros/$ afectados\"\n",
    "}}\"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=self.model,\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                temperature=0.3,\n",
    "                response_format={\"type\": \"json_object\"}\n",
    "            )\n",
    "            \n",
    "            result = json.loads(response.choices[0].message.content)\n",
    "            \n",
    "            hypotheses = []\n",
    "            for i, hyp_data in enumerate(result.get(\"hypotheses\", []), 1):\n",
    "                hypotheses.append(RootCauseHypothesis(\n",
    "                    rank=i,\n",
    "                    confidence=hyp_data[\"confidence\"],\n",
    "                    root_cause=hyp_data[\"root_cause\"],\n",
    "                    evidence=hyp_data[\"evidence\"],\n",
    "                    recommended_fix=hyp_data[\"recommended_fix\"],\n",
    "                    prevention_steps=hyp_data[\"prevention_steps\"]\n",
    "                ))\n",
    "            \n",
    "            return hypotheses, result[\"recommended_action\"], result[\"estimated_impact\"]\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error generando hip\u00f3tesis: {e}\")\n",
    "            return [], \"Manual investigation required\", \"Unknown\"\n",
    "    \n",
    "    def investigate(\n",
    "        self,\n",
    "        df: pd.DataFrame,\n",
    "        issue_description: str,\n",
    "        issue_column: str,\n",
    "        issue_condition: str,\n",
    "        event_log: List[Dict],\n",
    "        dimensions_to_analyze: List[str],\n",
    "        date_column: str = 'created_at'\n",
    "    ) -> RootCauseReport:\n",
    "        \"\"\"\n",
    "        Investigaci\u00f3n completa de root cause.\n",
    "        \n",
    "        Args:\n",
    "            df: DataFrame con datos\n",
    "            issue_description: descripci\u00f3n del problema\n",
    "            issue_column: columna con issue\n",
    "            issue_condition: condici\u00f3n que define el issue\n",
    "            event_log: log de eventos (deployments, schema changes, etc.)\n",
    "            dimensions_to_analyze: columnas para pattern analysis\n",
    "            date_column: columna de timestamp\n",
    "        \n",
    "        Returns:\n",
    "            Reporte completo de investigaci\u00f3n\n",
    "        \"\"\"\n",
    "        print(\"\ud83d\udd0d Iniciando investigaci\u00f3n de root cause...\")\n",
    "        \n",
    "        # 1. An\u00e1lisis temporal\n",
    "        print(\"  1\ufe0f\u20e3 Analizando patr\u00f3n temporal...\")\n",
    "        temporal = self.analyze_temporal_pattern(df, issue_column, issue_condition, date_column)\n",
    "        print(f\"     \u2713 {temporal.affected_records} registros afectados, tendencia: {temporal.trend}\")\n",
    "        \n",
    "        # 2. Eventos correlacionados\n",
    "        print(\"  2\ufe0f\u20e3 Buscando eventos correlacionados...\")\n",
    "        events = self.find_correlated_events(temporal, event_log)\n",
    "        print(f\"     \u2713 {len(events)} eventos encontrados\")\n",
    "        \n",
    "        # 3. Patrones\n",
    "        print(\"  3\ufe0f\u20e3 Analizando patrones en dimensiones...\")\n",
    "        patterns = self.analyze_patterns(df, issue_column, issue_condition, dimensions_to_analyze)\n",
    "        significant_patterns = [p for p in patterns if p.is_significant]\n",
    "        print(f\"     \u2713 {len(significant_patterns)}/{len(patterns)} patrones significativos\")\n",
    "        \n",
    "        # 4. Generar hip\u00f3tesis con LLM\n",
    "        print(\"  4\ufe0f\u20e3 Generando hip\u00f3tesis de causa ra\u00edz...\")\n",
    "        hypotheses, recommended_action, estimated_impact = self.generate_hypotheses(\n",
    "            issue_description, temporal, events, patterns\n",
    "        )\n",
    "        print(f\"     \u2713 {len(hypotheses)} hip\u00f3tesis generadas\")\n",
    "        \n",
    "        return RootCauseReport(\n",
    "            issue_description=issue_description,\n",
    "            temporal_analysis=temporal,\n",
    "            correlated_events=events,\n",
    "            pattern_insights=patterns,\n",
    "            hypotheses=hypotheses,\n",
    "            recommended_action=recommended_action,\n",
    "            estimated_impact=estimated_impact\n",
    "        )\n",
    "\n",
    "# EJEMPLO DE USO\n",
    "\n",
    "# Dataset simulado\n",
    "np.random.seed(42)\n",
    "\n",
    "dates = pd.date_range('2024-10-01', '2024-10-20', freq='H')\n",
    "n_records = len(dates)\n",
    "\n",
    "# Simular spike de NULLs desde 2024-10-15 solo en mobile_app\n",
    "df_signups = pd.DataFrame({\n",
    "    'user_id': range(n_records),\n",
    "    'created_at': dates,\n",
    "    'email': ['user{}@example.com'.format(i) for i in range(n_records)],\n",
    "    'source': np.random.choice(['web', 'mobile_app'], size=n_records, p=[0.6, 0.4]),\n",
    "    'region': np.random.choice(['US', 'EU', 'ASIA'], size=n_records)\n",
    "})\n",
    "\n",
    "# Introducir NULLs despu\u00e9s de 2024-10-15 solo en mobile_app\n",
    "spike_start = pd.Timestamp('2024-10-15')\n",
    "mobile_mask = df_signups['source'] == 'mobile_app'\n",
    "after_spike = df_signups['created_at'] >= spike_start\n",
    "\n",
    "df_signups.loc[mobile_mask & after_spike, 'email'] = None\n",
    "\n",
    "# Event log simulado\n",
    "event_log = [\n",
    "    {\n",
    "        'type': 'deployment',\n",
    "        'timestamp': '2024-10-15T14:30:00',\n",
    "        'description': 'Deployed signup API v2.1 with mobile app endpoint changes'\n",
    "    },\n",
    "    {\n",
    "        'type': 'schema_change',\n",
    "        'timestamp': '2024-10-12T10:00:00',\n",
    "        'description': 'Added index on users.email for performance'\n",
    "    },\n",
    "    {\n",
    "        'type': 'traffic_spike',\n",
    "        'timestamp': '2024-10-15T08:00:00',\n",
    "        'description': 'Marketing campaign launch, traffic +30%'\n",
    "    }\n",
    "]\n",
    "\n",
    "# Investigar\n",
    "analyzer = RootCauseAnalyzer()\n",
    "\n",
    "report = analyzer.investigate(\n",
    "    df=df_signups,\n",
    "    issue_description=\"500+ signups con email NULL desde 2024-10-15\",\n",
    "    issue_column='email',\n",
    "    issue_condition='isnull()',\n",
    "    event_log=event_log,\n",
    "    dimensions_to_analyze=['source', 'region'],\n",
    "    date_column='created_at'\n",
    ")\n",
    "\n",
    "# Mostrar reporte\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"\ud83d\udccb ROOT CAUSE ANALYSIS REPORT\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\n\ud83d\udd34 PROBLEMA: {report.issue_description}\")\n",
    "print(f\"\\n\ud83d\udcca AN\u00c1LISIS TEMPORAL:\")\n",
    "print(f\"   Afectados: {report.temporal_analysis.affected_records}\")\n",
    "print(f\"   Primera ocurrencia: {report.temporal_analysis.first_occurrence}\")\n",
    "print(f\"   Spike detectado: {report.temporal_analysis.spike_date}\")\n",
    "print(f\"   Tendencia: {report.temporal_analysis.trend}\")\n",
    "\n",
    "print(f\"\\n\ud83d\udd17 EVENTOS CORRELACIONADOS (top 3):\")\n",
    "for event in report.correlated_events[:3]:\n",
    "    print(f\"   [{event.confidence:.0%}] {event.event_type}: {event.description}\")\n",
    "\n",
    "print(f\"\\n\ud83d\udd0d PATRONES SIGNIFICATIVOS:\")\n",
    "for pattern in report.pattern_insights:\n",
    "    if pattern.is_significant:\n",
    "        print(f\"   {pattern.dimension}: {pattern.pattern}\")\n",
    "        print(f\"      Segmentos afectados: {pattern.affected_segments}\")\n",
    "\n",
    "print(f\"\\n\ud83d\udca1 HIP\u00d3TESIS DE CAUSA RA\u00cdZ:\")\n",
    "for hyp in report.hypotheses:\n",
    "    print(f\"\\n   {hyp.rank}. [{hyp.confidence:.0%}] {hyp.root_cause}\")\n",
    "    print(f\"      Evidencia:\")\n",
    "    for evidence in hyp.evidence:\n",
    "        print(f\"        - {evidence}\")\n",
    "    print(f\"      Fix recomendado: {hyp.recommended_fix}\")\n",
    "    print(f\"      Prevenci\u00f3n:\")\n",
    "    for step in hyp.prevention_steps:\n",
    "        print(f\"        - {step}\")\n",
    "\n",
    "print(f\"\\n\ud83d\ude80 ACCI\u00d3N RECOMENDADA:\")\n",
    "print(f\"   {report.recommended_action}\")\n",
    "\n",
    "print(f\"\\n\ud83d\udcc8 IMPACTO ESTIMADO:\")\n",
    "print(f\"   {report.estimated_impact}\")\n",
    "```\n",
    "\n",
    "### \ud83d\udcca M\u00e9tricas de \u00c9xito en Root Cause Analysis\n",
    "\n",
    "```python\n",
    "class RCAMetrics:\n",
    "    \"\"\"M\u00e9tricas para evaluar calidad de RCA.\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def measure_time_to_root_cause(\n",
    "        issue_detected_at: datetime,\n",
    "        root_cause_identified_at: datetime\n",
    "    ) -> float:\n",
    "        \"\"\"Tiempo desde detecci\u00f3n hasta identificaci\u00f3n de causa.\"\"\"\n",
    "        return (root_cause_identified_at - issue_detected_at).total_seconds() / 3600  # horas\n",
    "    \n",
    "    @staticmethod\n",
    "    def measure_hypothesis_accuracy(\n",
    "        predicted_cause: str,\n",
    "        actual_cause: str,\n",
    "        llm_model: str = \"gpt-4o\"\n",
    "    ) -> float:\n",
    "        \"\"\"\n",
    "        Eval\u00faa similitud sem\u00e1ntica entre causa predicha y real.\n",
    "        Retorna score 0.0-1.0.\n",
    "        \"\"\"\n",
    "        # Usar embeddings para similitud sem\u00e1ntica\n",
    "        from openai import OpenAI\n",
    "        client = OpenAI()\n",
    "        \n",
    "        response = client.embeddings.create(\n",
    "            model=\"text-embedding-3-small\",\n",
    "            input=[predicted_cause, actual_cause]\n",
    "        )\n",
    "        \n",
    "        emb1 = np.array(response.data[0].embedding)\n",
    "        emb2 = np.array(response.data[1].embedding)\n",
    "        \n",
    "        # Cosine similarity\n",
    "        similarity = np.dot(emb1, emb2) / (np.linalg.norm(emb1) * np.linalg.norm(emb2))\n",
    "        \n",
    "        return float(similarity)\n",
    "\n",
    "# Ejemplo de medici\u00f3n\n",
    "metrics = RCAMetrics()\n",
    "\n",
    "# Manual investigation: 4 horas\n",
    "manual_time = 4.0\n",
    "\n",
    "# LLM-powered: 15 minutos\n",
    "llm_time = 0.25\n",
    "\n",
    "print(f\"\u26a1 Speedup: {manual_time / llm_time:.0f}x m\u00e1s r\u00e1pido\")\n",
    "print(f\"\ud83d\udcb0 Ahorro: ${manual_time * 75:.0f} (@ $75/hora ingeniero) vs ${0.50:.2f} (API calls)\")\n",
    "```\n",
    "\n",
    "### \ud83d\udca1 Mejores Pr\u00e1cticas\n",
    "\n",
    "1. **Siempre investigar**: No asumir causa, seguir proceso sistem\u00e1tico\n",
    "2. **M\u00faltiples hip\u00f3tesis**: LLM debe generar 2-3 opciones, no solo una\n",
    "3. **Evidencia cuantitativa**: Basar hip\u00f3tesis en datos, no suposiciones\n",
    "4. **Timeline cr\u00edtico**: Marcar eventos importantes (deploys, schema changes)\n",
    "5. **Documentar**: Guardar investigaciones para aprendizaje futuro\n",
    "6. **Validar hip\u00f3tesis**: Confirmar causa ra\u00edz antes de aplicar fix masivo\n",
    "7. **Post-mortem autom\u00e1tico**: Generar documento de incident con LLM\n",
    "8. **Learn from patterns**: Entrenar modelo en investigaciones previas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f0264d",
   "metadata": {},
   "source": [
    "## \ud83c\udfed LLM-Powered Data Quality en Producci\u00f3n\n",
    "\n",
    "Implementar LLMs para Data Quality en producci\u00f3n requiere arquitectura robusta, monitoring exhaustivo, y estrategias para controlar costos y latencia. Aqu\u00ed exploramos patrones de producci\u00f3n reales.\n",
    "\n",
    "### \ud83c\udfd7\ufe0f Arquitectura de Data Quality Platform con LLMs\n",
    "\n",
    "```\n",
    "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
    "\u2502         DATA QUALITY PLATFORM: HYBRID ARCHITECTURE               \u2502\n",
    "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
    "\u2502                                                                  \u2502\n",
    "\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n",
    "\u2502  \u2502 INGESTION LAYER                                          \u2502   \u2502\n",
    "\u2502  \u2502  \u2022 Kafka / Kinesis streams                               \u2502   \u2502\n",
    "\u2502  \u2502  \u2022 Airflow DAGs                                          \u2502   \u2502\n",
    "\u2502  \u2502  \u2022 dbt models                                            \u2502   \u2502\n",
    "\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n",
    "\u2502                   \u2193                                              \u2502\n",
    "\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n",
    "\u2502  \u2502 VALIDATION LAYER (Multi-Stage)                           \u2502   \u2502\n",
    "\u2502  \u2502                                                          \u2502   \u2502\n",
    "\u2502  \u2502  Stage 1: TRADITIONAL (100% traffic, <10ms)             \u2502   \u2502\n",
    "\u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u2502   \u2502\n",
    "\u2502  \u2502  \u2502 \u2022 NULL checks (Pandas)                         \u2502     \u2502   \u2502\n",
    "\u2502  \u2502  \u2502 \u2022 Range validation (SQL)                       \u2502     \u2502   \u2502\n",
    "\u2502  \u2502  \u2502 \u2022 Regex patterns (Python re)                   \u2502     \u2502   \u2502\n",
    "\u2502  \u2502  \u2502 \u2022 Referential integrity (JOIN queries)         \u2502     \u2502   \u2502\n",
    "\u2502  \u2502  \u2502                                                \u2502     \u2502   \u2502\n",
    "\u2502  \u2502  \u2502 \u2705 Pass \u2192 Continue                             \u2502     \u2502   \u2502\n",
    "\u2502  \u2502  \u2502 \u274c Fail \u2192 Block + Alert                        \u2502     \u2502   \u2502\n",
    "\u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2502   \u2502\n",
    "\u2502  \u2502                   \u2193                                      \u2502   \u2502\n",
    "\u2502  \u2502  Stage 2: LLM SEMANTIC (1% sample, ~500ms)              \u2502   \u2502\n",
    "\u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u2502   \u2502\n",
    "\u2502  \u2502  \u2502 \u2022 Semantic NULL detection                      \u2502     \u2502   \u2502\n",
    "\u2502  \u2502  \u2502 \u2022 Plausibility checks                          \u2502     \u2502   \u2502\n",
    "\u2502  \u2502  \u2502 \u2022 PII detection                                \u2502     \u2502   \u2502\n",
    "\u2502  \u2502  \u2502 \u2022 Anomaly explanation                          \u2502     \u2502   \u2502\n",
    "\u2502  \u2502  \u2502                                                \u2502     \u2502   \u2502\n",
    "\u2502  \u2502  \u2502 Cache Layer (Redis):                           \u2502     \u2502   \u2502\n",
    "\u2502  \u2502  \u2502  key: hash(value + context)                    \u2502     \u2502   \u2502\n",
    "\u2502  \u2502  \u2502  value: {is_valid, confidence, reasoning}      \u2502     \u2502   \u2502\n",
    "\u2502  \u2502  \u2502  TTL: 7 days                                   \u2502     \u2502   \u2502\n",
    "\u2502  \u2502  \u2502                                                \u2502     \u2502   \u2502\n",
    "\u2502  \u2502  \u2502 \u26a0\ufe0f  Issues \u2192 Queue for investigation           \u2502     \u2502   \u2502\n",
    "\u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2502   \u2502\n",
    "\u2502  \u2502                   \u2193                                      \u2502   \u2502\n",
    "\u2502  \u2502  Stage 3: ROOT CAUSE ANALYSIS (on failures)             \u2502   \u2502\n",
    "\u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u2502   \u2502\n",
    "\u2502  \u2502  \u2502 \u2022 Triggered solo si >threshold failures        \u2502     \u2502   \u2502\n",
    "\u2502  \u2502  \u2502 \u2022 Analiza temporal patterns                    \u2502     \u2502   \u2502\n",
    "\u2502  \u2502  \u2502 \u2022 Correlaciona con eventos (deploys, etc.)     \u2502     \u2502   \u2502\n",
    "\u2502  \u2502  \u2502 \u2022 Genera hip\u00f3tesis con LLM                     \u2502     \u2502   \u2502\n",
    "\u2502  \u2502  \u2502 \u2022 Crea ticket autom\u00e1tico (Jira)               \u2502     \u2502   \u2502\n",
    "\u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2502   \u2502\n",
    "\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n",
    "\u2502                   \u2193                                              \u2502\n",
    "\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n",
    "\u2502  \u2502 MONITORING & ALERTING                                    \u2502   \u2502\n",
    "\u2502  \u2502  \u2022 Prometheus metrics                                    \u2502   \u2502\n",
    "\u2502  \u2502  \u2022 Grafana dashboards                                    \u2502   \u2502\n",
    "\u2502  \u2502  \u2022 PagerDuty/Slack alerts                                \u2502   \u2502\n",
    "\u2502  \u2502  \u2022 Cost tracking (LLM API usage)                         \u2502   \u2502\n",
    "\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n",
    "\u2502                   \u2193                                              \u2502\n",
    "\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n",
    "\u2502  \u2502 DATA STORAGE                                             \u2502   \u2502\n",
    "\u2502  \u2502  \u2022 Validated data \u2192 Data Warehouse (Snowflake)           \u2502   \u2502\n",
    "\u2502  \u2502  \u2022 Validation logs \u2192 S3 \u2192 Athena queries                 \u2502   \u2502\n",
    "\u2502  \u2502  \u2022 Failed records \u2192 Dead Letter Queue (DLQ)              \u2502   \u2502\n",
    "\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n",
    "\u2502                                                                  \u2502\n",
    "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
    "```\n",
    "\n",
    "### \ud83d\udd27 Implementaci\u00f3n: Production-Grade System\n",
    "\n",
    "```python\n",
    "from typing import Dict, List, Optional\n",
    "import asyncio\n",
    "import redis\n",
    "import hashlib\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "from dataclasses import dataclass\n",
    "import logging\n",
    "from prometheus_client import Counter, Histogram, Gauge\n",
    "from openai import AsyncOpenAI\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Prometheus metrics\n",
    "VALIDATIONS_TOTAL = Counter('dq_validations_total', 'Total validations', ['stage', 'result'])\n",
    "VALIDATION_DURATION = Histogram('dq_validation_duration_seconds', 'Validation duration', ['stage'])\n",
    "LLM_API_COST = Gauge('dq_llm_api_cost_usd', 'LLM API cost')\n",
    "CACHE_HIT_RATE = Gauge('dq_cache_hit_rate', 'Cache hit rate')\n",
    "\n",
    "# 1. CACHE LAYER\n",
    "\n",
    "class ValidationCache:\n",
    "    \"\"\"Redis-backed cache para validaciones LLM.\"\"\"\n",
    "    \n",
    "    def __init__(self, redis_url: str = \"redis://localhost:6379\"):\n",
    "        self.redis_client = redis.from_url(redis_url, decode_responses=True)\n",
    "        self.ttl_seconds = 7 * 24 * 3600  # 7 d\u00edas\n",
    "        self.hits = 0\n",
    "        self.misses = 0\n",
    "    \n",
    "    def _get_cache_key(self, value: str, context: str, validation_type: str) -> str:\n",
    "        \"\"\"Genera cache key determin\u00edstico.\"\"\"\n",
    "        content = f\"{validation_type}:{context}:{value}\"\n",
    "        return f\"dq:validation:{hashlib.sha256(content.encode()).hexdigest()}\"\n",
    "    \n",
    "    def get(self, value: str, context: str, validation_type: str) -> Optional[Dict]:\n",
    "        \"\"\"Obtiene resultado cacheado.\"\"\"\n",
    "        key = self._get_cache_key(value, context, validation_type)\n",
    "        \n",
    "        cached = self.redis_client.get(key)\n",
    "        \n",
    "        if cached:\n",
    "            self.hits += 1\n",
    "            CACHE_HIT_RATE.set(self.hits / (self.hits + self.misses))\n",
    "            return json.loads(cached)\n",
    "        else:\n",
    "            self.misses += 1\n",
    "            CACHE_HIT_RATE.set(self.hits / (self.hits + self.misses))\n",
    "            return None\n",
    "    \n",
    "    def set(self, value: str, context: str, validation_type: str, result: Dict):\n",
    "        \"\"\"Cachea resultado.\"\"\"\n",
    "        key = self._get_cache_key(value, context, validation_type)\n",
    "        self.redis_client.setex(key, self.ttl_seconds, json.dumps(result))\n",
    "\n",
    "# 2. VALIDATION ORCHESTRATOR\n",
    "\n",
    "@dataclass\n",
    "class ValidationConfig:\n",
    "    \"\"\"Configuraci\u00f3n de validaci\u00f3n.\"\"\"\n",
    "    traditional_enabled: bool = True\n",
    "    llm_enabled: bool = True\n",
    "    llm_sample_rate: float = 0.01  # 1% de tr\u00e1fico\n",
    "    llm_max_concurrent: int = 10\n",
    "    llm_timeout_seconds: int = 5\n",
    "    cost_budget_daily_usd: float = 10.0\n",
    "    failure_threshold_for_rca: int = 100  # Trigger RCA si >100 failures\n",
    "\n",
    "class ProductionValidator:\n",
    "    \"\"\"Validador de producci\u00f3n con stages.\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        config: ValidationConfig,\n",
    "        cache: ValidationCache,\n",
    "        llm_client: AsyncOpenAI\n",
    "    ):\n",
    "        self.config = config\n",
    "        self.cache = cache\n",
    "        self.llm_client = llm_client\n",
    "        self.daily_cost = 0.0\n",
    "        self.last_cost_reset = datetime.now()\n",
    "    \n",
    "    def _should_use_llm(self) -> bool:\n",
    "        \"\"\"Decide si usar LLM basado en sampling y budget.\"\"\"\n",
    "        # Reset daily cost\n",
    "        if datetime.now() - self.last_cost_reset > timedelta(days=1):\n",
    "            self.daily_cost = 0.0\n",
    "            self.last_cost_reset = datetime.now()\n",
    "        \n",
    "        # Check budget\n",
    "        if self.daily_cost >= self.config.cost_budget_daily_usd:\n",
    "            logger.warning(f\"Daily LLM budget exhausted: ${self.daily_cost:.2f}\")\n",
    "            return False\n",
    "        \n",
    "        # Sample rate\n",
    "        import random\n",
    "        return random.random() < self.config.llm_sample_rate\n",
    "    \n",
    "    async def validate_record(\n",
    "        self,\n",
    "        record: Dict,\n",
    "        validation_rules: Dict[str, Dict]\n",
    "    ) -> Dict:\n",
    "        \"\"\"\n",
    "        Valida un registro completo.\n",
    "        \n",
    "        Args:\n",
    "            record: diccionario con datos del registro\n",
    "            validation_rules: reglas por columna\n",
    "                {\n",
    "                    \"column_name\": {\n",
    "                        \"traditional\": {...},\n",
    "                        \"llm\": {\"enabled\": bool, \"context\": str}\n",
    "                    }\n",
    "                }\n",
    "        \n",
    "        Returns:\n",
    "            {\n",
    "                \"valid\": bool,\n",
    "                \"issues\": List[Dict],\n",
    "                \"stages_executed\": List[str],\n",
    "                \"duration_ms\": float,\n",
    "                \"cost_usd\": float\n",
    "            }\n",
    "        \"\"\"\n",
    "        start_time = datetime.now()\n",
    "        issues = []\n",
    "        stages_executed = []\n",
    "        total_cost = 0.0\n",
    "        \n",
    "        # STAGE 1: TRADITIONAL (ALWAYS)\n",
    "        if self.config.traditional_enabled:\n",
    "            with VALIDATION_DURATION.labels(stage='traditional').time():\n",
    "                trad_issues = await self._validate_traditional(record, validation_rules)\n",
    "                issues.extend(trad_issues)\n",
    "                stages_executed.append('traditional')\n",
    "                VALIDATIONS_TOTAL.labels(stage='traditional', result='pass' if len(trad_issues)==0 else 'fail').inc()\n",
    "        \n",
    "        # Si traditional falla cr\u00edticamente, no continuar\n",
    "        critical_issues = [i for i in issues if i.get('severity') == 'CRITICAL']\n",
    "        if critical_issues:\n",
    "            duration_ms = (datetime.now() - start_time).total_seconds() * 1000\n",
    "            return {\n",
    "                \"valid\": False,\n",
    "                \"issues\": issues,\n",
    "                \"stages_executed\": stages_executed,\n",
    "                \"duration_ms\": duration_ms,\n",
    "                \"cost_usd\": 0.0\n",
    "            }\n",
    "        \n",
    "        # STAGE 2: LLM SEMANTIC (SAMPLED)\n",
    "        if self.config.llm_enabled and self._should_use_llm():\n",
    "            with VALIDATION_DURATION.labels(stage='llm_semantic').time():\n",
    "                llm_issues, llm_cost = await self._validate_llm_semantic(record, validation_rules)\n",
    "                issues.extend(llm_issues)\n",
    "                stages_executed.append('llm_semantic')\n",
    "                total_cost += llm_cost\n",
    "                self.daily_cost += llm_cost\n",
    "                LLM_API_COST.set(self.daily_cost)\n",
    "                VALIDATIONS_TOTAL.labels(stage='llm_semantic', result='pass' if len(llm_issues)==0 else 'fail').inc()\n",
    "        \n",
    "        duration_ms = (datetime.now() - start_time).total_seconds() * 1000\n",
    "        \n",
    "        return {\n",
    "            \"valid\": len(issues) == 0,\n",
    "            \"issues\": issues,\n",
    "            \"stages_executed\": stages_executed,\n",
    "            \"duration_ms\": duration_ms,\n",
    "            \"cost_usd\": total_cost\n",
    "        }\n",
    "    \n",
    "    async def _validate_traditional(\n",
    "        self,\n",
    "        record: Dict,\n",
    "        rules: Dict\n",
    "    ) -> List[Dict]:\n",
    "        \"\"\"Stage 1: validaci\u00f3n tradicional (r\u00e1pida).\"\"\"\n",
    "        issues = []\n",
    "        \n",
    "        for column, rule_config in rules.items():\n",
    "            if 'traditional' not in rule_config:\n",
    "                continue\n",
    "            \n",
    "            value = record.get(column)\n",
    "            trad_rules = rule_config['traditional']\n",
    "            \n",
    "            # NULL check\n",
    "            if trad_rules.get('not_null') and value is None:\n",
    "                issues.append({\n",
    "                    \"column\": column,\n",
    "                    \"issue_type\": \"NULL\",\n",
    "                    \"severity\": \"CRITICAL\",\n",
    "                    \"message\": f\"Column '{column}' cannot be NULL\"\n",
    "                })\n",
    "            \n",
    "            # Range check\n",
    "            if 'range' in trad_rules and value is not None:\n",
    "                min_val, max_val = trad_rules['range']\n",
    "                if not (min_val <= value <= max_val):\n",
    "                    issues.append({\n",
    "                        \"column\": column,\n",
    "                        \"issue_type\": \"RANGE\",\n",
    "                        \"severity\": \"ERROR\",\n",
    "                        \"message\": f\"Value {value} outside range [{min_val}, {max_val}]\"\n",
    "                    })\n",
    "            \n",
    "            # Regex check\n",
    "            if 'regex' in trad_rules and value is not None:\n",
    "                import re\n",
    "                if not re.match(trad_rules['regex'], str(value)):\n",
    "                    issues.append({\n",
    "                        \"column\": column,\n",
    "                        \"issue_type\": \"FORMAT\",\n",
    "                        \"severity\": \"ERROR\",\n",
    "                        \"message\": f\"Value '{value}' doesn't match expected format\"\n",
    "                    })\n",
    "        \n",
    "        return issues\n",
    "    \n",
    "    async def _validate_llm_semantic(\n",
    "        self,\n",
    "        record: Dict,\n",
    "        rules: Dict\n",
    "    ) -> tuple[List[Dict], float]:\n",
    "        \"\"\"Stage 2: validaci\u00f3n sem\u00e1ntica con LLM (muestreada).\"\"\"\n",
    "        issues = []\n",
    "        total_cost = 0.0\n",
    "        \n",
    "        # Validar columnas con LLM enabled\n",
    "        llm_columns = {\n",
    "            col: config for col, config in rules.items()\n",
    "            if config.get('llm', {}).get('enabled', False)\n",
    "        }\n",
    "        \n",
    "        # Crear tasks concurrentes (con l\u00edmite)\n",
    "        semaphore = asyncio.Semaphore(self.config.llm_max_concurrent)\n",
    "        \n",
    "        async def validate_column(column: str, config: Dict):\n",
    "            async with semaphore:\n",
    "                value = record.get(column)\n",
    "                if value is None:\n",
    "                    return None, 0.0\n",
    "                \n",
    "                context = config['llm']['context']\n",
    "                \n",
    "                # Check cache\n",
    "                cached = self.cache.get(str(value), context, 'plausibility')\n",
    "                if cached:\n",
    "                    if not cached['is_valid']:\n",
    "                        return {\n",
    "                            \"column\": column,\n",
    "                            \"issue_type\": \"IMPLAUSIBLE\",\n",
    "                            \"severity\": \"WARNING\",\n",
    "                            \"message\": f\"{cached['reasoning']} (cached)\",\n",
    "                            \"confidence\": cached['confidence']\n",
    "                        }, 0.0\n",
    "                    return None, 0.0\n",
    "                \n",
    "                # LLM validation\n",
    "                prompt = f\"\"\"Valida plausibilidad:\n",
    "Column: {column}\n",
    "Context: {context}\n",
    "Value: {value}\n",
    "\n",
    "\u00bfEs v\u00e1lido? Responde JSON: {{\"is_valid\": bool, \"confidence\": 0-1, \"reasoning\": \"...\"}}\"\"\"\n",
    "                \n",
    "                try:\n",
    "                    response = await asyncio.wait_for(\n",
    "                        self.llm_client.chat.completions.create(\n",
    "                            model=\"gpt-4o-mini\",\n",
    "                            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                            temperature=0,\n",
    "                            response_format={\"type\": \"json_object\"}\n",
    "                        ),\n",
    "                        timeout=self.config.llm_timeout_seconds\n",
    "                    )\n",
    "                    \n",
    "                    result = json.loads(response.choices[0].message.content)\n",
    "                    \n",
    "                    # Estimar costo\n",
    "                    cost = (len(prompt) / 4 / 1_000_000 * 0.15) + (len(response.choices[0].message.content) / 4 / 1_000_000 * 0.60)\n",
    "                    \n",
    "                    # Cache result\n",
    "                    self.cache.set(str(value), context, 'plausibility', result)\n",
    "                    \n",
    "                    if not result['is_valid']:\n",
    "                        return {\n",
    "                            \"column\": column,\n",
    "                            \"issue_type\": \"IMPLAUSIBLE\",\n",
    "                            \"severity\": \"WARNING\",\n",
    "                            \"message\": result['reasoning'],\n",
    "                            \"confidence\": result['confidence']\n",
    "                        }, cost\n",
    "                    \n",
    "                    return None, cost\n",
    "                    \n",
    "                except asyncio.TimeoutError:\n",
    "                    logger.warning(f\"LLM timeout for column {column}\")\n",
    "                    return None, 0.0\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"LLM error for column {column}: {e}\")\n",
    "                    return None, 0.0\n",
    "        \n",
    "        # Ejecutar validaciones en paralelo\n",
    "        tasks = [validate_column(col, config) for col, config in llm_columns.items()]\n",
    "        results = await asyncio.gather(*tasks)\n",
    "        \n",
    "        for issue, cost in results:\n",
    "            if issue:\n",
    "                issues.append(issue)\n",
    "            total_cost += cost\n",
    "        \n",
    "        return issues, total_cost\n",
    "\n",
    "# 3. BATCH VALIDATOR (para procesamiento masivo)\n",
    "\n",
    "class BatchValidator:\n",
    "    \"\"\"Validador optimizado para batches grandes.\"\"\"\n",
    "    \n",
    "    def __init__(self, validator: ProductionValidator):\n",
    "        self.validator = validator\n",
    "    \n",
    "    async def validate_batch(\n",
    "        self,\n",
    "        records: List[Dict],\n",
    "        validation_rules: Dict,\n",
    "        parallelism: int = 100\n",
    "    ) -> Dict:\n",
    "        \"\"\"\n",
    "        Valida batch de registros en paralelo.\n",
    "        \n",
    "        Returns:\n",
    "            {\n",
    "                \"total_records\": int,\n",
    "                \"valid_records\": int,\n",
    "                \"invalid_records\": int,\n",
    "                \"issues_by_type\": Dict[str, int],\n",
    "                \"total_duration_seconds\": float,\n",
    "                \"total_cost_usd\": float\n",
    "            }\n",
    "        \"\"\"\n",
    "        start_time = datetime.now()\n",
    "        \n",
    "        # Semaphore para controlar paralelismo\n",
    "        semaphore = asyncio.Semaphore(parallelism)\n",
    "        \n",
    "        async def validate_with_semaphore(record):\n",
    "            async with semaphore:\n",
    "                return await self.validator.validate_record(record, validation_rules)\n",
    "        \n",
    "        # Validar todos los registros\n",
    "        tasks = [validate_with_semaphore(record) for record in records]\n",
    "        results = await asyncio.gather(*tasks)\n",
    "        \n",
    "        # Agregar resultados\n",
    "        valid_count = sum(1 for r in results if r['valid'])\n",
    "        invalid_count = len(results) - valid_count\n",
    "        \n",
    "        issues_by_type = {}\n",
    "        total_cost = 0.0\n",
    "        \n",
    "        for result in results:\n",
    "            total_cost += result['cost_usd']\n",
    "            for issue in result['issues']:\n",
    "                issue_type = issue['issue_type']\n",
    "                issues_by_type[issue_type] = issues_by_type.get(issue_type, 0) + 1\n",
    "        \n",
    "        duration = (datetime.now() - start_time).total_seconds()\n",
    "        \n",
    "        return {\n",
    "            \"total_records\": len(records),\n",
    "            \"valid_records\": valid_count,\n",
    "            \"invalid_records\": invalid_count,\n",
    "            \"issues_by_type\": issues_by_type,\n",
    "            \"total_duration_seconds\": duration,\n",
    "            \"total_cost_usd\": total_cost,\n",
    "            \"throughput_records_per_second\": len(records) / duration\n",
    "        }\n",
    "\n",
    "# EJEMPLO DE USO EN PRODUCCI\u00d3N\n",
    "\n",
    "async def main():\n",
    "    # Setup\n",
    "    cache = ValidationCache()\n",
    "    llm_client = AsyncOpenAI(api_key=os.getenv('OPENAI_API_KEY'))\n",
    "    \n",
    "    config = ValidationConfig(\n",
    "        traditional_enabled=True,\n",
    "        llm_enabled=True,\n",
    "        llm_sample_rate=0.01,  # 1% de tr\u00e1fico\n",
    "        llm_max_concurrent=10,\n",
    "        cost_budget_daily_usd=10.0\n",
    "    )\n",
    "    \n",
    "    validator = ProductionValidator(config, cache, llm_client)\n",
    "    batch_validator = BatchValidator(validator)\n",
    "    \n",
    "    # Reglas de validaci\u00f3n\n",
    "    validation_rules = {\n",
    "        'email': {\n",
    "            'traditional': {\n",
    "                'not_null': True,\n",
    "                'regex': r'^[\\w\\.-]+@[\\w\\.-]+\\.\\w+$'\n",
    "            },\n",
    "            'llm': {\n",
    "                'enabled': True,\n",
    "                'context': 'Customer emails (no test data)'\n",
    "            }\n",
    "        },\n",
    "        'age': {\n",
    "            'traditional': {\n",
    "                'not_null': True,\n",
    "                'range': [18, 120]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Dataset de prueba (1000 registros)\n",
    "    records = [\n",
    "        {'email': f'user{i}@example.com', 'age': 25 + (i % 50)}\n",
    "        for i in range(1000)\n",
    "    ]\n",
    "    \n",
    "    # Agregar algunos registros problem\u00e1ticos\n",
    "    records[10]['email'] = 'test@test.test'  # Fake email\n",
    "    records[20]['age'] = 999  # Outlier\n",
    "    records[30]['email'] = None  # NULL\n",
    "    \n",
    "    # Validar batch\n",
    "    print(\"\ud83d\ude80 Validando batch de 1000 registros...\")\n",
    "    result = await batch_validator.validate_batch(records, validation_rules, parallelism=50)\n",
    "    \n",
    "    print(\"\\n\ud83d\udcca RESULTADOS:\")\n",
    "    print(f\"   Total: {result['total_records']}\")\n",
    "    print(f\"   V\u00e1lidos: {result['valid_records']} ({result['valid_records']/result['total_records']:.1%})\")\n",
    "    print(f\"   Inv\u00e1lidos: {result['invalid_records']}\")\n",
    "    print(f\"   Issues por tipo: {result['issues_by_type']}\")\n",
    "    print(f\"   Duraci\u00f3n: {result['total_duration_seconds']:.2f}s\")\n",
    "    print(f\"   Throughput: {result['throughput_records_per_second']:.0f} records/s\")\n",
    "    print(f\"   Costo total: ${result['total_cost_usd']:.4f}\")\n",
    "\n",
    "# Ejecutar\n",
    "# asyncio.run(main())\n",
    "```\n",
    "\n",
    "### \ud83d\udcca M\u00e9tricas de Producci\u00f3n\n",
    "\n",
    "| M\u00e9trica | Target | Medici\u00f3n |\n",
    "|---------|--------|----------|\n",
    "| **Latency p50** | <50ms | Traditional only |\n",
    "| **Latency p99** | <500ms | With LLM (1% sample) |\n",
    "| **Throughput** | >1000 records/s | Batch processing |\n",
    "| **Cache hit rate** | >80% | Redis cache |\n",
    "| **Cost per 1M records** | <$10 | LLM API calls |\n",
    "| **False positive rate** | <2% | Validation precision |\n",
    "| **Availability** | 99.9% | Uptime |\n",
    "\n",
    "### \ud83d\udcb0 Estrategias de Optimizaci\u00f3n de Costos\n",
    "\n",
    "```python\n",
    "# 1. ADAPTIVE SAMPLING\n",
    "class AdaptiveSampler:\n",
    "    \"\"\"Ajusta sample rate bas\u00e1ndose en calidad de datos.\"\"\"\n",
    "    \n",
    "    def __init__(self, initial_rate: float = 0.01):\n",
    "        self.rate = initial_rate\n",
    "        self.recent_issues = []\n",
    "    \n",
    "    def update(self, has_issues: bool):\n",
    "        \"\"\"Actualiza rate bas\u00e1ndose en issues recientes.\"\"\"\n",
    "        self.recent_issues.append(has_issues)\n",
    "        \n",
    "        # Mantener ventana de \u00faltimos 1000 registros\n",
    "        if len(self.recent_issues) > 1000:\n",
    "            self.recent_issues = self.recent_issues[-1000:]\n",
    "        \n",
    "        issue_rate = sum(self.recent_issues) / len(self.recent_issues)\n",
    "        \n",
    "        # Si issue rate es alta (>5%), aumentar sampling\n",
    "        if issue_rate > 0.05:\n",
    "            self.rate = min(0.10, self.rate * 1.5)\n",
    "        # Si issue rate es baja (<1%), reducir sampling\n",
    "        elif issue_rate < 0.01:\n",
    "            self.rate = max(0.001, self.rate * 0.8)\n",
    "    \n",
    "    def should_sample(self) -> bool:\n",
    "        import random\n",
    "        return random.random() < self.rate\n",
    "\n",
    "# 2. SMART CACHING\n",
    "# Cachear por m\u00e1s tiempo valores que se repiten frecuentemente\n",
    "# TTL adaptativo basado en frecuencia\n",
    "\n",
    "# 3. BATCH INFERENCE\n",
    "# Procesar m\u00faltiples validaciones en un solo prompt\n",
    "# Reducir overhead de API calls\n",
    "```\n",
    "\n",
    "### \ud83d\ude80 Deployment Checklist\n",
    "\n",
    "- [ ] **Infraestructura**:\n",
    "  - [ ] Redis cluster para cache (multi-AZ)\n",
    "  - [ ] Async workers (Celery / RQ)\n",
    "  - [ ] Load balancer para distribuci\u00f3n\n",
    "  \n",
    "- [ ] **Monitoring**:\n",
    "  - [ ] Prometheus + Grafana dashboards\n",
    "  - [ ] Alertas en PagerDuty/Slack\n",
    "  - [ ] Cost tracking diario\n",
    "  - [ ] Latency monitoring (p50, p95, p99)\n",
    "  \n",
    "- [ ] **Testing**:\n",
    "  - [ ] Load testing (>10K records/s)\n",
    "  - [ ] Chaos testing (LLM API down)\n",
    "  - [ ] Cost simulation\n",
    "  \n",
    "- [ ] **Security**:\n",
    "  - [ ] API key rotation\n",
    "  - [ ] PII masking en logs\n",
    "  - [ ] Rate limiting por usuario\n",
    "  \n",
    "- [ ] **Documentation**:\n",
    "  - [ ] Runbook para incidents\n",
    "  - [ ] SLA commitments\n",
    "  - [ ] Cost budgets por equipo\n",
    "\n",
    "---\n",
    "**Autor:** Luis J. Raigoso V. (LJRV)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db249c09",
   "metadata": {},
   "source": [
    "## 1. Detecci\u00f3n de anomal\u00edas sem\u00e1nticas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78572e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))\n",
    "\n",
    "def detect_anomaly(value: str, context: str) -> dict:\n",
    "    \"\"\"Detecta si un valor es an\u00f3malo en su contexto.\"\"\"\n",
    "    prompt = f'''\n",
    "Contexto: {context}\n",
    "Valor: {value}\n",
    "\n",
    "\u00bfEs este valor an\u00f3malo o incorrecto? Responde en JSON:\n",
    "{{\n",
    "  \"is_anomaly\": true/false,\n",
    "  \"confidence\": 0-100,\n",
    "  \"reason\": \"explicaci\u00f3n\",\n",
    "  \"suggested_fix\": \"valor corregido o null\"\n",
    "}}\n",
    "'''\n",
    "    resp = client.chat.completions.create(\n",
    "        model='gpt-4',\n",
    "        messages=[{'role':'user','content':prompt}],\n",
    "        temperature=0\n",
    "    )\n",
    "    import json\n",
    "    return json.loads(resp.choices[0].message.content)\n",
    "\n",
    "# Ejemplos\n",
    "casos = [\n",
    "    {'valor': 'Nueva Yorkk', 'contexto': 'Columna: ciudad (ciudades de USA)'},\n",
    "    {'valor': '999', 'contexto': 'Columna: edad (a\u00f1os de personas)'},\n",
    "    {'valor': 'admin@example.com', 'contexto': 'Columna: email de clientes reales'}\n",
    "]\n",
    "\n",
    "for caso in casos:\n",
    "    result = detect_anomaly(caso['valor'], caso['contexto'])\n",
    "    print(f\"Valor: {caso['valor']}\")\n",
    "    print(f\"Anomal\u00eda: {result['is_anomaly']} (confianza={result['confidence']}%)\")\n",
    "    print(f\"Raz\u00f3n: {result['reason']}\")\n",
    "    if result['suggested_fix']:\n",
    "        print(f\"Sugerencia: {result['suggested_fix']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40dcd6b",
   "metadata": {},
   "source": [
    "## 2. Clasificaci\u00f3n de errores en datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc1c9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_data_issue(issue_description: str) -> str:\n",
    "    \"\"\"Clasifica el tipo de problema de datos.\"\"\"\n",
    "    prompt = f'''\n",
    "Clasifica este problema de datos en UNA categor\u00eda:\n",
    "- DUPLICATES: registros duplicados\n",
    "- NULLS: valores faltantes\n",
    "- FORMAT: formato incorrecto\n",
    "- OUTLIER: valores fuera de rango\n",
    "- INCONSISTENCY: datos inconsistentes entre fuentes\n",
    "- FRESHNESS: datos desactualizados\n",
    "\n",
    "Problema: {issue_description}\n",
    "\n",
    "Categor\u00eda:\n",
    "'''\n",
    "    resp = client.chat.completions.create(\n",
    "        model='gpt-3.5-turbo',\n",
    "        messages=[{'role':'user','content':prompt}],\n",
    "        temperature=0\n",
    "    )\n",
    "    return resp.choices[0].message.content.strip()\n",
    "\n",
    "issues = [\n",
    "    'La tabla tiene 500 filas con cliente_id = NULL',\n",
    "    'Fechas en formato DD/MM/YYYY pero esperamos YYYY-MM-DD',\n",
    "    '\u00daltima actualizaci\u00f3n hace 7 d\u00edas pero debe ser diaria',\n",
    "    'Misma transacci\u00f3n aparece 3 veces con diferentes IDs'\n",
    "]\n",
    "\n",
    "for issue in issues:\n",
    "    categoria = classify_data_issue(issue)\n",
    "    print(f'\u27a1\ufe0f \"{issue}\"')\n",
    "    print(f'   Categor\u00eda: {categoria}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb562809",
   "metadata": {},
   "source": [
    "## 3. Generaci\u00f3n de reglas de validaci\u00f3n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e3c7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_validation_rules(column_name: str, sample_data: list, description: str = '') -> str:\n",
    "    \"\"\"Genera reglas de Great Expectations.\"\"\"\n",
    "    prompt = f'''\n",
    "Genera expectativas de Great Expectations (Python) para validar esta columna:\n",
    "\n",
    "Columna: {column_name}\n",
    "Descripci\u00f3n: {description}\n",
    "Muestra de datos: {sample_data}\n",
    "\n",
    "Genera c\u00f3digo Python con expect_* methods. Ejemplos:\n",
    "- expect_column_values_to_not_be_null\n",
    "- expect_column_values_to_be_between\n",
    "- expect_column_values_to_match_regex\n",
    "\n",
    "C\u00f3digo:\n",
    "'''\n",
    "    resp = client.chat.completions.create(\n",
    "        model='gpt-4',\n",
    "        messages=[{'role':'user','content':prompt}],\n",
    "        temperature=0.1\n",
    "    )\n",
    "    return resp.choices[0].message.content.strip().replace('```python','').replace('```','')\n",
    "\n",
    "# Ejemplo\n",
    "rules = generate_validation_rules(\n",
    "    column_name='email',\n",
    "    sample_data=['user@example.com', 'admin@test.org', 'info@company.co'],\n",
    "    description='Emails de clientes'\n",
    ")\n",
    "\n",
    "print(rules)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cecde61",
   "metadata": {},
   "source": [
    "## 4. Validaci\u00f3n batch con LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cef1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_batch(df: pd.DataFrame, rules: dict) -> pd.DataFrame:\n",
    "    \"\"\"Valida DataFrame seg\u00fan reglas inferidas por LLM.\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for col, rule_desc in rules.items():\n",
    "        sample = df[col].dropna().head(10).tolist()\n",
    "        \n",
    "        prompt = f'''\n",
    "Valida si estos valores cumplen la regla:\n",
    "Regla: {rule_desc}\n",
    "Valores: {sample}\n",
    "\n",
    "Responde con porcentaje de conformidad (0-100) y problemas encontrados.\n",
    "'''\n",
    "        \n",
    "        resp = client.chat.completions.create(\n",
    "            model='gpt-3.5-turbo',\n",
    "            messages=[{'role':'user','content':prompt}],\n",
    "            temperature=0\n",
    "        )\n",
    "        \n",
    "        results.append({\n",
    "            'columna': col,\n",
    "            'regla': rule_desc,\n",
    "            'resultado': resp.choices[0].message.content\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Datos de prueba\n",
    "df_test = pd.DataFrame({\n",
    "    'edad': [25, 30, 200, 45, -5],\n",
    "    'email': ['a@b.com', 'invalido', 'test@x.org', None, 'ok@mail.com']\n",
    "})\n",
    "\n",
    "validation_rules = {\n",
    "    'edad': 'Debe estar entre 0 y 120',\n",
    "    'email': 'Debe ser email v\u00e1lido o null'\n",
    "}\n",
    "\n",
    "validation_report = validate_batch(df_test, validation_rules)\n",
    "print(validation_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00de5039",
   "metadata": {},
   "source": [
    "## 5. Explicaci\u00f3n de anomal\u00edas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058d734b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain_outlier(value: float, stats: dict) -> str:\n",
    "    \"\"\"Explica por qu\u00e9 un valor es outlier en lenguaje natural.\"\"\"\n",
    "    prompt = f'''\n",
    "Valor: {value}\n",
    "Estad\u00edsticas de la columna:\n",
    "- Media: {stats['mean']}\n",
    "- Desviaci\u00f3n est\u00e1ndar: {stats['std']}\n",
    "- Min: {stats['min']}\n",
    "- Max: {stats['max']}\n",
    "\n",
    "Explica en 2-3 frases por qu\u00e9 este valor es an\u00f3malo y qu\u00e9 puede indicar.\n",
    "'''\n",
    "    resp = client.chat.completions.create(\n",
    "        model='gpt-4',\n",
    "        messages=[{'role':'user','content':prompt}],\n",
    "        temperature=0.3\n",
    "    )\n",
    "    return resp.choices[0].message.content.strip()\n",
    "\n",
    "# Ejemplo\n",
    "outlier_explanation = explain_outlier(\n",
    "    value=50000,\n",
    "    stats={'mean': 120, 'std': 35, 'min': 50, 'max': 250}\n",
    ")\n",
    "\n",
    "print('Explicaci\u00f3n del outlier:')\n",
    "print(outlier_explanation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9b80d2",
   "metadata": {},
   "source": [
    "## 6. Sugerencia de limpieza de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5c773b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def suggest_data_cleaning(df_sample: pd.DataFrame) -> str:\n",
    "    \"\"\"Sugiere pasos de limpieza basados en muestra.\"\"\"\n",
    "    info = {\n",
    "        'columns': df_sample.columns.tolist(),\n",
    "        'dtypes': df_sample.dtypes.astype(str).to_dict(),\n",
    "        'nulls': df_sample.isnull().sum().to_dict(),\n",
    "        'sample': df_sample.head(3).to_dict()\n",
    "    }\n",
    "    \n",
    "    prompt = f'''\n",
    "Analiza este DataFrame y sugiere pasos de limpieza en orden de prioridad:\n",
    "\n",
    "{info}\n",
    "\n",
    "Lista numerada de acciones de limpieza con c\u00f3digo Pandas cuando sea relevante.\n",
    "'''\n",
    "    \n",
    "    resp = client.chat.completions.create(\n",
    "        model='gpt-4',\n",
    "        messages=[{'role':'user','content':prompt}],\n",
    "        temperature=0.2\n",
    "    )\n",
    "    \n",
    "    return resp.choices[0].message.content\n",
    "\n",
    "messy_df = pd.DataFrame({\n",
    "    'fecha': ['2024-01-01', '01/02/2024', None, '2024-03-15'],\n",
    "    'monto': ['100', '200.5', 'N/A', '300'],\n",
    "    'categoria': ['  ventas', 'VENTAS', 'Ventas ', 'marketing']\n",
    "})\n",
    "\n",
    "cleaning_plan = suggest_data_cleaning(messy_df)\n",
    "print(cleaning_plan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d205e02",
   "metadata": {},
   "source": [
    "## 7. Validaci\u00f3n de coherencia entre tablas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc895787",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_referential_integrity(parent_ids: list, child_ids: list, relationship: str) -> dict:\n",
    "    \"\"\"Valida integridad referencial con explicaci\u00f3n.\"\"\"\n",
    "    orphans = set(child_ids) - set(parent_ids)\n",
    "    \n",
    "    prompt = f'''\n",
    "Relaci\u00f3n: {relationship}\n",
    "IDs hu\u00e9rfanos (en tabla hija pero no en padre): {list(orphans)[:10]}\n",
    "Total hu\u00e9rfanos: {len(orphans)}\n",
    "\n",
    "Explica el problema y sugiere 3 posibles causas.\n",
    "'''\n",
    "    \n",
    "    resp = client.chat.completions.create(\n",
    "        model='gpt-4',\n",
    "        messages=[{'role':'user','content':prompt}],\n",
    "        temperature=0.2\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        'orphans_count': len(orphans),\n",
    "        'orphan_sample': list(orphans)[:5],\n",
    "        'explanation': resp.choices[0].message.content\n",
    "    }\n",
    "\n",
    "# Ejemplo\n",
    "productos_ids = [1, 2, 3, 4, 5]\n",
    "ventas_producto_ids = [1, 2, 3, 99, 100, 5]\n",
    "\n",
    "integrity_check = validate_referential_integrity(\n",
    "    parent_ids=productos_ids,\n",
    "    child_ids=ventas_producto_ids,\n",
    "    relationship='ventas.producto_id -> productos.producto_id'\n",
    ")\n",
    "\n",
    "print(f\"Hu\u00e9rfanos: {integrity_check['orphans_count']}\")\n",
    "print(f\"Muestra: {integrity_check['orphan_sample']}\")\n",
    "print(f\"\\nExplicaci\u00f3n:\\n{integrity_check['explanation']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808646c6",
   "metadata": {},
   "source": [
    "## 8. Buenas pr\u00e1cticas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af78399a",
   "metadata": {},
   "source": [
    "- **Complementar, no reemplazar**: LLMs complementan herramientas tradicionales (GE, pandas profiling).\n",
    "- **Validaci\u00f3n humana**: revisa sugerencias antes de aplicar.\n",
    "- **Umbrales**: define confidence thresholds para automatizaci\u00f3n.\n",
    "- **Logging**: registra todas las decisiones del LLM.\n",
    "- **Costos**: cachea validaciones comunes.\n",
    "- **Testing**: valida el validador con datos conocidos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37ea8ee",
   "metadata": {},
   "source": [
    "## 9. Ejercicios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9702d2f9",
   "metadata": {},
   "source": [
    "1. Construye un sistema de auto-reparaci\u00f3n de datos usando LLM suggestions.\n",
    "2. Genera un data quality dashboard con explicaciones en lenguaje natural.\n",
    "3. Implementa detecci\u00f3n de PII (datos sensibles) con LLMs.\n",
    "4. Crea un agente que diagnostique problemas de data quality y proponga fixes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## \ud83e\udded Navegaci\u00f3n\n",
    "\n",
    "**\u2190 Anterior:** [\ud83e\udd16 Agentes Aut\u00f3nomos para Automatizaci\u00f3n](06_agentes_automatizacion.ipynb)\n",
    "\n",
    "**Siguiente \u2192:** [\ud83c\udfb2 Generaci\u00f3n de Datos Sint\u00e9ticos con LLMs \u2192](08_sintesis_aumento_datos.ipynb)\n",
    "\n",
    "**\ud83d\udcda \u00cdndice de Nivel GenAI:**\n",
    "- [\ud83d\udd04 Comparaci\u00f3n: OpenAI vs Google Gemini](00_comparacion_openai_gemini.ipynb)\n",
    "- [\ud83e\udd16 Fundamentos de LLMs y Prompting](01_fundamentos_llms_prompting.ipynb)\n",
    "- [\ud83d\udcca Text-to-SQL: Generaci\u00f3n de Consultas SQL desde Lenguaje Natural](02_generacion_sql_nl2sql.ipynb)\n",
    "- [\ud83d\udd27 Generaci\u00f3n Autom\u00e1tica de C\u00f3digo ETL con LLMs](03_generacion_codigo_etl.ipynb)\n",
    "- [\ud83d\udcda RAG: Documentaci\u00f3n T\u00e9cnica con LLMs](04_rag_documentacion_datos.ipynb)\n",
    "- [\ud83d\udd0d Embeddings y Similitud en Datos](05_embeddings_similitud_datos.ipynb)\n",
    "- [\ud83e\udd16 Agentes Aut\u00f3nomos para Automatizaci\u00f3n](06_agentes_automatizacion.ipynb)\n",
    "- [\u2705 Validaci\u00f3n de Datos con LLMs](07_calidad_validacion_llm.ipynb) \u2190 \ud83d\udd35 Est\u00e1s aqu\u00ed\n",
    "- [\ud83c\udfb2 Generaci\u00f3n de Datos Sint\u00e9ticos con LLMs](08_sintesis_aumento_datos.ipynb)\n",
    "- [\ud83d\ude80 Proyecto Integrador 1: Chatbot de Consulta de Datos con RAG](09_proyecto_integrador_1.ipynb)\n",
    "- [\ud83c\udfd7\ufe0f Proyecto Integrador 2: Plataforma Self-Service con GenAI](10_proyecto_integrador_2.ipynb)\n",
    "\n",
    "**\ud83c\udf93 Otros Niveles:**\n",
    "- [Nivel Junior](../nivel_junior/README.md)\n",
    "- [Nivel Mid](../nivel_mid/README.md)\n",
    "- [Nivel Senior](../nivel_senior/README.md)\n",
    "- [Nivel GenAI](../nivel_genai/README.md)\n",
    "- [Negocio LATAM](../negocios_latam/README.md)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
