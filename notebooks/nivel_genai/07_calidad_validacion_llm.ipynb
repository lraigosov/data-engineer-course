{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29150ce4",
   "metadata": {},
   "source": [
    "# ‚úÖ Validaci√≥n de Datos con LLMs\n",
    "\n",
    "Objetivo: usar LLMs para detectar anomal√≠as, validar calidad de datos, clasificar errores, y generar reglas de validaci√≥n de forma inteligente.\n",
    "\n",
    "- Duraci√≥n: 90 min\n",
    "- Dificultad: Media/Alta\n",
    "- Stack: OpenAI, Great Expectations, Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c299757e",
   "metadata": {},
   "source": [
    "## üîç LLMs para Data Quality: M√°s All√° de Reglas Est√°ticas\n",
    "\n",
    "La **validaci√≥n tradicional** de datos se basa en reglas predefinidas (nulls, rangos, formatos). Los **LLMs** permiten validaci√≥n **sem√°ntica y contextual**: detectar anomal√≠as que ninguna regla puede capturar, explicar root causes, y generar reglas de validaci√≥n autom√°ticamente.\n",
    "\n",
    "### üèóÔ∏è Evoluci√≥n de Data Quality\n",
    "\n",
    "```\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ         DATA QUALITY: TRADITIONAL vs LLM-POWERED                 ‚îÇ\n",
    "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
    "‚îÇ                                                                  ‚îÇ\n",
    "‚îÇ  TRADITIONAL (Rule-Based):                                       ‚îÇ\n",
    "‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ\n",
    "‚îÇ  ‚îÇ 1. Null Checks                                           ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ    assert column.notnull().all()                         ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ    ‚úÖ Detecta: NULL values                               ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ    ‚ùå No detecta: \"N/A\", \"Unknown\", \"‚Äî\"                 ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ                                                          ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ 2. Range Checks                                          ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ    assert (edad >= 0) & (edad <= 120)                    ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ    ‚úÖ Detecta: edad = -5 o 200                           ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ    ‚ùå No detecta: edad = 999 (typo de 99)               ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ                                                          ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ 3. Regex Validation                                      ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ    assert email.str.match(r'^[\\w.-]+@[\\w.-]+\\.\\w+$')    ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ    ‚úÖ Detecta: \"invalid-email\"                           ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ    ‚ùå No detecta: \"test@test.test\" (fake)               ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ                                                          ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ 4. Referential Integrity                                 ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ    assert ventas.producto_id.isin(productos.id)          ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ    ‚úÖ Detecta: producto_id = 999 (no existe)            ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ    ‚ùå No explica POR QU√â fall√≥                          ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ\n",
    "‚îÇ                                                                  ‚îÇ\n",
    "‚îÇ  LLM-POWERED (Semantic + Contextual):                            ‚îÇ\n",
    "‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ\n",
    "‚îÇ  ‚îÇ 1. Semantic Null Detection                               ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ    LLM analiza: \"N/A\", \"Unknown\", \"‚Äî\", \"TBD\"            ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ    ‚Üí Detecta pseudo-nulls con contexto                   ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ    ‚úÖ \"N/A\" en columna 'ciudad' ‚Üí NULL sem√°ntico        ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ    ‚úÖ \"N/A\" en columna 'notas' ‚Üí V√°lido                 ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ                                                          ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ 2. Contextual Outlier Detection                          ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ    LLM: \"edad = 999 es typo de 99 (patr√≥n com√∫n)\"       ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ    ‚Üí Sugiere correcci√≥n basada en contexto              ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ    ‚úÖ Explica: \"Probablemente typo en entrada manual\"   ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ    ‚úÖ Sugiere: 99 o 9 (seg√∫n distribuci√≥n)              ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ                                                          ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ 3. Plausibility Validation                               ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ    LLM: \"test@test.test es email t√©cnico, no real\"      ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ    ‚Üí Detecta datos sint√©ticamente v√°lidos pero falsos   ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ    ‚úÖ \"admin@example.com\" ‚Üí Test data                   ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ    ‚úÖ \"Nueva Yorkk\" ‚Üí Typo de \"Nueva York\"              ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ                                                          ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ 4. Root Cause Analysis                                   ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ    LLM: \"50 producto_ids hu√©rfanos desde 2024-10-15\"    ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ    ‚Üí Analiza: \"Coincide con deploy de API v2\"           ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ    ‚úÖ Explica causa probable                            ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ    ‚úÖ Sugiere soluci√≥n: \"Mapear IDs antiguos‚Üínuevos\"    ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ\n",
    "‚îÇ                                                                  ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "```\n",
    "\n",
    "### üéØ Casos de Uso: LLMs vs Traditional\n",
    "\n",
    "| Problema | Traditional | LLM-Powered | Ganador |\n",
    "|----------|-------------|-------------|---------|\n",
    "| **NULL detection** | `column.isnull()` | Detecta \"N/A\", \"Unknown\", \"‚Äî\" | üèÜ LLM |\n",
    "| **Email validation** | Regex pattern | Detecta test@test.com como fake | üèÜ LLM |\n",
    "| **City names** | Whitelist de ciudades | Detecta \"Nueva Yorkk\" como typo | üèÜ LLM |\n",
    "| **Age range** | `age.between(0, 120)` | \"999 es typo de 99\" | üèÜ LLM |\n",
    "| **Performance** | Instant√°neo | 100-500ms por validaci√≥n | üèÜ Traditional |\n",
    "| **Costo** | Gratis | $0.001-$0.01 por registro | üèÜ Traditional |\n",
    "| **Explicabilidad** | Regla booleana | Natural language explanation | üèÜ LLM |\n",
    "\n",
    "**Conclusi√≥n**: LLMs **complementan** (no reemplazan) validaci√≥n tradicional. Usar ambos en **h√≠brido**.\n",
    "\n",
    "### üîß Implementaci√≥n: Sistema H√≠brido de Validaci√≥n\n",
    "\n",
    "```python\n",
    "from typing import List, Dict, Optional, Literal\n",
    "from pydantic import BaseModel, Field\n",
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dataclasses import dataclass\n",
    "from enum import Enum\n",
    "import json\n",
    "\n",
    "client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))\n",
    "\n",
    "# 1. MODELOS DE DATOS\n",
    "\n",
    "class ValidationSeverity(str, Enum):\n",
    "    \"\"\"Severidad de issue de calidad.\"\"\"\n",
    "    CRITICAL = \"CRITICAL\"  # Bloquea pipeline\n",
    "    ERROR = \"ERROR\"        # Requiere fix\n",
    "    WARNING = \"WARNING\"    # Revisar\n",
    "    INFO = \"INFO\"          # Informativo\n",
    "\n",
    "class ValidationIssue(BaseModel):\n",
    "    \"\"\"Issue de calidad detectado.\"\"\"\n",
    "    column: str\n",
    "    row_index: Optional[int] = None\n",
    "    value: Optional[str] = None\n",
    "    issue_type: str  # NULLS, OUTLIER, FORMAT, INCONSISTENCY, etc.\n",
    "    severity: ValidationSeverity\n",
    "    confidence: float = Field(..., ge=0, le=1)\n",
    "    description: str\n",
    "    suggested_fix: Optional[str] = None\n",
    "    detected_by: Literal[\"traditional\", \"llm\", \"hybrid\"]\n",
    "\n",
    "class ValidationReport(BaseModel):\n",
    "    \"\"\"Reporte completo de validaci√≥n.\"\"\"\n",
    "    table_name: str\n",
    "    total_rows: int\n",
    "    total_issues: int\n",
    "    issues_by_severity: Dict[ValidationSeverity, int]\n",
    "    issues: List[ValidationIssue]\n",
    "    execution_time_seconds: float\n",
    "    cost_usd: float\n",
    "\n",
    "# 2. VALIDADORES TRADICIONALES\n",
    "\n",
    "class TraditionalValidator:\n",
    "    \"\"\"Validador basado en reglas est√°ticas.\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def check_nulls(df: pd.DataFrame, column: str) -> List[ValidationIssue]:\n",
    "        \"\"\"Detecta valores NULL.\"\"\"\n",
    "        null_mask = df[column].isnull()\n",
    "        null_count = null_mask.sum()\n",
    "        \n",
    "        if null_count == 0:\n",
    "            return []\n",
    "        \n",
    "        # Detectar todos los nulls\n",
    "        issues = []\n",
    "        for idx in df[null_mask].index[:100]:  # Limitar a 100 por performance\n",
    "            issues.append(ValidationIssue(\n",
    "                column=column,\n",
    "                row_index=int(idx),\n",
    "                value=None,\n",
    "                issue_type=\"NULLS\",\n",
    "                severity=ValidationSeverity.ERROR,\n",
    "                confidence=1.0,\n",
    "                description=f\"Valor NULL en columna requerida '{column}'\",\n",
    "                suggested_fix=\"Impute con media/moda o remover registro\",\n",
    "                detected_by=\"traditional\"\n",
    "            ))\n",
    "        \n",
    "        return issues\n",
    "    \n",
    "    @staticmethod\n",
    "    def check_range(\n",
    "        df: pd.DataFrame, \n",
    "        column: str, \n",
    "        min_val: float, \n",
    "        max_val: float\n",
    "    ) -> List[ValidationIssue]:\n",
    "        \"\"\"Detecta valores fuera de rango.\"\"\"\n",
    "        out_of_range = df[(df[column] < min_val) | (df[column] > max_val)]\n",
    "        \n",
    "        issues = []\n",
    "        for idx, row in out_of_range.iterrows():\n",
    "            value = row[column]\n",
    "            issues.append(ValidationIssue(\n",
    "                column=column,\n",
    "                row_index=int(idx),\n",
    "                value=str(value),\n",
    "                issue_type=\"OUTLIER\",\n",
    "                severity=ValidationSeverity.ERROR,\n",
    "                confidence=1.0,\n",
    "                description=f\"Valor {value} fuera de rango [{min_val}, {max_val}]\",\n",
    "                suggested_fix=f\"Clamp a rango o marcar como outlier\",\n",
    "                detected_by=\"traditional\"\n",
    "            ))\n",
    "        \n",
    "        return issues\n",
    "    \n",
    "    @staticmethod\n",
    "    def check_regex(\n",
    "        df: pd.DataFrame, \n",
    "        column: str, \n",
    "        pattern: str\n",
    "    ) -> List[ValidationIssue]:\n",
    "        \"\"\"Valida formato con regex.\"\"\"\n",
    "        invalid_mask = ~df[column].astype(str).str.match(pattern)\n",
    "        invalid_values = df[invalid_mask]\n",
    "        \n",
    "        issues = []\n",
    "        for idx, row in invalid_values.iterrows():\n",
    "            value = row[column]\n",
    "            issues.append(ValidationIssue(\n",
    "                column=column,\n",
    "                row_index=int(idx),\n",
    "                value=str(value),\n",
    "                issue_type=\"FORMAT\",\n",
    "                severity=ValidationSeverity.ERROR,\n",
    "                confidence=1.0,\n",
    "                description=f\"Valor '{value}' no coincide con patr√≥n esperado\",\n",
    "                suggested_fix=\"Reformatear seg√∫n pattern\",\n",
    "                detected_by=\"traditional\"\n",
    "            ))\n",
    "        \n",
    "        return issues\n",
    "\n",
    "# 3. VALIDADOR CON LLM\n",
    "\n",
    "class LLMValidator:\n",
    "    \"\"\"Validador con an√°lisis sem√°ntico usando LLM.\"\"\"\n",
    "    \n",
    "    def __init__(self, model: str = \"gpt-4o-mini\"):  # Modelo barato para validaci√≥n\n",
    "        self.model = model\n",
    "        self.total_cost = 0.0\n",
    "    \n",
    "    def check_semantic_nulls(\n",
    "        self, \n",
    "        df: pd.DataFrame, \n",
    "        column: str\n",
    "    ) -> List[ValidationIssue]:\n",
    "        \"\"\"\n",
    "        Detecta valores que son NULL sem√°nticamente (N/A, Unknown, TBD, etc.)\n",
    "        pero no NULL sint√°cticamente.\n",
    "        \"\"\"\n",
    "        # Obtener valores √∫nicos no-null\n",
    "        non_null_values = df[column].dropna().unique()[:50]  # Limitar muestra\n",
    "        \n",
    "        prompt = f\"\"\"Analiza estos valores de la columna '{column}' y detecta cu√°les son NULL sem√°nticos (representan faltante/desconocido/no aplicable):\n",
    "\n",
    "Valores: {list(non_null_values)}\n",
    "\n",
    "Responde en JSON:\n",
    "{{\n",
    "  \"semantic_nulls\": [\"valor1\", \"valor2\", ...],\n",
    "  \"confidence\": 0.0-1.0,\n",
    "  \"reasoning\": \"explicaci√≥n breve\"\n",
    "}}\"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=self.model,\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                temperature=0,\n",
    "                response_format={\"type\": \"json_object\"}\n",
    "            )\n",
    "            \n",
    "            result = json.loads(response.choices[0].message.content)\n",
    "            \n",
    "            # Calcular costo aproximado (gpt-4o-mini: $0.15/$0.60 por 1M tokens)\n",
    "            input_tokens = len(prompt) / 4  # Aproximaci√≥n\n",
    "            output_tokens = len(response.choices[0].message.content) / 4\n",
    "            cost = (input_tokens / 1_000_000 * 0.15) + (output_tokens / 1_000_000 * 0.60)\n",
    "            self.total_cost += cost\n",
    "            \n",
    "            # Crear issues para cada NULL sem√°ntico\n",
    "            issues = []\n",
    "            for null_value in result.get(\"semantic_nulls\", []):\n",
    "                mask = df[column] == null_value\n",
    "                for idx in df[mask].index[:100]:\n",
    "                    issues.append(ValidationIssue(\n",
    "                        column=column,\n",
    "                        row_index=int(idx),\n",
    "                        value=str(null_value),\n",
    "                        issue_type=\"SEMANTIC_NULL\",\n",
    "                        severity=ValidationSeverity.WARNING,\n",
    "                        confidence=result.get(\"confidence\", 0.8),\n",
    "                        description=f\"'{null_value}' es NULL sem√°ntico: {result.get('reasoning', '')}\",\n",
    "                        suggested_fix=\"Convertir a NULL expl√≠cito\",\n",
    "                        detected_by=\"llm\"\n",
    "                    ))\n",
    "            \n",
    "            return issues\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error en LLM validation: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def check_plausibility(\n",
    "        self, \n",
    "        df: pd.DataFrame, \n",
    "        column: str, \n",
    "        context: str = \"\"\n",
    "    ) -> List[ValidationIssue]:\n",
    "        \"\"\"\n",
    "        Valida plausibilidad de valores (ej. emails fake, ciudades con typos).\n",
    "        \"\"\"\n",
    "        sample_values = df[column].dropna().head(20).tolist()\n",
    "        \n",
    "        prompt = f\"\"\"Analiza la plausibilidad de estos valores en la columna '{column}':\n",
    "\n",
    "Contexto: {context}\n",
    "Valores: {sample_values}\n",
    "\n",
    "Detecta valores implausibles (fake, typos, test data, etc.).\n",
    "\n",
    "Responde en JSON:\n",
    "{{\n",
    "  \"implausible_values\": [\n",
    "    {{\n",
    "      \"value\": \"valor\",\n",
    "      \"reason\": \"explicaci√≥n\",\n",
    "      \"confidence\": 0.0-1.0,\n",
    "      \"suggested_fix\": \"correcci√≥n o null\"\n",
    "    }}\n",
    "  ]\n",
    "}}\"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=self.model,\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                temperature=0,\n",
    "                response_format={\"type\": \"json_object\"}\n",
    "            )\n",
    "            \n",
    "            result = json.loads(response.choices[0].message.content)\n",
    "            \n",
    "            # Costo\n",
    "            cost = (len(prompt) / 4 / 1_000_000 * 0.15) + (len(response.choices[0].message.content) / 4 / 1_000_000 * 0.60)\n",
    "            self.total_cost += cost\n",
    "            \n",
    "            issues = []\n",
    "            for item in result.get(\"implausible_values\", []):\n",
    "                mask = df[column] == item[\"value\"]\n",
    "                for idx in df[mask].index:\n",
    "                    issues.append(ValidationIssue(\n",
    "                        column=column,\n",
    "                        row_index=int(idx),\n",
    "                        value=str(item[\"value\"]),\n",
    "                        issue_type=\"IMPLAUSIBLE\",\n",
    "                        severity=ValidationSeverity.WARNING,\n",
    "                        confidence=item.get(\"confidence\", 0.7),\n",
    "                        description=f\"Valor implausible: {item.get('reason', '')}\",\n",
    "                        suggested_fix=item.get(\"suggested_fix\"),\n",
    "                        detected_by=\"llm\"\n",
    "                    ))\n",
    "            \n",
    "            return issues\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error en plausibility check: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def explain_outlier(\n",
    "        self, \n",
    "        value: float, \n",
    "        column: str,\n",
    "        stats: Dict[str, float]\n",
    "    ) -> str:\n",
    "        \"\"\"Explica por qu√© un valor es outlier en lenguaje natural.\"\"\"\n",
    "        prompt = f\"\"\"Explica por qu√© este valor es an√≥malo en 2-3 frases:\n",
    "\n",
    "Columna: {column}\n",
    "Valor: {value}\n",
    "\n",
    "Estad√≠sticas:\n",
    "- Media: {stats['mean']:.2f}\n",
    "- Desv. est√°ndar: {stats['std']:.2f}\n",
    "- Min: {stats['min']:.2f}\n",
    "- Max (sin este): {stats['max']:.2f}\n",
    "- Percentil 99: {stats.get('p99', 'N/A')}\n",
    "\n",
    "Incluye posible causa ra√≠z (typo, error de medici√≥n, evento real extremo, etc.).\"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=self.model,\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                temperature=0.3\n",
    "            )\n",
    "            \n",
    "            cost = (len(prompt) / 4 / 1_000_000 * 0.15) + (len(response.choices[0].message.content) / 4 / 1_000_000 * 0.60)\n",
    "            self.total_cost += cost\n",
    "            \n",
    "            return response.choices[0].message.content.strip()\n",
    "            \n",
    "        except Exception as e:\n",
    "            return f\"Error generando explicaci√≥n: {e}\"\n",
    "\n",
    "# 4. VALIDADOR H√çBRIDO (COMBINA AMBOS)\n",
    "\n",
    "class HybridValidator:\n",
    "    \"\"\"Sistema h√≠brido: Traditional (r√°pido) + LLM (sem√°ntico).\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.traditional = TraditionalValidator()\n",
    "        self.llm = LLMValidator()\n",
    "    \n",
    "    def validate_dataframe(\n",
    "        self, \n",
    "        df: pd.DataFrame, \n",
    "        table_name: str,\n",
    "        validation_config: Dict\n",
    "    ) -> ValidationReport:\n",
    "        \"\"\"\n",
    "        Valida DataFrame completo con estrategia h√≠brida.\n",
    "        \n",
    "        Args:\n",
    "            df: DataFrame a validar\n",
    "            table_name: nombre de la tabla\n",
    "            validation_config: configuraci√≥n por columna\n",
    "                {\n",
    "                    \"column_name\": {\n",
    "                        \"checks\": [\"nulls\", \"range\", \"semantic_nulls\", \"plausibility\"],\n",
    "                        \"range\": [0, 120],\n",
    "                        \"context\": \"descripci√≥n para LLM\"\n",
    "                    }\n",
    "                }\n",
    "        \"\"\"\n",
    "        import time\n",
    "        start_time = time.time()\n",
    "        \n",
    "        all_issues = []\n",
    "        \n",
    "        for column, config in validation_config.items():\n",
    "            if column not in df.columns:\n",
    "                continue\n",
    "            \n",
    "            checks = config.get(\"checks\", [])\n",
    "            \n",
    "            # TRADITIONAL CHECKS (siempre primero - r√°pidos)\n",
    "            if \"nulls\" in checks:\n",
    "                all_issues.extend(self.traditional.check_nulls(df, column))\n",
    "            \n",
    "            if \"range\" in checks and \"range\" in config:\n",
    "                min_val, max_val = config[\"range\"]\n",
    "                all_issues.extend(self.traditional.check_range(df, column, min_val, max_val))\n",
    "            \n",
    "            if \"regex\" in checks and \"pattern\" in config:\n",
    "                all_issues.extend(self.traditional.check_regex(df, column, config[\"pattern\"]))\n",
    "            \n",
    "            # LLM CHECKS (solo si hay issues o configurado expl√≠citamente)\n",
    "            if \"semantic_nulls\" in checks:\n",
    "                all_issues.extend(self.llm.check_semantic_nulls(df, column))\n",
    "            \n",
    "            if \"plausibility\" in checks:\n",
    "                context = config.get(\"context\", f\"Columna {column}\")\n",
    "                all_issues.extend(self.llm.check_plausibility(df, column, context))\n",
    "        \n",
    "        # Generar reporte\n",
    "        execution_time = time.time() - start_time\n",
    "        \n",
    "        issues_by_severity = {\n",
    "            severity: sum(1 for issue in all_issues if issue.severity == severity)\n",
    "            for severity in ValidationSeverity\n",
    "        }\n",
    "        \n",
    "        report = ValidationReport(\n",
    "            table_name=table_name,\n",
    "            total_rows=len(df),\n",
    "            total_issues=len(all_issues),\n",
    "            issues_by_severity=issues_by_severity,\n",
    "            issues=all_issues,\n",
    "            execution_time_seconds=execution_time,\n",
    "            cost_usd=self.llm.total_cost\n",
    "        )\n",
    "        \n",
    "        return report\n",
    "\n",
    "# EJEMPLO DE USO\n",
    "\n",
    "# Dataset de prueba con varios tipos de problemas\n",
    "df_test = pd.DataFrame({\n",
    "    'customer_id': [1, 2, 3, 4, 5, 6, 7, 8],\n",
    "    'age': [25, 30, 999, 45, None, 22, -5, 150],  # Outliers, null, negativos\n",
    "    'email': [\n",
    "        'user@example.com',\n",
    "        'admin@test.test',  # Fake\n",
    "        'invalid-email',     # Inv√°lido\n",
    "        'test@test.com',     # Test data\n",
    "        None,\n",
    "        'real@company.io',\n",
    "        'N/A',               # NULL sem√°ntico\n",
    "        'john@gmail.com'\n",
    "    ],\n",
    "    'city': [\n",
    "        'New York',\n",
    "        'Nueva Yorkk',  # Typo\n",
    "        'Los Angeles',\n",
    "        'Unknown',      # NULL sem√°ntico\n",
    "        'San Francisco',\n",
    "        'N/A',          # NULL sem√°ntico\n",
    "        'Chicago',\n",
    "        'TBD'           # NULL sem√°ntico\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Configuraci√≥n de validaci√≥n\n",
    "validation_config = {\n",
    "    'age': {\n",
    "        'checks': ['nulls', 'range'],\n",
    "        'range': [0, 120]\n",
    "    },\n",
    "    'email': {\n",
    "        'checks': ['nulls', 'regex', 'plausibility'],\n",
    "        'pattern': r'^[\\w\\.-]+@[\\w\\.-]+\\.\\w+$',\n",
    "        'context': 'Emails de clientes reales (no test data)'\n",
    "    },\n",
    "    'city': {\n",
    "        'checks': ['semantic_nulls', 'plausibility'],\n",
    "        'context': 'Ciudades de USA'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Ejecutar validaci√≥n h√≠brida\n",
    "validator = HybridValidator()\n",
    "report = validator.validate_dataframe(df_test, 'customers', validation_config)\n",
    "\n",
    "# Mostrar resultados\n",
    "print(f\"üìä REPORTE DE VALIDACI√ìN: {report.table_name}\")\n",
    "print(f\"   Total filas: {report.total_rows}\")\n",
    "print(f\"   Total issues: {report.total_issues}\")\n",
    "print(f\"   Tiempo: {report.execution_time_seconds:.2f}s\")\n",
    "print(f\"   Costo LLM: ${report.cost_usd:.4f}\")\n",
    "print(f\"\\n   Issues por severidad:\")\n",
    "for severity, count in report.issues_by_severity.items():\n",
    "    if count > 0:\n",
    "        print(f\"     {severity.value}: {count}\")\n",
    "\n",
    "print(f\"\\nüîç ISSUES DETECTADOS (top 10):\")\n",
    "for i, issue in enumerate(report.issues[:10], 1):\n",
    "    print(f\"\\n{i}. [{issue.severity.value}] {issue.issue_type}\")\n",
    "    print(f\"   Columna: {issue.column}, Fila: {issue.row_index}\")\n",
    "    print(f\"   Valor: {issue.value}\")\n",
    "    print(f\"   {issue.description}\")\n",
    "    print(f\"   Confianza: {issue.confidence:.0%} | Detectado por: {issue.detected_by}\")\n",
    "    if issue.suggested_fix:\n",
    "        print(f\"   üí° Fix sugerido: {issue.suggested_fix}\")\n",
    "```\n",
    "\n",
    "### üìä Comparaci√≥n de Performance\n",
    "\n",
    "```python\n",
    "import time\n",
    "\n",
    "# Benchmark: Traditional vs LLM\n",
    "df_large = pd.DataFrame({\n",
    "    'age': np.random.randint(18, 70, size=10000),\n",
    "    'email': ['user{}@example.com'.format(i) for i in range(10000)]\n",
    "})\n",
    "\n",
    "# Traditional validation\n",
    "start = time.time()\n",
    "trad_validator = TraditionalValidator()\n",
    "trad_issues = trad_validator.check_range(df_large, 'age', 0, 120)\n",
    "trad_time = time.time() - start\n",
    "\n",
    "print(f\"Traditional: {trad_time*1000:.2f}ms, {len(trad_issues)} issues, $0\")\n",
    "\n",
    "# LLM validation (solo muestra)\n",
    "start = time.time()\n",
    "llm_validator = LLMValidator()\n",
    "llm_issues = llm_validator.check_plausibility(df_large.head(20), 'email', 'Customer emails')\n",
    "llm_time = time.time() - start\n",
    "\n",
    "print(f\"LLM: {llm_time*1000:.2f}ms, {len(llm_issues)} issues, ${llm_validator.total_cost:.4f}\")\n",
    "print(f\"\\nüí° LLM es {llm_time/trad_time:.0f}x m√°s lento pero detecta issues sem√°nticos\")\n",
    "```\n",
    "\n",
    "### üéØ Estrategia de Uso √ìptima\n",
    "\n",
    "```python\n",
    "# REGLA DE ORO: H√≠brido inteligente\n",
    "\n",
    "# 1. TRADITIONAL FIRST (always)\n",
    "#    - R√°pido, gratis, confiable\n",
    "#    - Cubre 80% de casos\n",
    "\n",
    "# 2. LLM IF:\n",
    "#    a) Traditional encontr√≥ issues ambiguos\n",
    "#    b) Columnas cr√≠ticas (PII, identificadores, nombres)\n",
    "#    c) Sample peque√±o (<1000 registros √∫nicos)\n",
    "#    d) Budget disponible ($0.01-$0.10 por tabla)\n",
    "\n",
    "# Ejemplo de decisi√≥n:\n",
    "def should_use_llm(df: pd.DataFrame, column: str, trad_issues: int) -> bool:\n",
    "    \"\"\"Decide si vale la pena usar LLM.\"\"\"\n",
    "    unique_count = df[column].nunique()\n",
    "    \n",
    "    # Criterios para usar LLM:\n",
    "    if trad_issues > 0 and trad_issues < 100:  # Issues moderados\n",
    "        return True\n",
    "    \n",
    "    if unique_count < 100:  # Pocos valores √∫nicos (categ√≥ricos)\n",
    "        return True\n",
    "    \n",
    "    if column in ['email', 'name', 'city', 'address']:  # Campos cr√≠ticos\n",
    "        return True\n",
    "    \n",
    "    return False\n",
    "```\n",
    "\n",
    "### üöÄ Mejores Pr√°cticas\n",
    "\n",
    "1. **Siempre traditional primero**: Fast fail para issues obvios\n",
    "2. **LLM como segunda capa**: Solo para casos ambiguos o sem√°nticos\n",
    "3. **Cache agresivo**: Mismos valores ‚Üí misma respuesta (lru_cache)\n",
    "4. **Batch validation**: Validar m√∫ltiples valores en un solo prompt\n",
    "5. **Confidence thresholds**: Solo actuar si confidence >0.8\n",
    "6. **Human review**: Issues con confidence <0.9 requieren revisi√≥n\n",
    "7. **Cost monitoring**: Alertar si costo >$1 por tabla\n",
    "8. **A/B testing**: Comparar LLM vs tradicional en m√©tricas de negocio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb72719",
   "metadata": {},
   "source": [
    "## ü§ñ Generaci√≥n Autom√°tica de Reglas de Validaci√≥n con LLMs\n",
    "\n",
    "Escribir reglas de validaci√≥n manualmente es tedioso y propenso a errores. Los **LLMs** pueden **inferir reglas de validaci√≥n** analizando datos y generando c√≥digo de Great Expectations, dbt tests, o Pandas assertions autom√°ticamente.\n",
    "\n",
    "### üèóÔ∏è Arquitectura de Auto-Generaci√≥n de Reglas\n",
    "\n",
    "```\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ      AUTO-GENERATION: FROM DATA TO VALIDATION RULES              ‚îÇ\n",
    "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
    "‚îÇ                                                                  ‚îÇ\n",
    "‚îÇ  INPUT: DataFrame con datos hist√≥ricos                          ‚îÇ\n",
    "‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ\n",
    "‚îÇ  ‚îÇ df['age']: [25, 30, 45, 22, 28, ...]                     ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ df['email']: ['user@x.com', 'admin@y.org', ...]          ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ df['status']: ['active', 'active', 'inactive', ...]      ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ\n",
    "‚îÇ        ‚Üì                                                         ‚îÇ\n",
    "‚îÇ  1Ô∏è‚É£ PROFILE DATA (EDA autom√°tico)                              ‚îÇ\n",
    "‚îÇ     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îÇ\n",
    "‚îÇ     ‚îÇ pandas-profiling / ydata-profiling                 ‚îÇ      ‚îÇ\n",
    "‚îÇ     ‚îÇ ‚Ä¢ Tipos de datos (int, str, datetime)             ‚îÇ      ‚îÇ\n",
    "‚îÇ     ‚îÇ ‚Ä¢ Distribuciones (mean, std, quantiles)           ‚îÇ      ‚îÇ\n",
    "‚îÇ     ‚îÇ ‚Ä¢ Valores √∫nicos y frecuencias                    ‚îÇ      ‚îÇ\n",
    "‚îÇ     ‚îÇ ‚Ä¢ Nulls, duplicates, outliers                     ‚îÇ      ‚îÇ\n",
    "‚îÇ     ‚îÇ ‚Ä¢ Correlaciones entre columnas                    ‚îÇ      ‚îÇ\n",
    "‚îÇ     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ\n",
    "‚îÇ        ‚Üì                                                         ‚îÇ\n",
    "‚îÇ  2Ô∏è‚É£ INFER RULES (LLM analiza profile)                          ‚îÇ\n",
    "‚îÇ     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îÇ\n",
    "‚îÇ     ‚îÇ Prompt: \"Bas√°ndote en estas estad√≠sticas,         ‚îÇ      ‚îÇ\n",
    "‚îÇ     ‚îÇ          genera reglas de validaci√≥n...\"           ‚îÇ      ‚îÇ\n",
    "‚îÇ     ‚îÇ                                                    ‚îÇ      ‚îÇ\n",
    "‚îÇ     ‚îÇ LLM ‚Üí Reglas inferidas:                           ‚îÇ      ‚îÇ\n",
    "‚îÇ     ‚îÇ  age:                                              ‚îÇ      ‚îÇ\n",
    "‚îÇ     ‚îÇ    - No NULL (0% nulls observed)                  ‚îÇ      ‚îÇ\n",
    "‚îÇ     ‚îÇ    - Range [18, 65] (min=18, max=65, no outliers)‚îÇ      ‚îÇ\n",
    "‚îÇ     ‚îÇ    - Integer type                                 ‚îÇ      ‚îÇ\n",
    "‚îÇ     ‚îÇ                                                    ‚îÇ      ‚îÇ\n",
    "‚îÇ     ‚îÇ  email:                                            ‚îÇ      ‚îÇ\n",
    "‚îÇ     ‚îÇ    - Match regex ^[\\w.-]+@[\\w.-]+\\.\\w+$          ‚îÇ      ‚îÇ\n",
    "‚îÇ     ‚îÇ    - No duplicates (100% unique)                  ‚îÇ      ‚îÇ\n",
    "‚îÇ     ‚îÇ    - Max length 100 chars                         ‚îÇ      ‚îÇ\n",
    "‚îÇ     ‚îÇ                                                    ‚îÇ      ‚îÇ\n",
    "‚îÇ     ‚îÇ  status:                                           ‚îÇ      ‚îÇ\n",
    "‚îÇ     ‚îÇ    - IN ['active', 'inactive', 'pending']         ‚îÇ      ‚îÇ\n",
    "‚îÇ     ‚îÇ    - No NULL (0% nulls)                           ‚îÇ      ‚îÇ\n",
    "‚îÇ     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ\n",
    "‚îÇ        ‚Üì                                                         ‚îÇ\n",
    "‚îÇ  3Ô∏è‚É£ GENERATE CODE (Target framework)                           ‚îÇ\n",
    "‚îÇ     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îÇ\n",
    "‚îÇ     ‚îÇ Great Expectations:                                ‚îÇ      ‚îÇ\n",
    "‚îÇ     ‚îÇ ```python                                          ‚îÇ      ‚îÇ\n",
    "‚îÇ     ‚îÇ suite.expect_column_values_to_not_be_null('age')  ‚îÇ      ‚îÇ\n",
    "‚îÇ     ‚îÇ suite.expect_column_values_to_be_between(         ‚îÇ      ‚îÇ\n",
    "‚îÇ     ‚îÇ     'age', min_value=18, max_value=65)            ‚îÇ      ‚îÇ\n",
    "‚îÇ     ‚îÇ suite.expect_column_values_to_match_regex(        ‚îÇ      ‚îÇ\n",
    "‚îÇ     ‚îÇ     'email', regex='^[\\w.-]+@[\\w.-]+\\.\\w+$')     ‚îÇ      ‚îÇ\n",
    "‚îÇ     ‚îÇ ```                                                ‚îÇ      ‚îÇ\n",
    "‚îÇ     ‚îÇ                                                    ‚îÇ      ‚îÇ\n",
    "‚îÇ     ‚îÇ dbt tests:                                         ‚îÇ      ‚îÇ\n",
    "‚îÇ     ‚îÇ ```yaml                                            ‚îÇ      ‚îÇ\n",
    "‚îÇ     ‚îÇ - name: age                                        ‚îÇ      ‚îÇ\n",
    "‚îÇ     ‚îÇ   tests:                                           ‚îÇ      ‚îÇ\n",
    "‚îÇ     ‚îÇ     - not_null                                     ‚îÇ      ‚îÇ\n",
    "‚îÇ     ‚îÇ     - dbt_utils.accepted_range:                   ‚îÇ      ‚îÇ\n",
    "‚îÇ     ‚îÇ         min_value: 18                              ‚îÇ      ‚îÇ\n",
    "‚îÇ     ‚îÇ         max_value: 65                              ‚îÇ      ‚îÇ\n",
    "‚îÇ     ‚îÇ ```                                                ‚îÇ      ‚îÇ\n",
    "‚îÇ     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ\n",
    "‚îÇ        ‚Üì                                                         ‚îÇ\n",
    "‚îÇ  4Ô∏è‚É£ VALIDATE & REFINE                                          ‚îÇ\n",
    "‚îÇ     - Ejecutar reglas contra datos nuevos                       ‚îÇ\n",
    "‚îÇ     - Si >5% false positives ‚Üí Ajustar thresholds               ‚îÇ\n",
    "‚îÇ     - Human review de reglas generadas                          ‚îÇ\n",
    "‚îÇ        ‚Üì                                                         ‚îÇ\n",
    "‚îÇ  OUTPUT: Validation suite lista para producci√≥n                 ‚îÇ\n",
    "‚îÇ                                                                  ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "```\n",
    "\n",
    "### üîß Implementaci√≥n Completa\n",
    "\n",
    "```python\n",
    "from typing import Dict, List, Optional\n",
    "from pydantic import BaseModel\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "import json\n",
    "\n",
    "client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))\n",
    "\n",
    "# 1. DATA PROFILER\n",
    "\n",
    "class ColumnProfile(BaseModel):\n",
    "    \"\"\"Profile estad√≠stico de una columna.\"\"\"\n",
    "    name: str\n",
    "    dtype: str\n",
    "    count: int\n",
    "    null_count: int\n",
    "    null_percentage: float\n",
    "    unique_count: int\n",
    "    unique_percentage: float\n",
    "    \n",
    "    # Num√©rico\n",
    "    mean: Optional[float] = None\n",
    "    std: Optional[float] = None\n",
    "    min: Optional[float] = None\n",
    "    max: Optional[float] = None\n",
    "    q25: Optional[float] = None\n",
    "    q50: Optional[float] = None\n",
    "    q75: Optional[float] = None\n",
    "    \n",
    "    # String\n",
    "    avg_length: Optional[float] = None\n",
    "    max_length: Optional[int] = None\n",
    "    \n",
    "    # Categorical\n",
    "    top_values: Optional[Dict[str, int]] = None\n",
    "    \n",
    "    # Ejemplos\n",
    "    sample_values: List[str] = []\n",
    "\n",
    "class DataProfiler:\n",
    "    \"\"\"Genera profile estad√≠stico de DataFrame.\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def profile_column(df: pd.DataFrame, column: str) -> ColumnProfile:\n",
    "        \"\"\"Genera profile de una columna.\"\"\"\n",
    "        col_data = df[column]\n",
    "        \n",
    "        profile = ColumnProfile(\n",
    "            name=column,\n",
    "            dtype=str(col_data.dtype),\n",
    "            count=len(col_data),\n",
    "            null_count=int(col_data.isnull().sum()),\n",
    "            null_percentage=float(col_data.isnull().mean()),\n",
    "            unique_count=int(col_data.nunique()),\n",
    "            unique_percentage=float(col_data.nunique() / len(col_data)),\n",
    "            sample_values=[str(v) for v in col_data.dropna().head(5).tolist()]\n",
    "        )\n",
    "        \n",
    "        # Stats num√©ricos\n",
    "        if pd.api.types.is_numeric_dtype(col_data):\n",
    "            profile.mean = float(col_data.mean())\n",
    "            profile.std = float(col_data.std())\n",
    "            profile.min = float(col_data.min())\n",
    "            profile.max = float(col_data.max())\n",
    "            profile.q25 = float(col_data.quantile(0.25))\n",
    "            profile.q50 = float(col_data.quantile(0.50))\n",
    "            profile.q75 = float(col_data.quantile(0.75))\n",
    "        \n",
    "        # Stats string\n",
    "        if pd.api.types.is_string_dtype(col_data) or col_data.dtype == 'object':\n",
    "            str_lengths = col_data.dropna().astype(str).str.len()\n",
    "            if len(str_lengths) > 0:\n",
    "                profile.avg_length = float(str_lengths.mean())\n",
    "                profile.max_length = int(str_lengths.max())\n",
    "        \n",
    "        # Top values (para categ√≥ricas)\n",
    "        if profile.unique_count <= 50:  # Considerar categ√≥rica si <50 √∫nicos\n",
    "            value_counts = col_data.value_counts().head(10)\n",
    "            profile.top_values = {str(k): int(v) for k, v in value_counts.items()}\n",
    "        \n",
    "        return profile\n",
    "    \n",
    "    @staticmethod\n",
    "    def profile_dataframe(df: pd.DataFrame) -> Dict[str, ColumnProfile]:\n",
    "        \"\"\"Genera profiles de todas las columnas.\"\"\"\n",
    "        return {\n",
    "            col: DataProfiler.profile_column(df, col) \n",
    "            for col in df.columns\n",
    "        }\n",
    "\n",
    "# 2. RULE GENERATOR\n",
    "\n",
    "class ValidationRule(BaseModel):\n",
    "    \"\"\"Regla de validaci√≥n generada.\"\"\"\n",
    "    column: str\n",
    "    rule_type: str  # not_null, range, regex, in_set, unique, etc.\n",
    "    parameters: Dict\n",
    "    confidence: float\n",
    "    reasoning: str\n",
    "    great_expectations_code: str\n",
    "    dbt_test_yaml: str\n",
    "    pandas_assertion: str\n",
    "\n",
    "class RuleGenerator:\n",
    "    \"\"\"Genera reglas de validaci√≥n usando LLM.\"\"\"\n",
    "    \n",
    "    def __init__(self, model: str = \"gpt-4o\"):\n",
    "        self.model = model\n",
    "    \n",
    "    def generate_rules(\n",
    "        self, \n",
    "        profile: ColumnProfile,\n",
    "        business_context: Optional[str] = None\n",
    "    ) -> List[ValidationRule]:\n",
    "        \"\"\"\n",
    "        Genera reglas de validaci√≥n para una columna.\n",
    "        \n",
    "        Args:\n",
    "            profile: profile estad√≠stico de la columna\n",
    "            business_context: contexto de negocio opcional\n",
    "        \n",
    "        Returns:\n",
    "            Lista de reglas de validaci√≥n\n",
    "        \"\"\"\n",
    "        prompt = f\"\"\"Analiza este profile de columna y genera reglas de validaci√≥n apropiadas:\n",
    "\n",
    "COLUMNA: {profile.name}\n",
    "TIPO: {profile.dtype}\n",
    "REGISTROS: {profile.count}\n",
    "NULLS: {profile.null_count} ({profile.null_percentage:.1%})\n",
    "√öNICOS: {profile.unique_count} ({profile.unique_percentage:.1%})\n",
    "\n",
    "{\"ESTAD√çSTICAS NUM√âRICAS:\" if profile.mean is not None else \"\"}\n",
    "{f\"- Mean: {profile.mean:.2f}\" if profile.mean is not None else \"\"}\n",
    "{f\"- Std: {profile.std:.2f}\" if profile.std is not None else \"\"}\n",
    "{f\"- Range: [{profile.min}, {profile.max}]\" if profile.min is not None else \"\"}\n",
    "{f\"- Q25/Q50/Q75: {profile.q25:.2f}/{profile.q50:.2f}/{profile.q75:.2f}\" if profile.q25 is not None else \"\"}\n",
    "\n",
    "{\"ESTAD√çSTICAS STRING:\" if profile.avg_length is not None else \"\"}\n",
    "{f\"- Avg length: {profile.avg_length:.1f}\" if profile.avg_length is not None else \"\"}\n",
    "{f\"- Max length: {profile.max_length}\" if profile.max_length is not None else \"\"}\n",
    "\n",
    "{\"TOP VALUES:\" if profile.top_values else \"\"}\n",
    "{json.dumps(profile.top_values, indent=2) if profile.top_values else \"\"}\n",
    "\n",
    "EJEMPLOS: {profile.sample_values}\n",
    "\n",
    "{f\"CONTEXTO DE NEGOCIO: {business_context}\" if business_context else \"\"}\n",
    "\n",
    "Genera 2-5 reglas de validaci√≥n apropiadas. Para cada regla, incluye:\n",
    "1. Tipo de regla (not_null, range, regex, in_set, unique, etc.)\n",
    "2. Par√°metros de la regla\n",
    "3. Confianza (0.0-1.0) basada en qu√© tan claro es el patr√≥n\n",
    "4. Razonamiento (por qu√© esta regla tiene sentido)\n",
    "5. C√≥digo de Great Expectations\n",
    "6. dbt test en YAML\n",
    "7. Assertion de Pandas\n",
    "\n",
    "Responde en JSON:\n",
    "{{\n",
    "  \"rules\": [\n",
    "    {{\n",
    "      \"rule_type\": \"...\",\n",
    "      \"parameters\": {{}},\n",
    "      \"confidence\": 0.0-1.0,\n",
    "      \"reasoning\": \"...\",\n",
    "      \"great_expectations_code\": \"suite.expect_...\",\n",
    "      \"dbt_test_yaml\": \"- name: ...\\\\n  tests: ...\",\n",
    "      \"pandas_assertion\": \"assert ...\"\n",
    "    }}\n",
    "  ]\n",
    "}}\"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=self.model,\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                temperature=0.2,  # Algo de creatividad pero no mucho\n",
    "                response_format={\"type\": \"json_object\"}\n",
    "            )\n",
    "            \n",
    "            result = json.loads(response.choices[0].message.content)\n",
    "            \n",
    "            rules = []\n",
    "            for rule_data in result.get(\"rules\", []):\n",
    "                rules.append(ValidationRule(\n",
    "                    column=profile.name,\n",
    "                    rule_type=rule_data[\"rule_type\"],\n",
    "                    parameters=rule_data[\"parameters\"],\n",
    "                    confidence=rule_data[\"confidence\"],\n",
    "                    reasoning=rule_data[\"reasoning\"],\n",
    "                    great_expectations_code=rule_data[\"great_expectations_code\"],\n",
    "                    dbt_test_yaml=rule_data[\"dbt_test_yaml\"],\n",
    "                    pandas_assertion=rule_data[\"pandas_assertion\"]\n",
    "                ))\n",
    "            \n",
    "            return rules\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error generando reglas: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def generate_table_validation_suite(\n",
    "        self,\n",
    "        df: pd.DataFrame,\n",
    "        table_name: str,\n",
    "        business_context: Optional[Dict[str, str]] = None\n",
    "    ) -> Dict[str, List[ValidationRule]]:\n",
    "        \"\"\"\n",
    "        Genera suite completo de validaci√≥n para tabla.\n",
    "        \n",
    "        Args:\n",
    "            df: DataFrame a analizar\n",
    "            table_name: nombre de la tabla\n",
    "            business_context: diccionario {columna: contexto}\n",
    "        \n",
    "        Returns:\n",
    "            Diccionario {columna: [reglas]}\n",
    "        \"\"\"\n",
    "        print(f\"üîç Generando validation suite para tabla '{table_name}'...\")\n",
    "        \n",
    "        # Profile todas las columnas\n",
    "        profiler = DataProfiler()\n",
    "        profiles = profiler.profile_dataframe(df)\n",
    "        \n",
    "        # Generar reglas para cada columna\n",
    "        all_rules = {}\n",
    "        business_context = business_context or {}\n",
    "        \n",
    "        for column, profile in profiles.items():\n",
    "            print(f\"  Analizando columna '{column}'...\")\n",
    "            \n",
    "            context = business_context.get(column, \"\")\n",
    "            rules = self.generate_rules(profile, context)\n",
    "            \n",
    "            all_rules[column] = rules\n",
    "            print(f\"    ‚úì {len(rules)} reglas generadas\")\n",
    "        \n",
    "        return all_rules\n",
    "\n",
    "# 3. GENERADOR DE C√ìDIGO EJECUTABLE\n",
    "\n",
    "class CodeGenerator:\n",
    "    \"\"\"Genera c√≥digo ejecutable de frameworks populares.\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def generate_great_expectations_suite(\n",
    "        rules_by_column: Dict[str, List[ValidationRule]],\n",
    "        suite_name: str\n",
    "    ) -> str:\n",
    "        \"\"\"Genera c√≥digo de Great Expectations.\"\"\"\n",
    "        code = f'''\"\"\"\n",
    "Auto-generated Great Expectations suite: {suite_name}\n",
    "Generated by LLM-powered rule generator\n",
    "\"\"\"\n",
    "\n",
    "import great_expectations as gx\n",
    "from great_expectations.core.batch import RuntimeBatchRequest\n",
    "\n",
    "# Create expectation suite\n",
    "context = gx.get_context()\n",
    "suite = context.add_expectation_suite(\n",
    "    expectation_suite_name=\"{suite_name}\",\n",
    "    overwrite_existing=True\n",
    ")\n",
    "\n",
    "# Expectations by column\n",
    "'''\n",
    "        \n",
    "        for column, rules in rules_by_column.items():\n",
    "            code += f\"\\n# {column}\\n\"\n",
    "            for rule in rules:\n",
    "                code += f\"# Confidence: {rule.confidence:.0%} - {rule.reasoning}\\n\"\n",
    "                code += f\"{rule.great_expectations_code}\\n\"\n",
    "        \n",
    "        code += '''\n",
    "# Save suite\n",
    "context.add_or_update_expectation_suite(expectation_suite=suite)\n",
    "\n",
    "print(f\"‚úì Suite '{suite_name}' created with {len(suite.expectations)} expectations\")\n",
    "'''\n",
    "        \n",
    "        return code\n",
    "    \n",
    "    @staticmethod\n",
    "    def generate_dbt_schema_yml(\n",
    "        rules_by_column: Dict[str, List[ValidationRule]],\n",
    "        model_name: str\n",
    "    ) -> str:\n",
    "        \"\"\"Genera archivo schema.yml de dbt.\"\"\"\n",
    "        yml = f'''version: 2\n",
    "\n",
    "models:\n",
    "  - name: {model_name}\n",
    "    description: \"Auto-generated dbt tests\"\n",
    "    columns:\n",
    "'''\n",
    "        \n",
    "        for column, rules in rules_by_column.items():\n",
    "            yml += f\"      - name: {column}\\n\"\n",
    "            yml += \"        tests:\\n\"\n",
    "            \n",
    "            for rule in rules:\n",
    "                # Parsear YAML del rule (simplificado)\n",
    "                yml += f\"          # Confidence: {rule.confidence:.0%} - {rule.reasoning}\\n\"\n",
    "                yml += f\"          {rule.dbt_test_yaml}\\n\"\n",
    "        \n",
    "        return yml\n",
    "    \n",
    "    @staticmethod\n",
    "    def generate_pandas_validation_script(\n",
    "        rules_by_column: Dict[str, List[ValidationRule]],\n",
    "        script_name: str\n",
    "    ) -> str:\n",
    "        \"\"\"Genera script de validaci√≥n con Pandas.\"\"\"\n",
    "        code = f'''\"\"\"\n",
    "Auto-generated Pandas validation script: {script_name}\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "def validate_dataframe(df: pd.DataFrame) -> bool:\n",
    "    \"\"\"Valida DataFrame contra reglas generadas.\"\"\"\n",
    "    errors = []\n",
    "    \n",
    "'''\n",
    "        \n",
    "        for column, rules in rules_by_column.items():\n",
    "            code += f\"    # Validar columna '{column}'\\n\"\n",
    "            for rule in rules:\n",
    "                code += f\"    # {rule.reasoning} (confidence: {rule.confidence:.0%})\\n\"\n",
    "                code += f\"    try:\\n\"\n",
    "                code += f\"        {rule.pandas_assertion}\\n\"\n",
    "                code += f\"    except AssertionError as e:\\n\"\n",
    "                code += f\"        errors.append('{column}: {{e}}')\\n\"\n",
    "                code += f\"\\n\"\n",
    "        \n",
    "        code += '''    \n",
    "    if errors:\n",
    "        print(f\"‚ùå Validation failed with {len(errors)} errors:\")\n",
    "        for error in errors:\n",
    "            print(f\"  - {error}\")\n",
    "        return False\n",
    "    \n",
    "    print(\"‚úÖ All validations passed!\")\n",
    "    return True\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Cargar datos\n",
    "    df = pd.read_csv(\"data.csv\")\n",
    "    \n",
    "    # Validar\n",
    "    success = validate_dataframe(df)\n",
    "    \n",
    "    sys.exit(0 if success else 1)\n",
    "'''\n",
    "        \n",
    "        return code\n",
    "\n",
    "# EJEMPLO COMPLETO\n",
    "\n",
    "# Dataset de ejemplo\n",
    "df_customers = pd.DataFrame({\n",
    "    'customer_id': range(1, 101),\n",
    "    'age': np.random.randint(18, 70, size=100),\n",
    "    'email': [f'user{i}@example.com' for i in range(100)],\n",
    "    'status': np.random.choice(['active', 'inactive', 'pending'], size=100),\n",
    "    'account_balance': np.random.uniform(-100, 10000, size=100),\n",
    "    'registration_date': pd.date_range('2020-01-01', periods=100)\n",
    "})\n",
    "\n",
    "# Contexto de negocio\n",
    "business_context = {\n",
    "    'customer_id': 'Identificador √∫nico de cliente, auto-incremental',\n",
    "    'age': 'Edad del cliente, debe ser adulto (18+)',\n",
    "    'email': 'Email de contacto, debe ser √∫nico y v√°lido',\n",
    "    'status': 'Estado de la cuenta del cliente',\n",
    "    'account_balance': 'Balance de cuenta, puede ser negativo (deuda)',\n",
    "    'registration_date': 'Fecha de registro del cliente en la plataforma'\n",
    "}\n",
    "\n",
    "# Generar reglas\n",
    "generator = RuleGenerator()\n",
    "rules_by_column = generator.generate_table_validation_suite(\n",
    "    df_customers,\n",
    "    'customers',\n",
    "    business_context\n",
    ")\n",
    "\n",
    "# Mostrar reglas generadas\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"REGLAS DE VALIDACI√ìN GENERADAS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for column, rules in rules_by_column.items():\n",
    "    print(f\"\\nüìä {column}\")\n",
    "    for i, rule in enumerate(rules, 1):\n",
    "        print(f\"\\n  {i}. {rule.rule_type.upper()}\")\n",
    "        print(f\"     Confianza: {rule.confidence:.0%}\")\n",
    "        print(f\"     Par√°metros: {rule.parameters}\")\n",
    "        print(f\"     Razonamiento: {rule.reasoning}\")\n",
    "        print(f\"     GE: {rule.great_expectations_code[:80]}...\")\n",
    "\n",
    "# Generar c√≥digo\n",
    "code_gen = CodeGenerator()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"C√ìDIGO GENERADO\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Great Expectations\n",
    "ge_code = code_gen.generate_great_expectations_suite(rules_by_column, 'customers_validation')\n",
    "print(\"\\n1Ô∏è‚É£ GREAT EXPECTATIONS:\")\n",
    "print(ge_code[:500] + \"...\\n\")\n",
    "\n",
    "# dbt\n",
    "dbt_yml = code_gen.generate_dbt_schema_yml(rules_by_column, 'stg_customers')\n",
    "print(\"\\n2Ô∏è‚É£ DBT SCHEMA.YML:\")\n",
    "print(dbt_yml[:500] + \"...\\n\")\n",
    "\n",
    "# Pandas\n",
    "pandas_script = code_gen.generate_pandas_validation_script(rules_by_column, 'validate_customers')\n",
    "print(\"\\n3Ô∏è‚É£ PANDAS SCRIPT:\")\n",
    "print(pandas_script[:500] + \"...\")\n",
    "```\n",
    "\n",
    "### üîÑ Refinamiento Iterativo de Reglas\n",
    "\n",
    "```python\n",
    "class RuleRefiner:\n",
    "    \"\"\"Refina reglas bas√°ndose en false positives/negatives.\"\"\"\n",
    "    \n",
    "    def __init__(self, generator: RuleGenerator):\n",
    "        self.generator = generator\n",
    "    \n",
    "    def evaluate_rule_quality(\n",
    "        self,\n",
    "        df: pd.DataFrame,\n",
    "        rule: ValidationRule,\n",
    "        ground_truth_issues: Optional[pd.Series] = None\n",
    "    ) -> Dict:\n",
    "        \"\"\"\n",
    "        Eval√∫a calidad de una regla ejecut√°ndola contra datos.\n",
    "        \n",
    "        Args:\n",
    "            df: datos a validar\n",
    "            rule: regla a evaluar\n",
    "            ground_truth_issues: m√°scara booleana de registros con issues reales\n",
    "        \n",
    "        Returns:\n",
    "            M√©tricas de calidad (precision, recall, false positive rate)\n",
    "        \"\"\"\n",
    "        # Ejecutar regla (simplificado)\n",
    "        try:\n",
    "            exec(rule.pandas_assertion, {\"df\": df})\n",
    "            violations = pd.Series([False] * len(df))\n",
    "        except AssertionError:\n",
    "            # Regla fall√≥, detectar qu√© registros violaron\n",
    "            # (implementaci√≥n real requiere parsear assertion)\n",
    "            violations = pd.Series([True] * len(df))\n",
    "        \n",
    "        if ground_truth_issues is None:\n",
    "            # Sin ground truth, solo reportar violations\n",
    "            return {\n",
    "                \"violations\": violations.sum(),\n",
    "                \"violation_rate\": violations.mean(),\n",
    "                \"precision\": None,\n",
    "                \"recall\": None\n",
    "            }\n",
    "        \n",
    "        # Con ground truth, calcular m√©tricas\n",
    "        true_positives = (violations & ground_truth_issues).sum()\n",
    "        false_positives = (violations & ~ground_truth_issues).sum()\n",
    "        false_negatives = (~violations & ground_truth_issues).sum()\n",
    "        \n",
    "        precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n",
    "        recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0\n",
    "        \n",
    "        return {\n",
    "            \"violations\": int(violations.sum()),\n",
    "            \"violation_rate\": float(violations.mean()),\n",
    "            \"precision\": precision,\n",
    "            \"recall\": recall,\n",
    "            \"false_positive_rate\": false_positives / len(df)\n",
    "        }\n",
    "    \n",
    "    def refine_rule(\n",
    "        self,\n",
    "        rule: ValidationRule,\n",
    "        quality_metrics: Dict,\n",
    "        df: pd.DataFrame\n",
    "    ) -> ValidationRule:\n",
    "        \"\"\"Refina regla si false positive rate >5%.\"\"\"\n",
    "        \n",
    "        if quality_metrics[\"false_positive_rate\"] > 0.05:\n",
    "            print(f\"‚ö†Ô∏è  High false positive rate ({quality_metrics['false_positive_rate']:.1%}), refining rule...\")\n",
    "            \n",
    "            # LLM sugiere ajustes\n",
    "            prompt = f\"\"\"Esta regla de validaci√≥n tiene demasiados false positives:\n",
    "\n",
    "Regla: {rule.rule_type}\n",
    "Par√°metros: {rule.parameters}\n",
    "Razonamiento: {rule.reasoning}\n",
    "\n",
    "False positive rate: {quality_metrics['false_positive_rate']:.1%}\n",
    "\n",
    "Analiza el profile actualizado y sugiere ajustes a los par√°metros para reducir false positives.\n",
    "Mant√©n el mismo rule_type pero ajusta thresholds, ranges, o patterns.\n",
    "\n",
    "Responde en JSON con regla refinada.\"\"\"\n",
    "            \n",
    "            # (implementaci√≥n LLM call omitida por brevedad)\n",
    "            \n",
    "        return rule\n",
    "```\n",
    "\n",
    "### üìä Comparaci√≥n: Manual vs Auto-Generated Rules\n",
    "\n",
    "| Aspecto | Manual | Auto-Generated (LLM) |\n",
    "|---------|--------|---------------------|\n",
    "| **Tiempo** | 2-4 horas por tabla | 5-10 minutos por tabla |\n",
    "| **Cobertura** | 60-70% de columnas | 95-100% de columnas |\n",
    "| **Calidad** | Alta (experto) | Media-Alta (requiere review) |\n",
    "| **Mantenimiento** | Manual al cambiar datos | Re-generar autom√°ticamente |\n",
    "| **Costo** | $150-$300 (tiempo ingeniero) | $0.10-$1.00 (API calls) |\n",
    "| **Consistency** | Variable por ingeniero | Consistente |\n",
    "\n",
    "**ROI**: Auto-generaci√≥n reduce tiempo **95%** y costo **99%**, pero requiere review humano.\n",
    "\n",
    "### üí° Mejores Pr√°cticas\n",
    "\n",
    "1. **Siempre revisar reglas generadas**: LLM puede inferir mal, especialmente sin contexto\n",
    "2. **Proveer business context**: Mejora significativamente calidad de reglas\n",
    "3. **Ejecutar en datos hist√≥ricos**: Validar que reglas no tengan alta tasa de false positives\n",
    "4. **Iterar**: Refinar reglas bas√°ndose en feedback de producci√≥n\n",
    "5. **Versionar**: Guardar reglas en Git, no re-generar cada vez\n",
    "6. **Combinar con experto**: LLM genera draft, humano refina\n",
    "7. **Monitoring**: Track false positive/negative rates en producci√≥n\n",
    "8. **A/B test**: Comparar LLM-generated vs manual rules en m√©tricas de calidad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f3e532",
   "metadata": {},
   "source": [
    "## üî¨ Root Cause Analysis: LLMs como Data Quality Investigators\n",
    "\n",
    "Cuando las validaciones fallan, el desaf√≠o **real** no es detectar el problema sino **explicar POR QU√â ocurri√≥** y **C√ìMO solucionarlo**. Los LLMs act√∫an como **investigadores expertos** que analizan patrones, correlaciones temporales, y contexto de negocio para identificar causas ra√≠z.\n",
    "\n",
    "### üïµÔ∏è Arquitectura de Root Cause Analysis\n",
    "\n",
    "```\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ         ROOT CAUSE ANALYSIS: FROM SYMPTOM TO SOLUTION            ‚îÇ\n",
    "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
    "‚îÇ                                                                  ‚îÇ\n",
    "‚îÇ  SYMPTOM: 500 registros con email = NULL desde 2024-10-15       ‚îÇ\n",
    "‚îÇ        ‚Üì                                                         ‚îÇ\n",
    "‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ\n",
    "‚îÇ  ‚îÇ 1. TEMPORAL ANALYSIS                                     ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ    ¬øCu√°ndo comenz√≥ el problema?                          ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ                                                          ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ    SELECT DATE(created_at), COUNT(*) as nulls            ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ    FROM customers WHERE email IS NULL                    ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ    GROUP BY 1 ORDER BY 1 DESC                            ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ                                                          ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ    Resultado:                                            ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ    2024-10-14: 0 nulls                                   ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ    2024-10-15: 125 nulls  ‚Üê SPIKE                       ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ    2024-10-16: 187 nulls                                 ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ    2024-10-17: 188 nulls                                 ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ                                                          ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ    üí° Insight: Problema comenz√≥ 2024-10-15               ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ\n",
    "‚îÇ        ‚Üì                                                         ‚îÇ\n",
    "‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ\n",
    "‚îÇ  ‚îÇ 2. CORRELATION ANALYSIS                                  ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ    ¬øQu√© m√°s cambi√≥ ese d√≠a?                              ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ                                                          ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ    - Git logs: Deploy de signup API v2.1 a las 14:30    ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ    - Airflow DAG 'ingest_signups' cambi√≥ l√≥gica         ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ    - Tr√°fico aument√≥ 30% (marketing campaign)           ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ                                                          ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ    üí° Insight: Deploy coincide con inicio de nulls       ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ\n",
    "‚îÇ        ‚Üì                                                         ‚îÇ\n",
    "‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ\n",
    "‚îÇ  ‚îÇ 3. PATTERN ANALYSIS                                      ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ    ¬øQu√© tienen en com√∫n los registros afectados?        ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ                                                          ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ    SELECT source, COUNT(*)                               ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ    FROM customers WHERE email IS NULL                    ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ    AND created_at >= '2024-10-15'                        ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ    GROUP BY 1                                            ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ                                                          ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ    Resultado:                                            ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ    mobile_app: 500 nulls  ‚Üê TODOS los nulls             ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ    web: 0 nulls                                          ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ                                                          ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ    üí° Insight: Solo afecta signups de mobile app         ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ\n",
    "‚îÇ        ‚Üì                                                         ‚îÇ\n",
    "‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ\n",
    "‚îÇ  ‚îÇ 4. LLM SYNTHESIS                                         ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ    Prompt: \"Analiza estos hallazgos y determina causa\"  ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ                                                          ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ    LLM ‚Üí ROOT CAUSE:                                     ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ    \"El deploy de signup API v2.1 el 2024-10-15 introdujo‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ     un bug en el endpoint de mobile app donde el campo  ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ     'email' dej√≥ de ser required en el request body.     ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ     El backend ahora acepta signups sin email pero la   ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ     base de datos espera NOT NULL, resultando en NULLs. ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ                                                          ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ     EVIDENCIA:                                           ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ     1. Spike exacto en fecha de deploy                   ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ     2. Solo afecta mobile app (endpoint modificado)      ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ     3. Web no afectado (endpoint diferente sin cambios)  ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ                                                          ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ     SOLUCI√ìN RECOMENDADA:                                ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ     1. Rollback a API v2.0 (inmediato)                   ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ     2. Fix: Agregar validaci√≥n 'email required'          ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ     3. Backfill: Contactar 500 usuarios para emails     ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ     4. Prevention: Agregar test e2e para campo required\"‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ\n",
    "‚îÇ        ‚Üì                                                         ‚îÇ\n",
    "‚îÇ  SOLUTION: Rollback + Fix + Backfill + Prevention                ‚îÇ\n",
    "‚îÇ                                                                  ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "```\n",
    "\n",
    "### üîß Implementaci√≥n Completa\n",
    "\n",
    "```python\n",
    "from typing import List, Dict, Optional\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel\n",
    "import json\n",
    "\n",
    "client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))\n",
    "\n",
    "# 1. MODELOS DE DATOS\n",
    "\n",
    "class TemporalAnomaly(BaseModel):\n",
    "    \"\"\"Anomal√≠a detectada con an√°lisis temporal.\"\"\"\n",
    "    issue_type: str\n",
    "    affected_records: int\n",
    "    first_occurrence: datetime\n",
    "    spike_date: Optional[datetime] = None\n",
    "    trend: str  # \"increasing\", \"decreasing\", \"stable\", \"spike\"\n",
    "    time_series: List[Dict[str, any]]  # [{date, count}]\n",
    "\n",
    "class CorrelatedEvent(BaseModel):\n",
    "    \"\"\"Evento que coincide temporalmente con anomal√≠a.\"\"\"\n",
    "    event_type: str  # \"deployment\", \"schema_change\", \"traffic_spike\", etc.\n",
    "    timestamp: datetime\n",
    "    description: str\n",
    "    confidence: float  # Qu√© tan probable es que sea la causa\n",
    "\n",
    "class PatternInsight(BaseModel):\n",
    "    \"\"\"Insight sobre patr√≥n en datos afectados.\"\"\"\n",
    "    dimension: str  # Columna analizada (source, region, user_type, etc.)\n",
    "    pattern: str  # Descripci√≥n del patr√≥n\n",
    "    affected_segments: Dict[str, int]  # {valor: count}\n",
    "    is_significant: bool\n",
    "\n",
    "class RootCauseHypothesis(BaseModel):\n",
    "    \"\"\"Hip√≥tesis de causa ra√≠z.\"\"\"\n",
    "    rank: int\n",
    "    confidence: float\n",
    "    root_cause: str\n",
    "    evidence: List[str]\n",
    "    recommended_fix: str\n",
    "    prevention_steps: List[str]\n",
    "\n",
    "class RootCauseReport(BaseModel):\n",
    "    \"\"\"Reporte completo de investigaci√≥n.\"\"\"\n",
    "    issue_description: str\n",
    "    temporal_analysis: TemporalAnomaly\n",
    "    correlated_events: List[CorrelatedEvent]\n",
    "    pattern_insights: List[PatternInsight]\n",
    "    hypotheses: List[RootCauseHypothesis]\n",
    "    recommended_action: str\n",
    "    estimated_impact: str\n",
    "\n",
    "# 2. ROOT CAUSE ANALYZER\n",
    "\n",
    "class RootCauseAnalyzer:\n",
    "    \"\"\"Investigador autom√°tico de causas ra√≠z.\"\"\"\n",
    "    \n",
    "    def __init__(self, model: str = \"gpt-4o\"):\n",
    "        self.model = model\n",
    "    \n",
    "    def analyze_temporal_pattern(\n",
    "        self,\n",
    "        df: pd.DataFrame,\n",
    "        issue_column: str,\n",
    "        issue_condition: str,\n",
    "        date_column: str = 'created_at'\n",
    "    ) -> TemporalAnomaly:\n",
    "        \"\"\"\n",
    "        Analiza patr√≥n temporal del issue.\n",
    "        \n",
    "        Args:\n",
    "            df: DataFrame completo\n",
    "            issue_column: columna con el issue\n",
    "            issue_condition: condici√≥n para detectar issue (ej. \"email IS NULL\")\n",
    "            date_column: columna de fecha\n",
    "        \"\"\"\n",
    "        # Filtrar registros con issue\n",
    "        issue_mask = eval(f\"df['{issue_column}'].{issue_condition}\")\n",
    "        affected_df = df[issue_mask].copy()\n",
    "        \n",
    "        # Time series de issues por d√≠a\n",
    "        affected_df['date'] = pd.to_datetime(affected_df[date_column]).dt.date\n",
    "        daily_counts = affected_df.groupby('date').size().reset_index(name='count')\n",
    "        \n",
    "        # Detectar spike\n",
    "        if len(daily_counts) > 1:\n",
    "            mean_count = daily_counts['count'].mean()\n",
    "            std_count = daily_counts['count'].std()\n",
    "            spike_threshold = mean_count + (2 * std_count)\n",
    "            \n",
    "            spikes = daily_counts[daily_counts['count'] > spike_threshold]\n",
    "            spike_date = spikes.iloc[0]['date'] if len(spikes) > 0 else None\n",
    "        else:\n",
    "            spike_date = None\n",
    "        \n",
    "        # Determinar trend\n",
    "        if len(daily_counts) >= 3:\n",
    "            recent_trend = daily_counts['count'].tail(3).diff().mean()\n",
    "            if recent_trend > daily_counts['count'].std():\n",
    "                trend = \"increasing\"\n",
    "            elif recent_trend < -daily_counts['count'].std():\n",
    "                trend = \"decreasing\"\n",
    "            else:\n",
    "                trend = \"stable\"\n",
    "        else:\n",
    "            trend = \"spike\" if spike_date else \"stable\"\n",
    "        \n",
    "        return TemporalAnomaly(\n",
    "            issue_type=issue_condition,\n",
    "            affected_records=len(affected_df),\n",
    "            first_occurrence=datetime.combine(daily_counts.iloc[0]['date'], datetime.min.time()),\n",
    "            spike_date=datetime.combine(spike_date, datetime.min.time()) if spike_date else None,\n",
    "            trend=trend,\n",
    "            time_series=[\n",
    "                {\"date\": str(row['date']), \"count\": int(row['count'])}\n",
    "                for _, row in daily_counts.iterrows()\n",
    "            ]\n",
    "        )\n",
    "    \n",
    "    def find_correlated_events(\n",
    "        self,\n",
    "        anomaly: TemporalAnomaly,\n",
    "        event_log: List[Dict]\n",
    "    ) -> List[CorrelatedEvent]:\n",
    "        \"\"\"\n",
    "        Encuentra eventos que coinciden temporalmente con anomal√≠a.\n",
    "        \n",
    "        Args:\n",
    "            anomaly: an√°lisis temporal\n",
    "            event_log: lista de eventos [{type, timestamp, description}]\n",
    "        \"\"\"\n",
    "        reference_date = anomaly.spike_date or anomaly.first_occurrence\n",
    "        window_hours = 24  # Ventana de +/- 24 horas\n",
    "        \n",
    "        correlated = []\n",
    "        \n",
    "        for event in event_log:\n",
    "            event_time = datetime.fromisoformat(event['timestamp'])\n",
    "            time_diff = abs((event_time - reference_date).total_seconds() / 3600)\n",
    "            \n",
    "            if time_diff <= window_hours:\n",
    "                # Calcular confidence basado en proximidad temporal\n",
    "                confidence = 1.0 - (time_diff / window_hours)\n",
    "                \n",
    "                correlated.append(CorrelatedEvent(\n",
    "                    event_type=event['type'],\n",
    "                    timestamp=event_time,\n",
    "                    description=event['description'],\n",
    "                    confidence=confidence\n",
    "                ))\n",
    "        \n",
    "        # Ordenar por confidence\n",
    "        return sorted(correlated, key=lambda x: x.confidence, reverse=True)\n",
    "    \n",
    "    def analyze_patterns(\n",
    "        self,\n",
    "        df: pd.DataFrame,\n",
    "        issue_column: str,\n",
    "        issue_condition: str,\n",
    "        dimensions: List[str]\n",
    "    ) -> List[PatternInsight]:\n",
    "        \"\"\"\n",
    "        Analiza patrones en m√∫ltiples dimensiones.\n",
    "        \n",
    "        Args:\n",
    "            df: DataFrame completo\n",
    "            issue_column: columna con issue\n",
    "            issue_condition: condici√≥n de issue\n",
    "            dimensions: columnas a analizar (source, region, etc.)\n",
    "        \"\"\"\n",
    "        issue_mask = eval(f\"df['{issue_column}'].{issue_condition}\")\n",
    "        affected_df = df[issue_mask]\n",
    "        \n",
    "        insights = []\n",
    "        \n",
    "        for dim in dimensions:\n",
    "            if dim not in df.columns:\n",
    "                continue\n",
    "            \n",
    "            # Distribuci√≥n en datos afectados\n",
    "            affected_dist = affected_df[dim].value_counts().to_dict()\n",
    "            \n",
    "            # Distribuci√≥n en datos totales\n",
    "            total_dist = df[dim].value_counts().to_dict()\n",
    "            \n",
    "            # Detectar si alg√∫n segmento est√° sobre-representado\n",
    "            total_records = len(df)\n",
    "            significant_segments = {}\n",
    "            \n",
    "            for value, count in affected_dist.items():\n",
    "                expected_ratio = total_dist.get(value, 0) / total_records\n",
    "                actual_ratio = count / len(affected_df)\n",
    "                \n",
    "                # Si ratio es >2x esperado, es significativo\n",
    "                if actual_ratio > expected_ratio * 2:\n",
    "                    significant_segments[str(value)] = count\n",
    "            \n",
    "            is_significant = len(significant_segments) > 0\n",
    "            \n",
    "            if is_significant:\n",
    "                pattern = f\"Segmento(s) sobre-representado(s): {', '.join(significant_segments.keys())}\"\n",
    "            else:\n",
    "                pattern = \"Distribuci√≥n uniforme entre segmentos\"\n",
    "            \n",
    "            insights.append(PatternInsight(\n",
    "                dimension=dim,\n",
    "                pattern=pattern,\n",
    "                affected_segments={str(k): int(v) for k, v in affected_dist.items()},\n",
    "                is_significant=is_significant\n",
    "            ))\n",
    "        \n",
    "        return insights\n",
    "    \n",
    "    def generate_hypotheses(\n",
    "        self,\n",
    "        issue_description: str,\n",
    "        temporal: TemporalAnomaly,\n",
    "        events: List[CorrelatedEvent],\n",
    "        patterns: List[PatternInsight]\n",
    "    ) -> List[RootCauseHypothesis]:\n",
    "        \"\"\"\n",
    "        Usa LLM para generar hip√≥tesis de causa ra√≠z.\n",
    "        \"\"\"\n",
    "        prompt = f\"\"\"Act√∫a como un Data Quality Investigator experto. Analiza estos hallazgos y genera hip√≥tesis de causa ra√≠z:\n",
    "\n",
    "PROBLEMA:\n",
    "{issue_description}\n",
    "\n",
    "AN√ÅLISIS TEMPORAL:\n",
    "- Registros afectados: {temporal.affected_records}\n",
    "- Primera ocurrencia: {temporal.first_occurrence}\n",
    "- Spike detectado: {temporal.spike_date or \"No\"}\n",
    "- Tendencia: {temporal.trend}\n",
    "- Serie temporal: {json.dumps(temporal.time_series[:7], indent=2)}\n",
    "\n",
    "EVENTOS CORRELACIONADOS:\n",
    "{chr(10).join([f\"- [{e.event_type}] {e.timestamp}: {e.description} (confidence: {e.confidence:.0%})\" for e in events[:5]])}\n",
    "\n",
    "PATRONES IDENTIFICADOS:\n",
    "{chr(10).join([f\"- {p.dimension}: {p.pattern}\" + (f\" (SIGNIFICATIVO)\" if p.is_significant else \"\") for p in patterns])}\n",
    "\n",
    "Genera 2-3 hip√≥tesis de causa ra√≠z, ordenadas por probabilidad. Para cada hip√≥tesis:\n",
    "1. Explicaci√≥n de la causa ra√≠z\n",
    "2. Evidencia que la soporta\n",
    "3. Fix recomendado\n",
    "4. Pasos de prevenci√≥n\n",
    "\n",
    "Responde en JSON:\n",
    "{{\n",
    "  \"hypotheses\": [\n",
    "    {{\n",
    "      \"confidence\": 0.0-1.0,\n",
    "      \"root_cause\": \"explicaci√≥n concisa\",\n",
    "      \"evidence\": [\"evidencia 1\", \"evidencia 2\", ...],\n",
    "      \"recommended_fix\": \"acci√≥n inmediata\",\n",
    "      \"prevention_steps\": [\"paso 1\", \"paso 2\", ...]\n",
    "    }}\n",
    "  ],\n",
    "  \"recommended_action\": \"qu√© hacer AHORA\",\n",
    "  \"estimated_impact\": \"cu√°ntos usuarios/registros/$ afectados\"\n",
    "}}\"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=self.model,\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                temperature=0.3,\n",
    "                response_format={\"type\": \"json_object\"}\n",
    "            )\n",
    "            \n",
    "            result = json.loads(response.choices[0].message.content)\n",
    "            \n",
    "            hypotheses = []\n",
    "            for i, hyp_data in enumerate(result.get(\"hypotheses\", []), 1):\n",
    "                hypotheses.append(RootCauseHypothesis(\n",
    "                    rank=i,\n",
    "                    confidence=hyp_data[\"confidence\"],\n",
    "                    root_cause=hyp_data[\"root_cause\"],\n",
    "                    evidence=hyp_data[\"evidence\"],\n",
    "                    recommended_fix=hyp_data[\"recommended_fix\"],\n",
    "                    prevention_steps=hyp_data[\"prevention_steps\"]\n",
    "                ))\n",
    "            \n",
    "            return hypotheses, result[\"recommended_action\"], result[\"estimated_impact\"]\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error generando hip√≥tesis: {e}\")\n",
    "            return [], \"Manual investigation required\", \"Unknown\"\n",
    "    \n",
    "    def investigate(\n",
    "        self,\n",
    "        df: pd.DataFrame,\n",
    "        issue_description: str,\n",
    "        issue_column: str,\n",
    "        issue_condition: str,\n",
    "        event_log: List[Dict],\n",
    "        dimensions_to_analyze: List[str],\n",
    "        date_column: str = 'created_at'\n",
    "    ) -> RootCauseReport:\n",
    "        \"\"\"\n",
    "        Investigaci√≥n completa de root cause.\n",
    "        \n",
    "        Args:\n",
    "            df: DataFrame con datos\n",
    "            issue_description: descripci√≥n del problema\n",
    "            issue_column: columna con issue\n",
    "            issue_condition: condici√≥n que define el issue\n",
    "            event_log: log de eventos (deployments, schema changes, etc.)\n",
    "            dimensions_to_analyze: columnas para pattern analysis\n",
    "            date_column: columna de timestamp\n",
    "        \n",
    "        Returns:\n",
    "            Reporte completo de investigaci√≥n\n",
    "        \"\"\"\n",
    "        print(\"üîç Iniciando investigaci√≥n de root cause...\")\n",
    "        \n",
    "        # 1. An√°lisis temporal\n",
    "        print(\"  1Ô∏è‚É£ Analizando patr√≥n temporal...\")\n",
    "        temporal = self.analyze_temporal_pattern(df, issue_column, issue_condition, date_column)\n",
    "        print(f\"     ‚úì {temporal.affected_records} registros afectados, tendencia: {temporal.trend}\")\n",
    "        \n",
    "        # 2. Eventos correlacionados\n",
    "        print(\"  2Ô∏è‚É£ Buscando eventos correlacionados...\")\n",
    "        events = self.find_correlated_events(temporal, event_log)\n",
    "        print(f\"     ‚úì {len(events)} eventos encontrados\")\n",
    "        \n",
    "        # 3. Patrones\n",
    "        print(\"  3Ô∏è‚É£ Analizando patrones en dimensiones...\")\n",
    "        patterns = self.analyze_patterns(df, issue_column, issue_condition, dimensions_to_analyze)\n",
    "        significant_patterns = [p for p in patterns if p.is_significant]\n",
    "        print(f\"     ‚úì {len(significant_patterns)}/{len(patterns)} patrones significativos\")\n",
    "        \n",
    "        # 4. Generar hip√≥tesis con LLM\n",
    "        print(\"  4Ô∏è‚É£ Generando hip√≥tesis de causa ra√≠z...\")\n",
    "        hypotheses, recommended_action, estimated_impact = self.generate_hypotheses(\n",
    "            issue_description, temporal, events, patterns\n",
    "        )\n",
    "        print(f\"     ‚úì {len(hypotheses)} hip√≥tesis generadas\")\n",
    "        \n",
    "        return RootCauseReport(\n",
    "            issue_description=issue_description,\n",
    "            temporal_analysis=temporal,\n",
    "            correlated_events=events,\n",
    "            pattern_insights=patterns,\n",
    "            hypotheses=hypotheses,\n",
    "            recommended_action=recommended_action,\n",
    "            estimated_impact=estimated_impact\n",
    "        )\n",
    "\n",
    "# EJEMPLO DE USO\n",
    "\n",
    "# Dataset simulado\n",
    "np.random.seed(42)\n",
    "\n",
    "dates = pd.date_range('2024-10-01', '2024-10-20', freq='H')\n",
    "n_records = len(dates)\n",
    "\n",
    "# Simular spike de NULLs desde 2024-10-15 solo en mobile_app\n",
    "df_signups = pd.DataFrame({\n",
    "    'user_id': range(n_records),\n",
    "    'created_at': dates,\n",
    "    'email': ['user{}@example.com'.format(i) for i in range(n_records)],\n",
    "    'source': np.random.choice(['web', 'mobile_app'], size=n_records, p=[0.6, 0.4]),\n",
    "    'region': np.random.choice(['US', 'EU', 'ASIA'], size=n_records)\n",
    "})\n",
    "\n",
    "# Introducir NULLs despu√©s de 2024-10-15 solo en mobile_app\n",
    "spike_start = pd.Timestamp('2024-10-15')\n",
    "mobile_mask = df_signups['source'] == 'mobile_app'\n",
    "after_spike = df_signups['created_at'] >= spike_start\n",
    "\n",
    "df_signups.loc[mobile_mask & after_spike, 'email'] = None\n",
    "\n",
    "# Event log simulado\n",
    "event_log = [\n",
    "    {\n",
    "        'type': 'deployment',\n",
    "        'timestamp': '2024-10-15T14:30:00',\n",
    "        'description': 'Deployed signup API v2.1 with mobile app endpoint changes'\n",
    "    },\n",
    "    {\n",
    "        'type': 'schema_change',\n",
    "        'timestamp': '2024-10-12T10:00:00',\n",
    "        'description': 'Added index on users.email for performance'\n",
    "    },\n",
    "    {\n",
    "        'type': 'traffic_spike',\n",
    "        'timestamp': '2024-10-15T08:00:00',\n",
    "        'description': 'Marketing campaign launch, traffic +30%'\n",
    "    }\n",
    "]\n",
    "\n",
    "# Investigar\n",
    "analyzer = RootCauseAnalyzer()\n",
    "\n",
    "report = analyzer.investigate(\n",
    "    df=df_signups,\n",
    "    issue_description=\"500+ signups con email NULL desde 2024-10-15\",\n",
    "    issue_column='email',\n",
    "    issue_condition='isnull()',\n",
    "    event_log=event_log,\n",
    "    dimensions_to_analyze=['source', 'region'],\n",
    "    date_column='created_at'\n",
    ")\n",
    "\n",
    "# Mostrar reporte\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üìã ROOT CAUSE ANALYSIS REPORT\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\nüî¥ PROBLEMA: {report.issue_description}\")\n",
    "print(f\"\\nüìä AN√ÅLISIS TEMPORAL:\")\n",
    "print(f\"   Afectados: {report.temporal_analysis.affected_records}\")\n",
    "print(f\"   Primera ocurrencia: {report.temporal_analysis.first_occurrence}\")\n",
    "print(f\"   Spike detectado: {report.temporal_analysis.spike_date}\")\n",
    "print(f\"   Tendencia: {report.temporal_analysis.trend}\")\n",
    "\n",
    "print(f\"\\nüîó EVENTOS CORRELACIONADOS (top 3):\")\n",
    "for event in report.correlated_events[:3]:\n",
    "    print(f\"   [{event.confidence:.0%}] {event.event_type}: {event.description}\")\n",
    "\n",
    "print(f\"\\nüîç PATRONES SIGNIFICATIVOS:\")\n",
    "for pattern in report.pattern_insights:\n",
    "    if pattern.is_significant:\n",
    "        print(f\"   {pattern.dimension}: {pattern.pattern}\")\n",
    "        print(f\"      Segmentos afectados: {pattern.affected_segments}\")\n",
    "\n",
    "print(f\"\\nüí° HIP√ìTESIS DE CAUSA RA√çZ:\")\n",
    "for hyp in report.hypotheses:\n",
    "    print(f\"\\n   {hyp.rank}. [{hyp.confidence:.0%}] {hyp.root_cause}\")\n",
    "    print(f\"      Evidencia:\")\n",
    "    for evidence in hyp.evidence:\n",
    "        print(f\"        - {evidence}\")\n",
    "    print(f\"      Fix recomendado: {hyp.recommended_fix}\")\n",
    "    print(f\"      Prevenci√≥n:\")\n",
    "    for step in hyp.prevention_steps:\n",
    "        print(f\"        - {step}\")\n",
    "\n",
    "print(f\"\\nüöÄ ACCI√ìN RECOMENDADA:\")\n",
    "print(f\"   {report.recommended_action}\")\n",
    "\n",
    "print(f\"\\nüìà IMPACTO ESTIMADO:\")\n",
    "print(f\"   {report.estimated_impact}\")\n",
    "```\n",
    "\n",
    "### üìä M√©tricas de √âxito en Root Cause Analysis\n",
    "\n",
    "```python\n",
    "class RCAMetrics:\n",
    "    \"\"\"M√©tricas para evaluar calidad de RCA.\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def measure_time_to_root_cause(\n",
    "        issue_detected_at: datetime,\n",
    "        root_cause_identified_at: datetime\n",
    "    ) -> float:\n",
    "        \"\"\"Tiempo desde detecci√≥n hasta identificaci√≥n de causa.\"\"\"\n",
    "        return (root_cause_identified_at - issue_detected_at).total_seconds() / 3600  # horas\n",
    "    \n",
    "    @staticmethod\n",
    "    def measure_hypothesis_accuracy(\n",
    "        predicted_cause: str,\n",
    "        actual_cause: str,\n",
    "        llm_model: str = \"gpt-4o\"\n",
    "    ) -> float:\n",
    "        \"\"\"\n",
    "        Eval√∫a similitud sem√°ntica entre causa predicha y real.\n",
    "        Retorna score 0.0-1.0.\n",
    "        \"\"\"\n",
    "        # Usar embeddings para similitud sem√°ntica\n",
    "        from openai import OpenAI\n",
    "        client = OpenAI()\n",
    "        \n",
    "        response = client.embeddings.create(\n",
    "            model=\"text-embedding-3-small\",\n",
    "            input=[predicted_cause, actual_cause]\n",
    "        )\n",
    "        \n",
    "        emb1 = np.array(response.data[0].embedding)\n",
    "        emb2 = np.array(response.data[1].embedding)\n",
    "        \n",
    "        # Cosine similarity\n",
    "        similarity = np.dot(emb1, emb2) / (np.linalg.norm(emb1) * np.linalg.norm(emb2))\n",
    "        \n",
    "        return float(similarity)\n",
    "\n",
    "# Ejemplo de medici√≥n\n",
    "metrics = RCAMetrics()\n",
    "\n",
    "# Manual investigation: 4 horas\n",
    "manual_time = 4.0\n",
    "\n",
    "# LLM-powered: 15 minutos\n",
    "llm_time = 0.25\n",
    "\n",
    "print(f\"‚ö° Speedup: {manual_time / llm_time:.0f}x m√°s r√°pido\")\n",
    "print(f\"üí∞ Ahorro: ${manual_time * 75:.0f} (@ $75/hora ingeniero) vs ${0.50:.2f} (API calls)\")\n",
    "```\n",
    "\n",
    "### üí° Mejores Pr√°cticas\n",
    "\n",
    "1. **Siempre investigar**: No asumir causa, seguir proceso sistem√°tico\n",
    "2. **M√∫ltiples hip√≥tesis**: LLM debe generar 2-3 opciones, no solo una\n",
    "3. **Evidencia cuantitativa**: Basar hip√≥tesis en datos, no suposiciones\n",
    "4. **Timeline cr√≠tico**: Marcar eventos importantes (deploys, schema changes)\n",
    "5. **Documentar**: Guardar investigaciones para aprendizaje futuro\n",
    "6. **Validar hip√≥tesis**: Confirmar causa ra√≠z antes de aplicar fix masivo\n",
    "7. **Post-mortem autom√°tico**: Generar documento de incident con LLM\n",
    "8. **Learn from patterns**: Entrenar modelo en investigaciones previas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f0264d",
   "metadata": {},
   "source": [
    "## üè≠ LLM-Powered Data Quality en Producci√≥n\n",
    "\n",
    "Implementar LLMs para Data Quality en producci√≥n requiere arquitectura robusta, monitoring exhaustivo, y estrategias para controlar costos y latencia. Aqu√≠ exploramos patrones de producci√≥n reales.\n",
    "\n",
    "### üèóÔ∏è Arquitectura de Data Quality Platform con LLMs\n",
    "\n",
    "```\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ         DATA QUALITY PLATFORM: HYBRID ARCHITECTURE               ‚îÇ\n",
    "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
    "‚îÇ                                                                  ‚îÇ\n",
    "‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ\n",
    "‚îÇ  ‚îÇ INGESTION LAYER                                          ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ  ‚Ä¢ Kafka / Kinesis streams                               ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ  ‚Ä¢ Airflow DAGs                                          ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ  ‚Ä¢ dbt models                                            ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ\n",
    "‚îÇ                   ‚Üì                                              ‚îÇ\n",
    "‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ\n",
    "‚îÇ  ‚îÇ VALIDATION LAYER (Multi-Stage)                           ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ                                                          ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ  Stage 1: TRADITIONAL (100% traffic, <10ms)             ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ  ‚îÇ ‚Ä¢ NULL checks (Pandas)                         ‚îÇ     ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ  ‚îÇ ‚Ä¢ Range validation (SQL)                       ‚îÇ     ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ  ‚îÇ ‚Ä¢ Regex patterns (Python re)                   ‚îÇ     ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ  ‚îÇ ‚Ä¢ Referential integrity (JOIN queries)         ‚îÇ     ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ  ‚îÇ                                                ‚îÇ     ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ  ‚îÇ ‚úÖ Pass ‚Üí Continue                             ‚îÇ     ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ  ‚îÇ ‚ùå Fail ‚Üí Block + Alert                        ‚îÇ     ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ                   ‚Üì                                      ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ  Stage 2: LLM SEMANTIC (1% sample, ~500ms)              ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ  ‚îÇ ‚Ä¢ Semantic NULL detection                      ‚îÇ     ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ  ‚îÇ ‚Ä¢ Plausibility checks                          ‚îÇ     ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ  ‚îÇ ‚Ä¢ PII detection                                ‚îÇ     ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ  ‚îÇ ‚Ä¢ Anomaly explanation                          ‚îÇ     ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ  ‚îÇ                                                ‚îÇ     ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ  ‚îÇ Cache Layer (Redis):                           ‚îÇ     ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ  ‚îÇ  key: hash(value + context)                    ‚îÇ     ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ  ‚îÇ  value: {is_valid, confidence, reasoning}      ‚îÇ     ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ  ‚îÇ  TTL: 7 days                                   ‚îÇ     ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ  ‚îÇ                                                ‚îÇ     ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ  ‚îÇ ‚ö†Ô∏è  Issues ‚Üí Queue for investigation           ‚îÇ     ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ                   ‚Üì                                      ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ  Stage 3: ROOT CAUSE ANALYSIS (on failures)             ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ  ‚îÇ ‚Ä¢ Triggered solo si >threshold failures        ‚îÇ     ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ  ‚îÇ ‚Ä¢ Analiza temporal patterns                    ‚îÇ     ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ  ‚îÇ ‚Ä¢ Correlaciona con eventos (deploys, etc.)     ‚îÇ     ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ  ‚îÇ ‚Ä¢ Genera hip√≥tesis con LLM                     ‚îÇ     ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ  ‚îÇ ‚Ä¢ Crea ticket autom√°tico (Jira)               ‚îÇ     ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ\n",
    "‚îÇ                   ‚Üì                                              ‚îÇ\n",
    "‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ\n",
    "‚îÇ  ‚îÇ MONITORING & ALERTING                                    ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ  ‚Ä¢ Prometheus metrics                                    ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ  ‚Ä¢ Grafana dashboards                                    ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ  ‚Ä¢ PagerDuty/Slack alerts                                ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ  ‚Ä¢ Cost tracking (LLM API usage)                         ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ\n",
    "‚îÇ                   ‚Üì                                              ‚îÇ\n",
    "‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ\n",
    "‚îÇ  ‚îÇ DATA STORAGE                                             ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ  ‚Ä¢ Validated data ‚Üí Data Warehouse (Snowflake)           ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ  ‚Ä¢ Validation logs ‚Üí S3 ‚Üí Athena queries                 ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îÇ  ‚Ä¢ Failed records ‚Üí Dead Letter Queue (DLQ)              ‚îÇ   ‚îÇ\n",
    "‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ\n",
    "‚îÇ                                                                  ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "```\n",
    "\n",
    "### üîß Implementaci√≥n: Production-Grade System\n",
    "\n",
    "```python\n",
    "from typing import Dict, List, Optional\n",
    "import asyncio\n",
    "import redis\n",
    "import hashlib\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "from dataclasses import dataclass\n",
    "import logging\n",
    "from prometheus_client import Counter, Histogram, Gauge\n",
    "from openai import AsyncOpenAI\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Prometheus metrics\n",
    "VALIDATIONS_TOTAL = Counter('dq_validations_total', 'Total validations', ['stage', 'result'])\n",
    "VALIDATION_DURATION = Histogram('dq_validation_duration_seconds', 'Validation duration', ['stage'])\n",
    "LLM_API_COST = Gauge('dq_llm_api_cost_usd', 'LLM API cost')\n",
    "CACHE_HIT_RATE = Gauge('dq_cache_hit_rate', 'Cache hit rate')\n",
    "\n",
    "# 1. CACHE LAYER\n",
    "\n",
    "class ValidationCache:\n",
    "    \"\"\"Redis-backed cache para validaciones LLM.\"\"\"\n",
    "    \n",
    "    def __init__(self, redis_url: str = \"redis://localhost:6379\"):\n",
    "        self.redis_client = redis.from_url(redis_url, decode_responses=True)\n",
    "        self.ttl_seconds = 7 * 24 * 3600  # 7 d√≠as\n",
    "        self.hits = 0\n",
    "        self.misses = 0\n",
    "    \n",
    "    def _get_cache_key(self, value: str, context: str, validation_type: str) -> str:\n",
    "        \"\"\"Genera cache key determin√≠stico.\"\"\"\n",
    "        content = f\"{validation_type}:{context}:{value}\"\n",
    "        return f\"dq:validation:{hashlib.sha256(content.encode()).hexdigest()}\"\n",
    "    \n",
    "    def get(self, value: str, context: str, validation_type: str) -> Optional[Dict]:\n",
    "        \"\"\"Obtiene resultado cacheado.\"\"\"\n",
    "        key = self._get_cache_key(value, context, validation_type)\n",
    "        \n",
    "        cached = self.redis_client.get(key)\n",
    "        \n",
    "        if cached:\n",
    "            self.hits += 1\n",
    "            CACHE_HIT_RATE.set(self.hits / (self.hits + self.misses))\n",
    "            return json.loads(cached)\n",
    "        else:\n",
    "            self.misses += 1\n",
    "            CACHE_HIT_RATE.set(self.hits / (self.hits + self.misses))\n",
    "            return None\n",
    "    \n",
    "    def set(self, value: str, context: str, validation_type: str, result: Dict):\n",
    "        \"\"\"Cachea resultado.\"\"\"\n",
    "        key = self._get_cache_key(value, context, validation_type)\n",
    "        self.redis_client.setex(key, self.ttl_seconds, json.dumps(result))\n",
    "\n",
    "# 2. VALIDATION ORCHESTRATOR\n",
    "\n",
    "@dataclass\n",
    "class ValidationConfig:\n",
    "    \"\"\"Configuraci√≥n de validaci√≥n.\"\"\"\n",
    "    traditional_enabled: bool = True\n",
    "    llm_enabled: bool = True\n",
    "    llm_sample_rate: float = 0.01  # 1% de tr√°fico\n",
    "    llm_max_concurrent: int = 10\n",
    "    llm_timeout_seconds: int = 5\n",
    "    cost_budget_daily_usd: float = 10.0\n",
    "    failure_threshold_for_rca: int = 100  # Trigger RCA si >100 failures\n",
    "\n",
    "class ProductionValidator:\n",
    "    \"\"\"Validador de producci√≥n con stages.\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        config: ValidationConfig,\n",
    "        cache: ValidationCache,\n",
    "        llm_client: AsyncOpenAI\n",
    "    ):\n",
    "        self.config = config\n",
    "        self.cache = cache\n",
    "        self.llm_client = llm_client\n",
    "        self.daily_cost = 0.0\n",
    "        self.last_cost_reset = datetime.now()\n",
    "    \n",
    "    def _should_use_llm(self) -> bool:\n",
    "        \"\"\"Decide si usar LLM basado en sampling y budget.\"\"\"\n",
    "        # Reset daily cost\n",
    "        if datetime.now() - self.last_cost_reset > timedelta(days=1):\n",
    "            self.daily_cost = 0.0\n",
    "            self.last_cost_reset = datetime.now()\n",
    "        \n",
    "        # Check budget\n",
    "        if self.daily_cost >= self.config.cost_budget_daily_usd:\n",
    "            logger.warning(f\"Daily LLM budget exhausted: ${self.daily_cost:.2f}\")\n",
    "            return False\n",
    "        \n",
    "        # Sample rate\n",
    "        import random\n",
    "        return random.random() < self.config.llm_sample_rate\n",
    "    \n",
    "    async def validate_record(\n",
    "        self,\n",
    "        record: Dict,\n",
    "        validation_rules: Dict[str, Dict]\n",
    "    ) -> Dict:\n",
    "        \"\"\"\n",
    "        Valida un registro completo.\n",
    "        \n",
    "        Args:\n",
    "            record: diccionario con datos del registro\n",
    "            validation_rules: reglas por columna\n",
    "                {\n",
    "                    \"column_name\": {\n",
    "                        \"traditional\": {...},\n",
    "                        \"llm\": {\"enabled\": bool, \"context\": str}\n",
    "                    }\n",
    "                }\n",
    "        \n",
    "        Returns:\n",
    "            {\n",
    "                \"valid\": bool,\n",
    "                \"issues\": List[Dict],\n",
    "                \"stages_executed\": List[str],\n",
    "                \"duration_ms\": float,\n",
    "                \"cost_usd\": float\n",
    "            }\n",
    "        \"\"\"\n",
    "        start_time = datetime.now()\n",
    "        issues = []\n",
    "        stages_executed = []\n",
    "        total_cost = 0.0\n",
    "        \n",
    "        # STAGE 1: TRADITIONAL (ALWAYS)\n",
    "        if self.config.traditional_enabled:\n",
    "            with VALIDATION_DURATION.labels(stage='traditional').time():\n",
    "                trad_issues = await self._validate_traditional(record, validation_rules)\n",
    "                issues.extend(trad_issues)\n",
    "                stages_executed.append('traditional')\n",
    "                VALIDATIONS_TOTAL.labels(stage='traditional', result='pass' if len(trad_issues)==0 else 'fail').inc()\n",
    "        \n",
    "        # Si traditional falla cr√≠ticamente, no continuar\n",
    "        critical_issues = [i for i in issues if i.get('severity') == 'CRITICAL']\n",
    "        if critical_issues:\n",
    "            duration_ms = (datetime.now() - start_time).total_seconds() * 1000\n",
    "            return {\n",
    "                \"valid\": False,\n",
    "                \"issues\": issues,\n",
    "                \"stages_executed\": stages_executed,\n",
    "                \"duration_ms\": duration_ms,\n",
    "                \"cost_usd\": 0.0\n",
    "            }\n",
    "        \n",
    "        # STAGE 2: LLM SEMANTIC (SAMPLED)\n",
    "        if self.config.llm_enabled and self._should_use_llm():\n",
    "            with VALIDATION_DURATION.labels(stage='llm_semantic').time():\n",
    "                llm_issues, llm_cost = await self._validate_llm_semantic(record, validation_rules)\n",
    "                issues.extend(llm_issues)\n",
    "                stages_executed.append('llm_semantic')\n",
    "                total_cost += llm_cost\n",
    "                self.daily_cost += llm_cost\n",
    "                LLM_API_COST.set(self.daily_cost)\n",
    "                VALIDATIONS_TOTAL.labels(stage='llm_semantic', result='pass' if len(llm_issues)==0 else 'fail').inc()\n",
    "        \n",
    "        duration_ms = (datetime.now() - start_time).total_seconds() * 1000\n",
    "        \n",
    "        return {\n",
    "            \"valid\": len(issues) == 0,\n",
    "            \"issues\": issues,\n",
    "            \"stages_executed\": stages_executed,\n",
    "            \"duration_ms\": duration_ms,\n",
    "            \"cost_usd\": total_cost\n",
    "        }\n",
    "    \n",
    "    async def _validate_traditional(\n",
    "        self,\n",
    "        record: Dict,\n",
    "        rules: Dict\n",
    "    ) -> List[Dict]:\n",
    "        \"\"\"Stage 1: validaci√≥n tradicional (r√°pida).\"\"\"\n",
    "        issues = []\n",
    "        \n",
    "        for column, rule_config in rules.items():\n",
    "            if 'traditional' not in rule_config:\n",
    "                continue\n",
    "            \n",
    "            value = record.get(column)\n",
    "            trad_rules = rule_config['traditional']\n",
    "            \n",
    "            # NULL check\n",
    "            if trad_rules.get('not_null') and value is None:\n",
    "                issues.append({\n",
    "                    \"column\": column,\n",
    "                    \"issue_type\": \"NULL\",\n",
    "                    \"severity\": \"CRITICAL\",\n",
    "                    \"message\": f\"Column '{column}' cannot be NULL\"\n",
    "                })\n",
    "            \n",
    "            # Range check\n",
    "            if 'range' in trad_rules and value is not None:\n",
    "                min_val, max_val = trad_rules['range']\n",
    "                if not (min_val <= value <= max_val):\n",
    "                    issues.append({\n",
    "                        \"column\": column,\n",
    "                        \"issue_type\": \"RANGE\",\n",
    "                        \"severity\": \"ERROR\",\n",
    "                        \"message\": f\"Value {value} outside range [{min_val}, {max_val}]\"\n",
    "                    })\n",
    "            \n",
    "            # Regex check\n",
    "            if 'regex' in trad_rules and value is not None:\n",
    "                import re\n",
    "                if not re.match(trad_rules['regex'], str(value)):\n",
    "                    issues.append({\n",
    "                        \"column\": column,\n",
    "                        \"issue_type\": \"FORMAT\",\n",
    "                        \"severity\": \"ERROR\",\n",
    "                        \"message\": f\"Value '{value}' doesn't match expected format\"\n",
    "                    })\n",
    "        \n",
    "        return issues\n",
    "    \n",
    "    async def _validate_llm_semantic(\n",
    "        self,\n",
    "        record: Dict,\n",
    "        rules: Dict\n",
    "    ) -> tuple[List[Dict], float]:\n",
    "        \"\"\"Stage 2: validaci√≥n sem√°ntica con LLM (muestreada).\"\"\"\n",
    "        issues = []\n",
    "        total_cost = 0.0\n",
    "        \n",
    "        # Validar columnas con LLM enabled\n",
    "        llm_columns = {\n",
    "            col: config for col, config in rules.items()\n",
    "            if config.get('llm', {}).get('enabled', False)\n",
    "        }\n",
    "        \n",
    "        # Crear tasks concurrentes (con l√≠mite)\n",
    "        semaphore = asyncio.Semaphore(self.config.llm_max_concurrent)\n",
    "        \n",
    "        async def validate_column(column: str, config: Dict):\n",
    "            async with semaphore:\n",
    "                value = record.get(column)\n",
    "                if value is None:\n",
    "                    return None, 0.0\n",
    "                \n",
    "                context = config['llm']['context']\n",
    "                \n",
    "                # Check cache\n",
    "                cached = self.cache.get(str(value), context, 'plausibility')\n",
    "                if cached:\n",
    "                    if not cached['is_valid']:\n",
    "                        return {\n",
    "                            \"column\": column,\n",
    "                            \"issue_type\": \"IMPLAUSIBLE\",\n",
    "                            \"severity\": \"WARNING\",\n",
    "                            \"message\": f\"{cached['reasoning']} (cached)\",\n",
    "                            \"confidence\": cached['confidence']\n",
    "                        }, 0.0\n",
    "                    return None, 0.0\n",
    "                \n",
    "                # LLM validation\n",
    "                prompt = f\"\"\"Valida plausibilidad:\n",
    "Column: {column}\n",
    "Context: {context}\n",
    "Value: {value}\n",
    "\n",
    "¬øEs v√°lido? Responde JSON: {{\"is_valid\": bool, \"confidence\": 0-1, \"reasoning\": \"...\"}}\"\"\"\n",
    "                \n",
    "                try:\n",
    "                    response = await asyncio.wait_for(\n",
    "                        self.llm_client.chat.completions.create(\n",
    "                            model=\"gpt-4o-mini\",\n",
    "                            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                            temperature=0,\n",
    "                            response_format={\"type\": \"json_object\"}\n",
    "                        ),\n",
    "                        timeout=self.config.llm_timeout_seconds\n",
    "                    )\n",
    "                    \n",
    "                    result = json.loads(response.choices[0].message.content)\n",
    "                    \n",
    "                    # Estimar costo\n",
    "                    cost = (len(prompt) / 4 / 1_000_000 * 0.15) + (len(response.choices[0].message.content) / 4 / 1_000_000 * 0.60)\n",
    "                    \n",
    "                    # Cache result\n",
    "                    self.cache.set(str(value), context, 'plausibility', result)\n",
    "                    \n",
    "                    if not result['is_valid']:\n",
    "                        return {\n",
    "                            \"column\": column,\n",
    "                            \"issue_type\": \"IMPLAUSIBLE\",\n",
    "                            \"severity\": \"WARNING\",\n",
    "                            \"message\": result['reasoning'],\n",
    "                            \"confidence\": result['confidence']\n",
    "                        }, cost\n",
    "                    \n",
    "                    return None, cost\n",
    "                    \n",
    "                except asyncio.TimeoutError:\n",
    "                    logger.warning(f\"LLM timeout for column {column}\")\n",
    "                    return None, 0.0\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"LLM error for column {column}: {e}\")\n",
    "                    return None, 0.0\n",
    "        \n",
    "        # Ejecutar validaciones en paralelo\n",
    "        tasks = [validate_column(col, config) for col, config in llm_columns.items()]\n",
    "        results = await asyncio.gather(*tasks)\n",
    "        \n",
    "        for issue, cost in results:\n",
    "            if issue:\n",
    "                issues.append(issue)\n",
    "            total_cost += cost\n",
    "        \n",
    "        return issues, total_cost\n",
    "\n",
    "# 3. BATCH VALIDATOR (para procesamiento masivo)\n",
    "\n",
    "class BatchValidator:\n",
    "    \"\"\"Validador optimizado para batches grandes.\"\"\"\n",
    "    \n",
    "    def __init__(self, validator: ProductionValidator):\n",
    "        self.validator = validator\n",
    "    \n",
    "    async def validate_batch(\n",
    "        self,\n",
    "        records: List[Dict],\n",
    "        validation_rules: Dict,\n",
    "        parallelism: int = 100\n",
    "    ) -> Dict:\n",
    "        \"\"\"\n",
    "        Valida batch de registros en paralelo.\n",
    "        \n",
    "        Returns:\n",
    "            {\n",
    "                \"total_records\": int,\n",
    "                \"valid_records\": int,\n",
    "                \"invalid_records\": int,\n",
    "                \"issues_by_type\": Dict[str, int],\n",
    "                \"total_duration_seconds\": float,\n",
    "                \"total_cost_usd\": float\n",
    "            }\n",
    "        \"\"\"\n",
    "        start_time = datetime.now()\n",
    "        \n",
    "        # Semaphore para controlar paralelismo\n",
    "        semaphore = asyncio.Semaphore(parallelism)\n",
    "        \n",
    "        async def validate_with_semaphore(record):\n",
    "            async with semaphore:\n",
    "                return await self.validator.validate_record(record, validation_rules)\n",
    "        \n",
    "        # Validar todos los registros\n",
    "        tasks = [validate_with_semaphore(record) for record in records]\n",
    "        results = await asyncio.gather(*tasks)\n",
    "        \n",
    "        # Agregar resultados\n",
    "        valid_count = sum(1 for r in results if r['valid'])\n",
    "        invalid_count = len(results) - valid_count\n",
    "        \n",
    "        issues_by_type = {}\n",
    "        total_cost = 0.0\n",
    "        \n",
    "        for result in results:\n",
    "            total_cost += result['cost_usd']\n",
    "            for issue in result['issues']:\n",
    "                issue_type = issue['issue_type']\n",
    "                issues_by_type[issue_type] = issues_by_type.get(issue_type, 0) + 1\n",
    "        \n",
    "        duration = (datetime.now() - start_time).total_seconds()\n",
    "        \n",
    "        return {\n",
    "            \"total_records\": len(records),\n",
    "            \"valid_records\": valid_count,\n",
    "            \"invalid_records\": invalid_count,\n",
    "            \"issues_by_type\": issues_by_type,\n",
    "            \"total_duration_seconds\": duration,\n",
    "            \"total_cost_usd\": total_cost,\n",
    "            \"throughput_records_per_second\": len(records) / duration\n",
    "        }\n",
    "\n",
    "# EJEMPLO DE USO EN PRODUCCI√ìN\n",
    "\n",
    "async def main():\n",
    "    # Setup\n",
    "    cache = ValidationCache()\n",
    "    llm_client = AsyncOpenAI(api_key=os.getenv('OPENAI_API_KEY'))\n",
    "    \n",
    "    config = ValidationConfig(\n",
    "        traditional_enabled=True,\n",
    "        llm_enabled=True,\n",
    "        llm_sample_rate=0.01,  # 1% de tr√°fico\n",
    "        llm_max_concurrent=10,\n",
    "        cost_budget_daily_usd=10.0\n",
    "    )\n",
    "    \n",
    "    validator = ProductionValidator(config, cache, llm_client)\n",
    "    batch_validator = BatchValidator(validator)\n",
    "    \n",
    "    # Reglas de validaci√≥n\n",
    "    validation_rules = {\n",
    "        'email': {\n",
    "            'traditional': {\n",
    "                'not_null': True,\n",
    "                'regex': r'^[\\w\\.-]+@[\\w\\.-]+\\.\\w+$'\n",
    "            },\n",
    "            'llm': {\n",
    "                'enabled': True,\n",
    "                'context': 'Customer emails (no test data)'\n",
    "            }\n",
    "        },\n",
    "        'age': {\n",
    "            'traditional': {\n",
    "                'not_null': True,\n",
    "                'range': [18, 120]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Dataset de prueba (1000 registros)\n",
    "    records = [\n",
    "        {'email': f'user{i}@example.com', 'age': 25 + (i % 50)}\n",
    "        for i in range(1000)\n",
    "    ]\n",
    "    \n",
    "    # Agregar algunos registros problem√°ticos\n",
    "    records[10]['email'] = 'test@test.test'  # Fake email\n",
    "    records[20]['age'] = 999  # Outlier\n",
    "    records[30]['email'] = None  # NULL\n",
    "    \n",
    "    # Validar batch\n",
    "    print(\"üöÄ Validando batch de 1000 registros...\")\n",
    "    result = await batch_validator.validate_batch(records, validation_rules, parallelism=50)\n",
    "    \n",
    "    print(\"\\nüìä RESULTADOS:\")\n",
    "    print(f\"   Total: {result['total_records']}\")\n",
    "    print(f\"   V√°lidos: {result['valid_records']} ({result['valid_records']/result['total_records']:.1%})\")\n",
    "    print(f\"   Inv√°lidos: {result['invalid_records']}\")\n",
    "    print(f\"   Issues por tipo: {result['issues_by_type']}\")\n",
    "    print(f\"   Duraci√≥n: {result['total_duration_seconds']:.2f}s\")\n",
    "    print(f\"   Throughput: {result['throughput_records_per_second']:.0f} records/s\")\n",
    "    print(f\"   Costo total: ${result['total_cost_usd']:.4f}\")\n",
    "\n",
    "# Ejecutar\n",
    "# asyncio.run(main())\n",
    "```\n",
    "\n",
    "### üìä M√©tricas de Producci√≥n\n",
    "\n",
    "| M√©trica | Target | Medici√≥n |\n",
    "|---------|--------|----------|\n",
    "| **Latency p50** | <50ms | Traditional only |\n",
    "| **Latency p99** | <500ms | With LLM (1% sample) |\n",
    "| **Throughput** | >1000 records/s | Batch processing |\n",
    "| **Cache hit rate** | >80% | Redis cache |\n",
    "| **Cost per 1M records** | <$10 | LLM API calls |\n",
    "| **False positive rate** | <2% | Validation precision |\n",
    "| **Availability** | 99.9% | Uptime |\n",
    "\n",
    "### üí∞ Estrategias de Optimizaci√≥n de Costos\n",
    "\n",
    "```python\n",
    "# 1. ADAPTIVE SAMPLING\n",
    "class AdaptiveSampler:\n",
    "    \"\"\"Ajusta sample rate bas√°ndose en calidad de datos.\"\"\"\n",
    "    \n",
    "    def __init__(self, initial_rate: float = 0.01):\n",
    "        self.rate = initial_rate\n",
    "        self.recent_issues = []\n",
    "    \n",
    "    def update(self, has_issues: bool):\n",
    "        \"\"\"Actualiza rate bas√°ndose en issues recientes.\"\"\"\n",
    "        self.recent_issues.append(has_issues)\n",
    "        \n",
    "        # Mantener ventana de √∫ltimos 1000 registros\n",
    "        if len(self.recent_issues) > 1000:\n",
    "            self.recent_issues = self.recent_issues[-1000:]\n",
    "        \n",
    "        issue_rate = sum(self.recent_issues) / len(self.recent_issues)\n",
    "        \n",
    "        # Si issue rate es alta (>5%), aumentar sampling\n",
    "        if issue_rate > 0.05:\n",
    "            self.rate = min(0.10, self.rate * 1.5)\n",
    "        # Si issue rate es baja (<1%), reducir sampling\n",
    "        elif issue_rate < 0.01:\n",
    "            self.rate = max(0.001, self.rate * 0.8)\n",
    "    \n",
    "    def should_sample(self) -> bool:\n",
    "        import random\n",
    "        return random.random() < self.rate\n",
    "\n",
    "# 2. SMART CACHING\n",
    "# Cachear por m√°s tiempo valores que se repiten frecuentemente\n",
    "# TTL adaptativo basado en frecuencia\n",
    "\n",
    "# 3. BATCH INFERENCE\n",
    "# Procesar m√∫ltiples validaciones en un solo prompt\n",
    "# Reducir overhead de API calls\n",
    "```\n",
    "\n",
    "### üöÄ Deployment Checklist\n",
    "\n",
    "- [ ] **Infraestructura**:\n",
    "  - [ ] Redis cluster para cache (multi-AZ)\n",
    "  - [ ] Async workers (Celery / RQ)\n",
    "  - [ ] Load balancer para distribuci√≥n\n",
    "  \n",
    "- [ ] **Monitoring**:\n",
    "  - [ ] Prometheus + Grafana dashboards\n",
    "  - [ ] Alertas en PagerDuty/Slack\n",
    "  - [ ] Cost tracking diario\n",
    "  - [ ] Latency monitoring (p50, p95, p99)\n",
    "  \n",
    "- [ ] **Testing**:\n",
    "  - [ ] Load testing (>10K records/s)\n",
    "  - [ ] Chaos testing (LLM API down)\n",
    "  - [ ] Cost simulation\n",
    "  \n",
    "- [ ] **Security**:\n",
    "  - [ ] API key rotation\n",
    "  - [ ] PII masking en logs\n",
    "  - [ ] Rate limiting por usuario\n",
    "  \n",
    "- [ ] **Documentation**:\n",
    "  - [ ] Runbook para incidents\n",
    "  - [ ] SLA commitments\n",
    "  - [ ] Cost budgets por equipo\n",
    "\n",
    "---\n",
    "**Autor:** Luis J. Raigoso V. (LJRV)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db249c09",
   "metadata": {},
   "source": [
    "## 1. Detecci√≥n de anomal√≠as sem√°nticas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78572e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))\n",
    "\n",
    "def detect_anomaly(value: str, context: str) -> dict:\n",
    "    \"\"\"Detecta si un valor es an√≥malo en su contexto.\"\"\"\n",
    "    prompt = f'''\n",
    "Contexto: {context}\n",
    "Valor: {value}\n",
    "\n",
    "¬øEs este valor an√≥malo o incorrecto? Responde en JSON:\n",
    "{{\n",
    "  \"is_anomaly\": true/false,\n",
    "  \"confidence\": 0-100,\n",
    "  \"reason\": \"explicaci√≥n\",\n",
    "  \"suggested_fix\": \"valor corregido o null\"\n",
    "}}\n",
    "'''\n",
    "    resp = client.chat.completions.create(\n",
    "        model='gpt-4',\n",
    "        messages=[{'role':'user','content':prompt}],\n",
    "        temperature=0\n",
    "    )\n",
    "    import json\n",
    "    return json.loads(resp.choices[0].message.content)\n",
    "\n",
    "# Ejemplos\n",
    "casos = [\n",
    "    {'valor': 'Nueva Yorkk', 'contexto': 'Columna: ciudad (ciudades de USA)'},\n",
    "    {'valor': '999', 'contexto': 'Columna: edad (a√±os de personas)'},\n",
    "    {'valor': 'admin@example.com', 'contexto': 'Columna: email de clientes reales'}\n",
    "]\n",
    "\n",
    "for caso in casos:\n",
    "    result = detect_anomaly(caso['valor'], caso['contexto'])\n",
    "    print(f\"Valor: {caso['valor']}\")\n",
    "    print(f\"Anomal√≠a: {result['is_anomaly']} (confianza={result['confidence']}%)\")\n",
    "    print(f\"Raz√≥n: {result['reason']}\")\n",
    "    if result['suggested_fix']:\n",
    "        print(f\"Sugerencia: {result['suggested_fix']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40dcd6b",
   "metadata": {},
   "source": [
    "## 2. Clasificaci√≥n de errores en datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc1c9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_data_issue(issue_description: str) -> str:\n",
    "    \"\"\"Clasifica el tipo de problema de datos.\"\"\"\n",
    "    prompt = f'''\n",
    "Clasifica este problema de datos en UNA categor√≠a:\n",
    "- DUPLICATES: registros duplicados\n",
    "- NULLS: valores faltantes\n",
    "- FORMAT: formato incorrecto\n",
    "- OUTLIER: valores fuera de rango\n",
    "- INCONSISTENCY: datos inconsistentes entre fuentes\n",
    "- FRESHNESS: datos desactualizados\n",
    "\n",
    "Problema: {issue_description}\n",
    "\n",
    "Categor√≠a:\n",
    "'''\n",
    "    resp = client.chat.completions.create(\n",
    "        model='gpt-3.5-turbo',\n",
    "        messages=[{'role':'user','content':prompt}],\n",
    "        temperature=0\n",
    "    )\n",
    "    return resp.choices[0].message.content.strip()\n",
    "\n",
    "issues = [\n",
    "    'La tabla tiene 500 filas con cliente_id = NULL',\n",
    "    'Fechas en formato DD/MM/YYYY pero esperamos YYYY-MM-DD',\n",
    "    '√öltima actualizaci√≥n hace 7 d√≠as pero debe ser diaria',\n",
    "    'Misma transacci√≥n aparece 3 veces con diferentes IDs'\n",
    "]\n",
    "\n",
    "for issue in issues:\n",
    "    categoria = classify_data_issue(issue)\n",
    "    print(f'‚û°Ô∏è \"{issue}\"')\n",
    "    print(f'   Categor√≠a: {categoria}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb562809",
   "metadata": {},
   "source": [
    "## 3. Generaci√≥n de reglas de validaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e3c7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_validation_rules(column_name: str, sample_data: list, description: str = '') -> str:\n",
    "    \"\"\"Genera reglas de Great Expectations.\"\"\"\n",
    "    prompt = f'''\n",
    "Genera expectativas de Great Expectations (Python) para validar esta columna:\n",
    "\n",
    "Columna: {column_name}\n",
    "Descripci√≥n: {description}\n",
    "Muestra de datos: {sample_data}\n",
    "\n",
    "Genera c√≥digo Python con expect_* methods. Ejemplos:\n",
    "- expect_column_values_to_not_be_null\n",
    "- expect_column_values_to_be_between\n",
    "- expect_column_values_to_match_regex\n",
    "\n",
    "C√≥digo:\n",
    "'''\n",
    "    resp = client.chat.completions.create(\n",
    "        model='gpt-4',\n",
    "        messages=[{'role':'user','content':prompt}],\n",
    "        temperature=0.1\n",
    "    )\n",
    "    return resp.choices[0].message.content.strip().replace('```python','').replace('```','')\n",
    "\n",
    "# Ejemplo\n",
    "rules = generate_validation_rules(\n",
    "    column_name='email',\n",
    "    sample_data=['user@example.com', 'admin@test.org', 'info@company.co'],\n",
    "    description='Emails de clientes'\n",
    ")\n",
    "\n",
    "print(rules)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cecde61",
   "metadata": {},
   "source": [
    "## 4. Validaci√≥n batch con LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cef1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_batch(df: pd.DataFrame, rules: dict) -> pd.DataFrame:\n",
    "    \"\"\"Valida DataFrame seg√∫n reglas inferidas por LLM.\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for col, rule_desc in rules.items():\n",
    "        sample = df[col].dropna().head(10).tolist()\n",
    "        \n",
    "        prompt = f'''\n",
    "Valida si estos valores cumplen la regla:\n",
    "Regla: {rule_desc}\n",
    "Valores: {sample}\n",
    "\n",
    "Responde con porcentaje de conformidad (0-100) y problemas encontrados.\n",
    "'''\n",
    "        \n",
    "        resp = client.chat.completions.create(\n",
    "            model='gpt-3.5-turbo',\n",
    "            messages=[{'role':'user','content':prompt}],\n",
    "            temperature=0\n",
    "        )\n",
    "        \n",
    "        results.append({\n",
    "            'columna': col,\n",
    "            'regla': rule_desc,\n",
    "            'resultado': resp.choices[0].message.content\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Datos de prueba\n",
    "df_test = pd.DataFrame({\n",
    "    'edad': [25, 30, 200, 45, -5],\n",
    "    'email': ['a@b.com', 'invalido', 'test@x.org', None, 'ok@mail.com']\n",
    "})\n",
    "\n",
    "validation_rules = {\n",
    "    'edad': 'Debe estar entre 0 y 120',\n",
    "    'email': 'Debe ser email v√°lido o null'\n",
    "}\n",
    "\n",
    "validation_report = validate_batch(df_test, validation_rules)\n",
    "print(validation_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00de5039",
   "metadata": {},
   "source": [
    "## 5. Explicaci√≥n de anomal√≠as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058d734b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain_outlier(value: float, stats: dict) -> str:\n",
    "    \"\"\"Explica por qu√© un valor es outlier en lenguaje natural.\"\"\"\n",
    "    prompt = f'''\n",
    "Valor: {value}\n",
    "Estad√≠sticas de la columna:\n",
    "- Media: {stats['mean']}\n",
    "- Desviaci√≥n est√°ndar: {stats['std']}\n",
    "- Min: {stats['min']}\n",
    "- Max: {stats['max']}\n",
    "\n",
    "Explica en 2-3 frases por qu√© este valor es an√≥malo y qu√© puede indicar.\n",
    "'''\n",
    "    resp = client.chat.completions.create(\n",
    "        model='gpt-4',\n",
    "        messages=[{'role':'user','content':prompt}],\n",
    "        temperature=0.3\n",
    "    )\n",
    "    return resp.choices[0].message.content.strip()\n",
    "\n",
    "# Ejemplo\n",
    "outlier_explanation = explain_outlier(\n",
    "    value=50000,\n",
    "    stats={'mean': 120, 'std': 35, 'min': 50, 'max': 250}\n",
    ")\n",
    "\n",
    "print('Explicaci√≥n del outlier:')\n",
    "print(outlier_explanation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9b80d2",
   "metadata": {},
   "source": [
    "## 6. Sugerencia de limpieza de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5c773b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def suggest_data_cleaning(df_sample: pd.DataFrame) -> str:\n",
    "    \"\"\"Sugiere pasos de limpieza basados en muestra.\"\"\"\n",
    "    info = {\n",
    "        'columns': df_sample.columns.tolist(),\n",
    "        'dtypes': df_sample.dtypes.astype(str).to_dict(),\n",
    "        'nulls': df_sample.isnull().sum().to_dict(),\n",
    "        'sample': df_sample.head(3).to_dict()\n",
    "    }\n",
    "    \n",
    "    prompt = f'''\n",
    "Analiza este DataFrame y sugiere pasos de limpieza en orden de prioridad:\n",
    "\n",
    "{info}\n",
    "\n",
    "Lista numerada de acciones de limpieza con c√≥digo Pandas cuando sea relevante.\n",
    "'''\n",
    "    \n",
    "    resp = client.chat.completions.create(\n",
    "        model='gpt-4',\n",
    "        messages=[{'role':'user','content':prompt}],\n",
    "        temperature=0.2\n",
    "    )\n",
    "    \n",
    "    return resp.choices[0].message.content\n",
    "\n",
    "messy_df = pd.DataFrame({\n",
    "    'fecha': ['2024-01-01', '01/02/2024', None, '2024-03-15'],\n",
    "    'monto': ['100', '200.5', 'N/A', '300'],\n",
    "    'categoria': ['  ventas', 'VENTAS', 'Ventas ', 'marketing']\n",
    "})\n",
    "\n",
    "cleaning_plan = suggest_data_cleaning(messy_df)\n",
    "print(cleaning_plan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d205e02",
   "metadata": {},
   "source": [
    "## 7. Validaci√≥n de coherencia entre tablas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc895787",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_referential_integrity(parent_ids: list, child_ids: list, relationship: str) -> dict:\n",
    "    \"\"\"Valida integridad referencial con explicaci√≥n.\"\"\"\n",
    "    orphans = set(child_ids) - set(parent_ids)\n",
    "    \n",
    "    prompt = f'''\n",
    "Relaci√≥n: {relationship}\n",
    "IDs hu√©rfanos (en tabla hija pero no en padre): {list(orphans)[:10]}\n",
    "Total hu√©rfanos: {len(orphans)}\n",
    "\n",
    "Explica el problema y sugiere 3 posibles causas.\n",
    "'''\n",
    "    \n",
    "    resp = client.chat.completions.create(\n",
    "        model='gpt-4',\n",
    "        messages=[{'role':'user','content':prompt}],\n",
    "        temperature=0.2\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        'orphans_count': len(orphans),\n",
    "        'orphan_sample': list(orphans)[:5],\n",
    "        'explanation': resp.choices[0].message.content\n",
    "    }\n",
    "\n",
    "# Ejemplo\n",
    "productos_ids = [1, 2, 3, 4, 5]\n",
    "ventas_producto_ids = [1, 2, 3, 99, 100, 5]\n",
    "\n",
    "integrity_check = validate_referential_integrity(\n",
    "    parent_ids=productos_ids,\n",
    "    child_ids=ventas_producto_ids,\n",
    "    relationship='ventas.producto_id -> productos.producto_id'\n",
    ")\n",
    "\n",
    "print(f\"Hu√©rfanos: {integrity_check['orphans_count']}\")\n",
    "print(f\"Muestra: {integrity_check['orphan_sample']}\")\n",
    "print(f\"\\nExplicaci√≥n:\\n{integrity_check['explanation']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808646c6",
   "metadata": {},
   "source": [
    "## 8. Buenas pr√°cticas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af78399a",
   "metadata": {},
   "source": [
    "- **Complementar, no reemplazar**: LLMs complementan herramientas tradicionales (GE, pandas profiling).\n",
    "- **Validaci√≥n humana**: revisa sugerencias antes de aplicar.\n",
    "- **Umbrales**: define confidence thresholds para automatizaci√≥n.\n",
    "- **Logging**: registra todas las decisiones del LLM.\n",
    "- **Costos**: cachea validaciones comunes.\n",
    "- **Testing**: valida el validador con datos conocidos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37ea8ee",
   "metadata": {},
   "source": [
    "## 9. Ejercicios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9702d2f9",
   "metadata": {},
   "source": [
    "1. Construye un sistema de auto-reparaci√≥n de datos usando LLM suggestions.\n",
    "2. Genera un data quality dashboard con explicaciones en lenguaje natural.\n",
    "3. Implementa detecci√≥n de PII (datos sensibles) con LLMs.\n",
    "4. Crea un agente que diagnostique problemas de data quality y proponga fixes."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
