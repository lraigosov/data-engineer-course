{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed0d4e2b",
   "metadata": {},
   "source": [
    "# üîç Embeddings y Similitud en Datos\n",
    "\n",
    "Objetivo: usar embeddings para b√∫squeda sem√°ntica en cat√°logos de datos, detecci√≥n de duplicados, clustering, y recomendaciones.\n",
    "\n",
    "- Duraci√≥n: 90 min\n",
    "- Dificultad: Media\n",
    "- Stack: OpenAI Embeddings, scikit-learn, FAISS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d7fd36",
   "metadata": {},
   "source": [
    "## 1. Generar embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffb93fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))\n",
    "\n",
    "def embed(text: str) -> np.ndarray:\n",
    "    resp = client.embeddings.create(\n",
    "        model='text-embedding-ada-002',\n",
    "        input=text\n",
    "    )\n",
    "    return np.array(resp.data[0].embedding)\n",
    "\n",
    "textos = [\n",
    "    'Tabla de ventas con transacciones diarias',\n",
    "    'Data de transacciones de venta por d√≠a',  # Similar\n",
    "    'Cat√°logo de productos con precios',\n",
    "    'Informaci√≥n demogr√°fica de clientes'\n",
    "]\n",
    "\n",
    "embeddings = [embed(t) for t in textos]\n",
    "print(f'Embeddings generados: {len(embeddings)} vectores de dimensi√≥n {len(embeddings[0])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa1b5e1",
   "metadata": {},
   "source": [
    "## 2. Similitud coseno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792b6c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Matriz de similitud\n",
    "sim_matrix = cosine_similarity(embeddings)\n",
    "\n",
    "print('Matriz de similitud:\\n')\n",
    "for i, texto in enumerate(textos):\n",
    "    print(f'{i}. {texto}')\n",
    "\n",
    "print('\\n', sim_matrix.round(3))\n",
    "print(f'\\n‚û°Ô∏è Textos 0 y 1 tienen similitud: {sim_matrix[0][1]:.3f} (duplicados potenciales)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1635129",
   "metadata": {},
   "source": [
    "## 3. B√∫squeda sem√°ntica en cat√°logo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e73834",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cat√°logo de data assets\n",
    "catalogo = pd.DataFrame([\n",
    "    {'asset': 'dwh.ventas', 'desc': 'Transacciones de venta con fecha, monto, producto'},\n",
    "    {'asset': 'dwh.clientes', 'desc': 'Datos demogr√°ficos de clientes: edad, ciudad, segmento'},\n",
    "    {'asset': 'dwh.productos', 'desc': 'Cat√°logo de productos con precios y categor√≠as'},\n",
    "    {'asset': 'dwh.inventario', 'desc': 'Stock disponible por almac√©n y SKU'},\n",
    "    {'asset': 'analytics.revenue_monthly', 'desc': 'Ingresos mensuales agregados por regi√≥n'}\n",
    "])\n",
    "\n",
    "# Embeddings del cat√°logo\n",
    "catalogo['embedding'] = catalogo['desc'].apply(lambda x: embed(x))\n",
    "\n",
    "def search_catalog(query: str, top_k: int = 3) -> pd.DataFrame:\n",
    "    query_emb = embed(query)\n",
    "    catalogo['similarity'] = catalogo['embedding'].apply(\n",
    "        lambda x: cosine_similarity([query_emb], [x])[0][0]\n",
    "    )\n",
    "    return catalogo.nlargest(top_k, 'similarity')[['asset', 'desc', 'similarity']]\n",
    "\n",
    "print(search_catalog('¬øD√≥nde encuentro informaci√≥n de productos?'))\n",
    "print('\\n')\n",
    "print(search_catalog('Necesito datos de ventas mensuales'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ed677f",
   "metadata": {},
   "source": [
    "## 4. Detecci√≥n de duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ca56fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset con posibles duplicados\n",
    "descripciones = [\n",
    "    'Apple iPhone 13 Pro Max 256GB',\n",
    "    'iPhone 13 Pro Max 256GB Apple',\n",
    "    'Samsung Galaxy S21 Ultra',\n",
    "    'Galaxy S21 Ultra by Samsung',\n",
    "    'Sony PlayStation 5 Console'\n",
    "]\n",
    "\n",
    "embs = [embed(d) for d in descripciones]\n",
    "threshold = 0.95\n",
    "\n",
    "duplicates = []\n",
    "for i in range(len(embs)):\n",
    "    for j in range(i+1, len(embs)):\n",
    "        sim = cosine_similarity([embs[i]], [embs[j]])[0][0]\n",
    "        if sim > threshold:\n",
    "            duplicates.append((i, j, sim))\n",
    "\n",
    "print('Duplicados detectados:\\n')\n",
    "for i, j, sim in duplicates:\n",
    "    print(f'- \"{descripciones[i]}\" ‚âà \"{descripciones[j]}\" (sim={sim:.3f})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc50e87c",
   "metadata": {},
   "source": [
    "## 5. Clustering con K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ab12a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "productos = [\n",
    "    'Laptop Dell XPS 13',\n",
    "    'MacBook Pro 14 inch',\n",
    "    'HP Pavilion Laptop',\n",
    "    'Nike Air Max Sneakers',\n",
    "    'Adidas Ultraboost Shoes',\n",
    "    'Puma Running Shoes',\n",
    "    'Organic Green Tea 100 bags',\n",
    "    'Colombian Coffee Beans 1kg'\n",
    "]\n",
    "\n",
    "prod_embs = np.array([embed(p) for p in productos])\n",
    "\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "clusters = kmeans.fit_predict(prod_embs)\n",
    "\n",
    "df_clusters = pd.DataFrame({'producto': productos, 'cluster': clusters})\n",
    "print(df_clusters.sort_values('cluster'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a2c629",
   "metadata": {},
   "source": [
    "## 6. FAISS para b√∫squeda r√°pida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d943a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install faiss-cpu\n",
    "import faiss\n",
    "\n",
    "# Crear √≠ndice\n",
    "dimension = prod_embs.shape[1]\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "index.add(prod_embs.astype('float32'))\n",
    "\n",
    "# B√∫squeda\n",
    "query = 'zapatos deportivos'\n",
    "query_emb = embed(query).reshape(1, -1).astype('float32')\n",
    "\n",
    "k = 3\n",
    "distances, indices = index.search(query_emb, k)\n",
    "\n",
    "print(f'Top {k} productos para \"{query}\":\\n')\n",
    "for i, idx in enumerate(indices[0]):\n",
    "    print(f'{i+1}. {productos[idx]} (distancia={distances[0][i]:.2f})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae539a8",
   "metadata": {},
   "source": [
    "## 7. Recomendaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c4ae02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recomendar_similar(producto: str, catalogo: list, top_k: int = 3) -> list:\n",
    "    \"\"\"Recomienda productos similares.\"\"\"\n",
    "    query_emb = embed(producto)\n",
    "    catalogo_embs = [embed(p) for p in catalogo]\n",
    "    \n",
    "    similarities = [\n",
    "        (p, cosine_similarity([query_emb], [e])[0][0])\n",
    "        for p, e in zip(catalogo, catalogo_embs)\n",
    "        if p != producto\n",
    "    ]\n",
    "    \n",
    "    return sorted(similarities, key=lambda x: x[1], reverse=True)[:top_k]\n",
    "\n",
    "comprado = 'Laptop Dell XPS 13'\n",
    "recomendaciones = recomendar_similar(comprado, productos)\n",
    "\n",
    "print(f'Cliente compr√≥: {comprado}')\n",
    "print('Recomendaciones:\\n')\n",
    "for prod, sim in recomendaciones:\n",
    "    print(f'- {prod} (similitud={sim:.3f})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca5799c",
   "metadata": {},
   "source": [
    "## 8. Buenas pr√°cticas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b404e0ec",
   "metadata": {},
   "source": [
    "- **Cache embeddings**: generarlos es costoso, almacena en DB.\n",
    "- **Batch processing**: genera embeddings en lotes para eficiencia.\n",
    "- **Normalizaci√≥n**: limpia texto antes de generar embeddings.\n",
    "- **Modelos locales**: considera Sentence Transformers para evitar API calls.\n",
    "- **Threshold din√°mico**: ajusta seg√∫n caso de uso (duplicados vs b√∫squeda).\n",
    "- **Monitoreo de costos**: embeddings consumen tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74deae01",
   "metadata": {},
   "source": [
    "## 9. Ejercicios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912c26d3",
   "metadata": {},
   "source": [
    "1. Construye un deduplicador de registros usando embeddings.\n",
    "2. Implementa b√∫squeda h√≠brida (keyword + sem√°ntica) en tu cat√°logo.\n",
    "3. Crea clusters de clientes basados en descripciones de comportamiento.\n",
    "4. Desarrolla un sistema de recomendaci√≥n de datasets para analistas."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
