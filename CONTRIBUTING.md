# ğŸ¤ GuÃ­a de ContribuciÃ³n - Curso de IngenierÃ­a de Datos

Â¡Gracias por tu interÃ©s en contribuir al proyecto! Esta guÃ­a te ayudarÃ¡ a participar de manera efectiva y mantener la calidad del contenido educativo.

## ğŸ¯ Tipos de Contribuciones

### ğŸ“š Contenido Educativo
- **Nuevos notebooks**: Lecciones adicionales o temas especÃ­ficos
- **Mejoras en explicaciones**: Clarificar conceptos complejos
- **Ejercicios prÃ¡cticos**: Casos de uso reales y desafÃ­os
- **Datasets**: Nuevos conjuntos de datos para ejercicios

### ğŸ› Correcciones y Mejoras
- **Errores en cÃ³digo**: Bugs en notebooks o scripts
- **Errores tipogrÃ¡ficos**: DocumentaciÃ³n y comentarios
- **Optimizaciones**: Mejorar rendimiento del cÃ³digo
- **Actualizaciones**: Versiones de librerÃ­as y APIs

### ğŸ› ï¸ Infraestructura
- **Testing**: Pruebas automatizadas para notebooks
- **CI/CD**: Mejoras en workflows de GitHub Actions
- **DocumentaciÃ³n**: GuÃ­as y referencias
- **Herramientas**: Scripts de utilidad y automatizaciÃ³n

## ğŸš€ Proceso de ContribuciÃ³n

### 1. Preparar el Entorno
```bash
# Fork del repositorio en GitHub
git clone https://github.com/tu-usuario/curso-ingenieria-datos.git
cd curso-ingenieria-datos

# Configurar upstream
git remote add upstream https://github.com/original/curso-ingenieria-datos.git

# Crear entorno virtual
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# Instalar dependencias
pip install -r requirements.txt
pip install -r requirements-dev.txt  # Herramientas de desarrollo
```

### 2. Crear Branch de Trabajo
```bash
# Sincronizar con upstream
git fetch upstream
git checkout main
git merge upstream/main

# Crear nueva rama
git checkout -b feature/nombre-descriptivo
# o
git checkout -b fix/descripcion-del-bug
# o
git checkout -b docs/mejora-documentacion
```

### 3. Realizar Cambios

#### Para Notebooks
- **Ejecutar completamente**: AsegÃºrate de que el notebook se ejecute sin errores
- **Limpiar outputs**: Usar `jupyter nbconvert --clear-output` antes del commit
- **Documentar bien**: Cada celda debe tener explicaciones claras
- **Incluir metadata**: Objetivo, duraciÃ³n, nivel de dificultad

#### Para CÃ³digo Python
- **Seguir PEP 8**: Usar black para formateo automÃ¡tico
- **Documentar funciones**: Docstrings claros y completos
- **Type hints**: Usar anotaciones de tipos cuando sea apropiado
- **Tests**: Incluir pruebas para nuevo cÃ³digo

### 4. Validar Cambios
```bash
# Formatear cÃ³digo
black .

# Verificar linting
flake8 .

# Ejecutar tests
pytest

# Validar notebooks
pytest --nbval notebooks/
```

### 5. Commit y Push
```bash
# Agregar cambios
git add .

# Commit con mensaje descriptivo
git commit -m "feat: agregar notebook sobre Apache Kafka

- IntroducciÃ³n a conceptos de streaming
- Ejemplos prÃ¡cticos con kafka-python
- Ejercicios con casos de uso reales
- Tests automatizados incluidos"

# Push a tu fork
git push origin feature/nombre-descriptivo
```

### 6. Crear Pull Request
- **TÃ­tulo claro**: Describe el cambio principal
- **DescripciÃ³n detallada**: Explica quÃ©, por quÃ© y cÃ³mo
- **Screenshots**: Para cambios visuales
- **Testing**: Describe cÃ³mo probaste los cambios
- **Referencias**: Issues relacionados

## ğŸ“ EstÃ¡ndares de Calidad

### Notebooks (.ipynb)
```python
# Estructura estÃ¡ndar de notebook
"""
# [Nivel] - [NÃºmero]. [TÃ­tulo del Notebook]

**Objetivos de Aprendizaje:**
- [ ] Objetivo 1
- [ ] Objetivo 2

**DuraciÃ³n Estimada:** 45-60 minutos
**Nivel de Dificultad:** Principiante/Intermedio/Avanzado
**Prerrequisitos:** Lista de notebooks anteriores

**Datasets Necesarios:**
- dataset1.csv (descripciÃ³n)
- dataset2.json (descripciÃ³n)
"""

# Cada celda debe tener comentarios explicativos
import pandas as pd
import numpy as np

# Cargar datos con manejo de errores
try:
    df = pd.read_csv('../datasets/raw/ejemplo.csv')
    print(f"âœ… Datos cargados: {df.shape[0]} filas, {df.shape[1]} columnas")
except FileNotFoundError:
    print("âŒ Error: No se encontrÃ³ el archivo de datos")
    print("ğŸ“ InstrucciÃ³n: Ejecutar notebook de descarga de datos primero")
```

### CÃ³digo Python (.py)
```python
"""
MÃ³dulo: transformaciones.py
DescripciÃ³n: Funciones para transformaciÃ³n de datos
Autor: Tu Nombre
Fecha: 2024-01-01
"""

from typing import Optional, List, Dict, Any
import pandas as pd
import logging

# Configurar logging
logger = logging.getLogger(__name__)


def limpiar_datos(
    df: pd.DataFrame,
    columnas_numericas: Optional[List[str]] = None,
    eliminar_duplicados: bool = True
) -> pd.DataFrame:
    """
    Limpia un DataFrame aplicando transformaciones estÃ¡ndar.
    
    Args:
        df: DataFrame a limpiar
        columnas_numericas: Lista de columnas a convertir a numÃ©rico
        eliminar_duplicados: Si eliminar filas duplicadas
        
    Returns:
        DataFrame limpio
        
    Raises:
        ValueError: Si el DataFrame estÃ¡ vacÃ­o
        
    Example:
        >>> df = pd.DataFrame({'A': ['1', '2', 'invalid'], 'B': [1, 2, 3]})
        >>> df_limpio = limpiar_datos(df, columnas_numericas=['A'])
        >>> assert df_limpio['A'].dtype == 'float64'
    """
    if df.empty:
        raise ValueError("El DataFrame no puede estar vacÃ­o")
    
    df_resultado = df.copy()
    
    # Log del estado inicial
    logger.info(f"Limpiando DataFrame: {df.shape[0]} filas, {df.shape[1]} columnas")
    
    # Convertir columnas numÃ©ricas
    if columnas_numericas:
        for col in columnas_numericas:
            df_resultado[col] = pd.to_numeric(df_resultado[col], errors='coerce')
    
    # Eliminar duplicados si se solicita
    if eliminar_duplicados:
        duplicados_antes = df_resultado.duplicated().sum()
        df_resultado = df_resultado.drop_duplicates()
        logger.info(f"Eliminados {duplicados_antes} duplicados")
    
    logger.info(f"DataFrame limpio: {df_resultado.shape[0]} filas")
    return df_resultado
```

### Tests (.py)
```python
"""
test_transformaciones.py
Tests para el mÃ³dulo de transformaciones
"""

import pytest
import pandas as pd
import numpy as np
from scripts.transformaciones import limpiar_datos


class TestLimpiarDatos:
    """Tests para la funciÃ³n limpiar_datos"""
    
    def test_dataframe_vacio_genera_error(self):
        """Test que DataFrame vacÃ­o genera ValueError"""
        df_vacio = pd.DataFrame()
        
        with pytest.raises(ValueError, match="El DataFrame no puede estar vacÃ­o"):
            limpiar_datos(df_vacio)
    
    def test_conversion_columnas_numericas(self):
        """Test conversiÃ³n de columnas a numÃ©ricas"""
        df = pd.DataFrame({
            'A': ['1', '2', '3'],
            'B': ['text1', 'text2', 'text3']
        })
        
        resultado = limpiar_datos(df, columnas_numericas=['A'])
        
        assert resultado['A'].dtype in ['int64', 'float64']
        assert resultado['B'].dtype == 'object'
    
    def test_eliminacion_duplicados(self):
        """Test eliminaciÃ³n de filas duplicadas"""
        df = pd.DataFrame({
            'A': [1, 2, 2, 3],
            'B': ['a', 'b', 'b', 'c']
        })
        
        resultado = limpiar_datos(df, eliminar_duplicados=True)
        
        assert len(resultado) == 3
        assert not resultado.duplicated().any()
    
    @pytest.fixture
    def sample_dataframe(self):
        """Fixture con DataFrame de ejemplo"""
        return pd.DataFrame({
            'numeros': ['1', '2', 'invalid', '4'],
            'texto': ['a', 'b', 'c', 'd'],
            'duplicado': [1, 1, 2, 3]
        })
    
    def test_integracion_completa(self, sample_dataframe):
        """Test de integraciÃ³n con todas las funcionalidades"""
        resultado = limpiar_datos(
            sample_dataframe,
            columnas_numericas=['numeros'],
            eliminar_duplicados=True
        )
        
        assert len(resultado) == 4  # Sin duplicados en este caso
        assert resultado['numeros'].dtype in ['int64', 'float64']
        assert pd.isna(resultado['numeros'].iloc[2])  # 'invalid' -> NaN
```

## ğŸ” Review Process

### Criterios de AprobaciÃ³n
- [ ] **Funcionalidad**: El cÃ³digo funciona correctamente
- [ ] **Tests**: Pruebas pasan y cubren casos relevantes
- [ ] **DocumentaciÃ³n**: Clara y completa
- [ ] **Estilo**: Sigue las convenciones del proyecto
- [ ] **Compatibilidad**: No rompe funcionalidad existente

### Checklist para Reviewers
- [ ] Ejecutar notebook completamente
- [ ] Verificar explicaciones pedagÃ³gicas
- [ ] Validar ejemplos y ejercicios
- [ ] Comprobar manejo de errores
- [ ] Revisar performance en datasets grandes

## ğŸ·ï¸ Convenciones de Naming

### Branches
```
feature/[area]-[descripcion-corta]
fix/[area]-[descripcion-bug]
docs/[tipo-documentacion]
test/[area-testing]
refactor/[area-refactored]

# Ejemplos:
feature/junior-pandas-advanced
fix/airflow-dag-scheduling
docs/installation-guide
test/etl-pipeline-validation
```

### Commits
Usar [Conventional Commits](https://www.conventionalcommits.org/):

```
tipo(scope): descripciÃ³n

# Tipos vÃ¡lidos:
feat:     Nueva funcionalidad
fix:      CorrecciÃ³n de bug
docs:     Solo documentaciÃ³n
style:    Formateo, punto y coma, etc
refactor: Cambio de cÃ³digo que no es fix ni feature
test:     Agregar o corregir tests
chore:    Cambios en build, dependencias, etc

# Ejemplos:
feat(junior): agregar notebook de introducciÃ³n a SQL
fix(pipeline): corregir error en transformaciÃ³n de fechas
docs(readme): actualizar instrucciones de instalaciÃ³n
test(etl): agregar tests para validaciÃ³n de datos
```

## ğŸ¨ Estilo Visual

### Notebooks
- **TÃ­tulos**: Usar markdown headers (# ## ###)
- **Code blocks**: Indentar consistentemente (4 espacios)
- **Outputs**: Limpiar antes de commit
- **ImÃ¡genes**: Incluir alt text y dimensiones apropiadas

### DocumentaciÃ³n
- **Emojis**: Usar consistentemente para secciones
- **Links**: Preferir referencias relativas cuando sea posible
- **CÃ³digo**: Siempre en code blocks con syntax highlighting

## ğŸ› Reportar Issues

### Bug Reports
```markdown
## ğŸ› DescripciÃ³n del Bug
DescripciÃ³n clara y concisa del problema.

## ğŸ”„ Pasos para Reproducir
1. Ir a '...'
2. Ejecutar '...'
3. Ver error

## âœ… Comportamiento Esperado
DescripciÃ³n de lo que deberÃ­a pasar.

## ğŸ“± Entorno
- OS: [e.g. Windows 10]
- Python: [e.g. 3.9.7]
- Notebook: [e.g. 05_pandas_fundamentos.ipynb]

## ğŸ“ InformaciÃ³n Adicional
Screenshots, logs, o contexto adicional.
```

### Feature Requests
```markdown
## ğŸš€ DescripciÃ³n de la Funcionalidad
DescripciÃ³n clara de la nueva funcionalidad.

## ğŸ¯ MotivaciÃ³n
Â¿Por quÃ© serÃ­a Ãºtil esta funcionalidad?

## ğŸ’¡ SoluciÃ³n Propuesta
DescripciÃ³n de cÃ³mo deberÃ­a funcionar.

## ğŸ”„ Alternativas Consideradas
Otras soluciones que consideraste.
```

## ğŸ“ Contacto y Soporte

- **GitHub Issues**: Para bugs y feature requests ([Crear Issue](https://github.com/lraigosov/data-engineer-course/issues))
- **GitHub Discussions**: Para preguntas generales ([Ir a Discussions](https://github.com/lraigosov/data-engineer-course/discussions))
- **Email**: A travÃ©s de GitHub Issues
- **Mantenedor**: Luis J. Raigoso V. ([@lraigosov](https://github.com/lraigosov))

## ğŸ† Reconocimiento

Los contribuidores serÃ¡n reconocidos en:
- **README.md**: SecciÃ³n de contribuidores
- **CHANGELOG.md**: CrÃ©ditos por versiÃ³n
- **Hall of Fame**: Contribuidores destacados

## ğŸ‘¤ Autor y Mantenedor

**Luis J. Raigoso V. (LJRV)**
- GitHub: [@lraigosov](https://github.com/lraigosov)
- LinkedIn: [lraigosov](https://www.linkedin.com/in/lraigosov/)

---

Â¡Gracias por ayudar a hacer este curso mejor para toda la comunidad! ğŸ™Œ

Â© 2024-2025 LJRV - Luis J. Raigoso V.